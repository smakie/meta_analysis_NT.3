---
title: "meta_analysis_NT"
date: '2022-03-05'
author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"
    role:
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

output: papaja::apa6_word
always_allow_html: true
floatsintext: yes
linenumbers: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include = F)
opts <- options(knitr.kable.NA = "")
```

```{r packages}
library(metafor)
library(clubSandwich)
library(weightr)
library(tidyverse)
library(dplyr)
library(kableExtra)
library(devtools)
library(egg)
library(papaja)
library(here)
library(multcomp)
library(cowplot) 
library(openxlsx)
```




```{r function_chunk}
######################################################################
#Time converter, used to convert among different time units (mins, days, months, year)
time_converter <- function(min, d, m, y){
      mins <- ifelse(
    missing(min),
    ifelse(
      missing(d),
      ifelse(
        missing(m),
        y*525960,
        m*44560.5),
      d*1440),
    min*1)
    days <- ifelse(
    missing(d),
    ifelse(
      missing(min),
      ifelse(
        missing(m),
        y*365.25,
        m*30.4375),
      min/1440),
    d*1)
  months <- ifelse(
    missing(m),
    ifelse(
      missing(min), 
      ifelse(
        missing(d), 
        y*12, 
        d/30.4375),
      min/43830),
    m*1)
  years <- ifelse(
    missing(y),
    ifelse(
      missing(min), 
      ifelse(
        missing(d), 
        m/12, 
        d/365.25),
      min/525960),
    y*1)
  return(tibble(mins,days, months, years))
}


######################################################################
#Convert from t to r
t_to_r <- function(t, df){sqrt((t^2)/((t^2)+(df)))}


######################################################################
#apa p
report.p <- function(x, where = c("table", "text")){
  while(!require(weights)) install.packages("weights")
  if(where == "text"){
    ifelse(x < .001, "< .001", paste0(" = ", rd(x, 3)))
  }
  else {
    ifelse(x < .001, "< .001", rd(x, 3))
  }
}



######################################################################
#Used to examine the variances at each level in the 3-level meta-analysis model 
vardist.3l <- function(model, digits = 3){
  level1 <- ((length(model$vi)-1)*(sum(1/model$vi)))/
    ((sum(1/model$vi)^2)-(sum(1/((model$vi)^2))))
  level2 <- model$sigma2[2]
  level3 <- model$sigma2[1]
  p_level1 <- level1/(level1 + model$sigma2[2] + model$sigma2[1])
  p_level2 <- model$sigma2[2]/(level1 + model$sigma2[2] + model$sigma2[1])
  p_level3 <- model$sigma2[1]/(level1 + model$sigma2[2] + model$sigma2[1])
  tib1 <- rename(as.tibble(c(level1, level2, level3)), variances = value)
  tib2 <- rename(as.tibble(c(p_level1, p_level2, p_level3)), proportions_I2 = value)
  tib3 <- dplyr::select(add_column(round(cbind(tib1, tib2), digits = digits), Level = c(1, 2, 3)), Level, variances, proportions_I2)
  return(tib3)
}




######################################################################
#Sensitivity analysis: See how different degree of dependency affect the estimates 
dependency <- function(data, random = NULL, mods = ~ NULL, b = 0, r, robust = NULL, cluster = cluster){
  c <- cluster
  r.1 <- r
  rlevelz <- rename(rowid_to_column(as.tibble(r.1), var = "r_id"), r_level = value)
  estimate <- c()
  se <- c()
  ci.lb <- c()
  ci.ub <- c()
  tval <- c()
  pval <- c()
  lev3var <- c()
  lev2var <- c()
  if(is.null(robust)){
    for(counter in 1:max(rlevelz$r_id)){
      rlevelz.1 <- unlist(array(c(rlevelz[counter,][2])))
      v_r <- impute_covariance_matrix(data$vi, cluster = c, r = rlevelz.1)
      model.r <- rma.mv(yi = yi, V = v_r, data = data, struct = "CS", method = "REML", test = "t", random = random, mods =  mods)
      estimate <- c(estimate, tanh(model.r$b[b+1]))
      se <- c(se, tanh(model.r$se[b+1])) 
      ci.lb <- c(ci.lb, tanh(model.r$ci.lb[b+1]))
      ci.ub <- c(ci.ub, tanh(model.r$ci.ub[b+1]))
      tval <- c(tval, model.r$zval[b+1])
      pval <- c(pval, model.r$pval[b+1])
      lev3var <- c(lev3var, model.r$sigma2[1])
      lev2var <- c(lev2var, model.r$sigma2[2])}}
  else if(robust == "clubSandwich"){
    for(counter in 1:max(rlevelz$r_id)){
      rlevelz.1 <- unlist(array(c(rlevelz[counter,][2])))
      v_r <- impute_covariance_matrix(data$vi, cluster = c, r = rlevelz.1)
      model.r.p1 <- rma.mv(yi = yi, V = v_r, data = data, struct = "CS", method = "REML", test = "t", random = random, mods =  mods)
      model.r <- as.tibble(coef_test(model.r.p1, vcov = "CR2", cluster = c))
      estimate <- c(estimate, tanh(unlist(array(c((model.r[(b+1),][2]))))))
      se <- c(se, tanh(unlist(array(c((model.r[(b+1),][3]))))))
      tval <- c(tval, unlist(array(c((model.r[(b+1),][4])))))
      pval <- c(pval, unlist(array(c((model.r[(b+1),][6])))))}}

return(cbind(rlevelz, as.data.frame(cbind(estimate, se, ci.lb, ci.ub, tval, pval, lev3var, lev2var))))
}





######################################################################
#Outliers, influential cases and leave1out analysis 
rma.mv.influence <- function(data, struct = "CS", method = "REML", random = NULL, mods = ~ NULL, b = 0, cluster, robust = FALSE, robust.cluster, adjust = FALSE, clubSandwich = F, CHE = FALSE, r){
  data.gojira <- data
  c1 <- cluster #input should be something like "effect"
  c <- unlist(as.list(array(data[c(c1)]))) #This turns c1 into data$effect
  data.gojira.2 <- mutate(rowid_to_column(mutate(data.gojira, cluster.gojira = as.factor(c)), var = "rowid.gojira"), rowid.gojira = as.character(rowid.gojira))
  data.gojira.2$cluster.gojira2 <- group_indices(group_by(data.gojira.2, cluster.gojira), cluster.gojira)
  if(isTRUE(CHE)){
    vi_CHE <- impute_covariance_matrix(data.gojira$vi, cluster = c, r = r)}
  if(isFALSE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)}
  else if(isTRUE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi_CHE, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)
  }
     
     leveldetermine1 <- dplyr::select(mutate(rowid_to_column(rename(as.tibble(rev(str_trim(unlist(strsplit(str_trim(unlist(strsplit(as.character(model0$random), "[|]"))[2], side = c("both", "left", "right")), "[/]")), side = c("both", "left", "right")))), cluster = value), var = "id"), level = id + 1), level, cluster)
     leveldetermine2 <- unlist(as.list(array(dplyr::select(filter(leveldetermine1 , cluster == c1), level))))
    
  cluster_unit <- c()
  leave1out <- c()
  se <- c()
  tval <- c()
  pval <-c()
  ci.lb <- c()
  ci.ub <- c()
  if (!is.null(mods)) {model.F <- c()}
  if (!is.null(mods)) {model.F.p <- c()}
  model.aic <- c()
  model.bic <- c()
  model.aicc <- c()
  for(counter in 1:max(data.gojira.2$cluster.gojira2)){
    data.gojira.3 <- filter(data.gojira.2, cluster.gojira2 != counter)
    c2 <- unlist(as.list(array(data.gojira.3[c(robust.cluster)])))
    if(isTRUE(CHE)){
    vi_adjusted <- impute_covariance_matrix(data.gojira.3$vi, r = r, cluster = c2)}
    
    if (isFALSE(robust)){
      if(isFALSE(CHE)){
        model <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)}
      else if(isTRUE(CHE)){
        model <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)}}
    else if(isTRUE(robust)){
      if(isFALSE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- metafor::robust(model.p1, cluster = pull(data.gojira.3, robust.cluster), adjust = adjust, clubSandwich = clubSandwich)}
      else if(isTRUE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- metafor::robust(model.p1, cluster = pull(data.gojira.3, robust.cluster), adjust = adjust, clubSandwich = clubSandwich)}
      }
    cluster_unit <- c(cluster_unit, as.vector(dplyr::select(filter(data.gojira.2, cluster.gojira2 == counter) , cluster.gojira)[1,]))
    leave1out <- c(leave1out, tanh(model$b[b+1]))
    se <- c(se, model$se[b+1])
    tval <- c(tval, model$zval[b+1])
    pval <- c(pval, model$pval[b+1])
    ci.lb <- c(ci.lb, model$ci.lb[b+1])
    ci.ub <- c(ci.ub, model$ci.ub[b+1])
    if (!is.null(mods)) {model.F <- c(model.F, model$QM[1])}
    if (!is.null(mods)) {model.F.p <- c(model.F.p, model$QMp[1])}
    model.aic <- c(model.aic ,model$fit.stats[ifelse(model$method == "ML", 1, 2)][3,])
    model.bic <- c(model.bic, model$fit.stats[ifelse(model$method == "ML", 1, 2)][4,])
    model.aicc <- c(model.aicc, model$fit.stats[ifelse(model$method == "ML", 1, 2)][5,])
  }
  resid <- rename(dplyr::select(full_join(data.gojira.2, rename(dplyr::select(rownames_to_column(as.data.frame(rstudent(model0)), var = "rowid.gojira"), rowid.gojira, z), rstudent = z), by = "rowid.gojira"), cluster.gojira, rstudent), cluster_unit = cluster.gojira)
  cd.1 <- cooks.distance(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
  cd.2 <- rename(mutate(rownames_to_column(as.data.frame(cd.1), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit)), cooks.d = cd.1)
    dfbetas1 <- dfbetas(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
    dfbetas2 <- mutate(rownames_to_column(as.data.frame(t(as.data.frame(t(dfbetas1))[(b + 1),])), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit))
    names(dfbetas2)[2]<-paste("DFBETAS") 
    cluster_unit_col <- rename(as.tibble(c), cluster_unit = value)
    cluster_unit_col2 <- cluster_unit_col[!duplicated(cluster_unit_col$cluster_unit), ]

   #OUTPUT
  if(isFALSE(robust)){
    if(is.null(mods)){
        if(leveldetermine2 == 2){
          return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}
        else if(leveldetermine2 != 2){
          return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}}}
    
  if(isTRUE(robust)){
        if(is.null(mods)){
          if(leveldetermine2 == 2){
            return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"),dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}
            else if(leveldetermine2 != 2){
              return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}}}}



######################################################################
#Same as rma.mv.influence, but this is for robust SE with the ClubSandwich package
sandwich.influence <- function(data, struct = "CS", method = "REML", random = NULL, mods = NULL, b = 0, cluster, robust.cluster, adjust = FALSE, CHE = FALSE, r, test = "Satterthwaite"){
  data.gojira <- data
  c1 <- cluster #input should be something like "effect"
  c <- unlist(as.list(array(data[c(c1)]))) #This turns c1 into data$effect
  data.gojira.2 <- mutate(rowid_to_column(mutate(data.gojira, cluster.gojira = as.factor(c)), var = "rowid.gojira"), rowid.gojira = as.character(rowid.gojira))
  data.gojira.2$cluster.gojira2 <- group_indices(group_by(data.gojira.2, cluster.gojira), cluster.gojira)
  if(isTRUE(CHE)){
    vi_CHE <- impute_covariance_matrix(data.gojira$vi, cluster = c, r = r)}
  if(isFALSE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)}
  else if(isTRUE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi_CHE, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)
  }
     
     leveldetermine1 <- dplyr::select(mutate(rowid_to_column(rename(as.tibble(rev(str_trim(unlist(strsplit(str_trim(unlist(strsplit(as.character(model0$random), "[|]"))[2], side = c("both", "left", "right")), "[/]")), side = c("both", "left", "right")))), cluster = value), var = "id"), level = id + 1), level, cluster)
     leveldetermine2 <- unlist(as.list(array(dplyr::select(filter(leveldetermine1 , cluster == c1), level))))
    
  cluster_unit <- c()
  leave1out <- c()
  se <- c()
  t <- c()
  df <- c()
  p <- c()
  for(counter in 1:max(data.gojira.2$cluster.gojira2)){
    data.gojira.3 <- filter(data.gojira.2, cluster.gojira2 != counter)
    c2 <- unlist(as.list(array(data.gojira.3[c(robust.cluster)])))
    if(isTRUE(CHE)){
    vi_adjusted <- impute_covariance_matrix(data.gojira.3$vi, r = r, cluster = c2)}
  
    if(isFALSE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- tibble(as.data.frame(coef_test(obj = model.p1, vcov = "CR2", test = test, cluster = c2)))
        }
    else if(isTRUE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- tibble(as.data.frame(coef_test(obj = model.p1, vcov = "CR2", test = test, cluster = c2)))}
  
    cluster_unit <- c(cluster_unit, as.vector(dplyr::select(filter(data.gojira.2, cluster.gojira2 == counter) , cluster.gojira)[1,]))
    leave1out <- c(leave1out, tanh(unlist(array(c(model[(b+1),][2])))))
    se <- c(se, unlist(array(c(model[(b+1),][3]))))
    t <- c(t,  unlist(array(c(model[(b+1),][4]))))
    df <- c(df,  unlist(array(c(model[(b+1),][5]))))
    p <- c(p,  unlist(array(c(model[(b+1),][6]))))}


  resid <- rename(dplyr::select(full_join(data.gojira.2, rename(dplyr::select(rownames_to_column(as.data.frame(rstudent(model0)), var = "rowid.gojira"), rowid.gojira, z), rstudent = z), by = "rowid.gojira"), cluster.gojira, rstudent), cluster_unit = cluster.gojira)
  cd.1 <- cooks.distance(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
  cd.2 <- rename(mutate(rownames_to_column(as.data.frame(cd.1), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit)), cooks.d = cd.1)
    dfbetas1 <- dfbetas(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
    dfbetas2 <- mutate(rownames_to_column(as.data.frame(t(as.data.frame(t(dfbetas1))[(b + 1),])), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit))
    names(dfbetas2)[2]<-paste("DFBETAS") 
    cluster_unit_col <- rename(as.tibble(c), cluster_unit = value)
    cluster_unit_col2 <- cluster_unit_col[!duplicated(cluster_unit_col$cluster_unit), ]

   #OUTPUT
    if(is.null(mods)){
        if(leveldetermine2 == 2){
          return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, t, df, p))}
        else if(leveldetermine2 != 2){
          return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d,DFBETAS, leave1out, se, t, df, p))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, t, df, p))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d,DFBETAS, leave1out, se, t, df, p))}}}


######################################################################
#Assumption function, used to examine model assumption 
assumption <- function(model){
  model_fitted <- mutate(rowid_to_column(rename(as.tibble(fitted(model)), fitted = value), var = "effect"), effect = as.factor(effect))
  model_resid <- rename(dplyr::select(rownames_to_column(as.data.frame(rstandard(model)) , var = "effect"), effect, resid, z), rraw = resid, rstandard = z)
  model_fitted_resid <- dplyr::full_join(model_fitted, model_resid, by = "effect")
  x <- seq(-5, 5, by = 0.05)
  normfunct <- function(x){(1/(1*sqrt(2*pi)))*exp((-1/2)*(((x - 0)/1)^2))}
  y <- normfunct(x = x)
  xynorm <- as.tibble(cbind(x, y))
  density.plot <- ggplot2::ggplot(data = model_resid) + geom_density(mapping = aes(x= rstandard), alpha = 0.8, fill= "#589E9E", color = "#589E9E", size = 0) + scale_x_continuous(limits = c(-5, 5)) + geom_line(data = xynorm, mapping = aes(x = x, y = y)) + theme_minimal()
  resid_fitted_plot <- ggplot2::ggplot(data = NULL) + geom_point(data = model_fitted_resid, mapping = aes(x = fitted, y = rraw), color = "#589E9E", alpha = 0.6, size = 3) + labs(x = "Fitted Values", y = "rstandard") + theme_minimal()
  qqplot <- qqnorm(residuals(model))
  return(list(qqplot, density.plot,resid_fitted_plot))}


######################################################################
#Report table for regression with non-robust and robust statistics 
rmatib2 <- function(mod1, mod2, elabs, dp){
  meshuggah <- paste0('%.', dp, 'f')
  cbind(cbind(tanh(mod1$b), tanh(mod1$se), mod1$zval, mod1$pval, tanh(mod1$ci.lb), tanh(mod1$ci.ub), mod1$ddf) %>% as.data.frame() %>% rownames_to_column(var = "Effect_Description.p1") %>% rename(estimate = V1, se = V2, t = V3, p = V4, ci.l = V5, ci.u = V6, df = V7) %>% add_column(Effect_Description = elabs) %>% dplyr::select(Effect_Description, estimate, se, t, p, ci.l, ci.u, df), cbind(mod2$b, mod2$se, mod2$zval, mod2$pval, mod2$ci.lb, mod2$ci.ub, mod2$ddf) %>% as.data.frame() %>% rownames_to_column(var = "Effect_Description.p1") %>% rename(estimate.rbst = V1, se.rbst = V2, t.rbst = V3, p.rbst = V4, ci.l.rbst = V5, ci.u.rbst = V6, df.rbst = V7) %>% add_column(Effect_Description.rbst = elabs) %>% dplyr::select(Effect_Description.rbst, estimate.rbst, se.rbst, t.rbst, p.rbst, ci.l.rbst, ci.u.rbst, df.rbst)) %>% dplyr::select(Effect_Description, estimate, se, se.rbst, ci.l, ci.l.rbst, ci.u, ci.u.rbst, t, t.rbst, df, df.rbst, p, p.rbst) %>% rename(Effect = Effect_Description, "b" = estimate) %>% dplyr::mutate(p = report.p(p), p.rbst = report.p(p.rbst)) %>% mutate(across(c(2, 3, 4, 5, 6, 7, 8, 9, 10, 12), ~sprintf(meshuggah, round(.,100)))) %>% mutate(across(c(4, 6, 8, 10, 12, 14), ~sub("(.{0})(.*)", "\\1(\\2)", .))) %>% tidyr::unite("SE", se:se.rbst, sep= " ", remove = T) %>% tidyr::unite("CI.lower", ci.l:ci.l.rbst, sep= " ", remove = T) %>% tidyr::unite("CI.upper", ci.u:ci.u.rbst, sep= " ", remove = T) %>% tidyr::unite("t", t:t.rbst, sep= " ", remove = T) %>% tidyr::unite("df", df:df.rbst, sep= " ", remove = T) %>% tidyr::unite("p", p:p.rbst, sep= " ", remove = T) %>% mutate(across(c(4), ~sub("(.{0})(.*)", "\\1[\\2,", .))) %>% mutate(across(c(5), ~sub("(.*)", "\\1]", .))) %>% tidyr::unite("95% CI", CI.lower:CI.upper, sep= " ", remove = T)}

######################################################################
#Report table for regression with non-robust and robust statistics for ClubSandwich
rmatib2.cs <- function(mod1, mod2, elabs, dp){
  meshuggah <- paste0('%.', dp, 'f')
cbind(cbind(tanh(mod1$b), tanh(mod1$se), tanh(mod1$ci.lb), tanh(mod1$ci.ub), mod1$zval, mod1$ddf, mod1$pval) %>% as.data.frame() %>% rownames_to_column(var = "Effect_Description.p1") %>% rename(estimate = V1, se = V2, ci.l = V3, ci.u = V4, t = V5, df = V6, p = V7) %>% add_column(Effect_Description = elabs) %>% dplyr::select(Effect_Description, estimate, se, ci.l, ci.u,  t, df, p),

cbind(mod2$beta, mod2$SE, mod2$tstat, mod2$df_Satt, mod2$p_Satt) %>% as.data.frame() %>% rownames_to_column(var = "Effect_Description.p1") %>% rename(estimate.rbst = V1, se.rbst = V2, t.rbst = V3, df.rbst = V4, p.rbst = V5) %>% add_column(Effect_Description.rbst = elabs) %>% dplyr::select(Effect_Description.rbst, estimate.rbst, se.rbst, t.rbst, df.rbst, p.rbst) %>% dplyr::mutate(ci.l.rbst = (estimate.rbst - (qt(p = 0.025, df = df.rbst))*se.rbst), ci.u.rbst = (estimate.rbst + (qt(p = 0.025, df = df.rbst))*se.rbst)) %>% dplyr::select(Effect_Description.rbst, estimate.rbst, se.rbst, ci.l.rbst, ci.u.rbst, t.rbst, df.rbst, p.rbst)) %>% dplyr::select(Effect_Description, estimate, se, se.rbst, ci.l, ci.l.rbst, ci.u, ci.u.rbst, t, t.rbst, df, df.rbst, p, p.rbst) %>% rename(Effect = Effect_Description, "b" = estimate) %>% dplyr::mutate(p = report.p(p), p.rbst = report.p(p.rbst)) %>% mutate(across(c(2, 3, 4, 5, 6, 7, 8, 9, 10, 12), ~sprintf(meshuggah, round(.,100)))) %>% mutate(across(c(4, 6, 8, 10, 12, 14), ~sub("(.{0})(.*)", "\\1(\\2)", .))) %>% tidyr::unite("SE", se:se.rbst, sep= " ", remove = T) %>% tidyr::unite("CI.lower", ci.l:ci.l.rbst, sep= " ", remove = T) %>% tidyr::unite("CI.upper", ci.u:ci.u.rbst, sep= " ", remove = T) %>% tidyr::unite("t", t:t.rbst, sep= " ", remove = T) %>% tidyr::unite("df", df:df.rbst, sep= " ", remove = T) %>% tidyr::unite("p", p:p.rbst, sep= " ", remove = T) %>% mutate(across(c(4), ~sub("(.{0})(.*)", "\\1[\\2,", .))) %>% mutate(across(c(5), ~sub("(.*)", "\\1]", .))) %>% tidyr::unite("95% CI", CI.lower:CI.upper, sep= " ", remove = T)}



######################################################################
#Report table for leave-one-out analysis 
influence.apa <- function(tib, label){
jjj <- tib %>% dplyr::select(cluster_unit,rstudent, cooks.d, DFBETAS, leave1out, se, ci.lb, ci.ub, tval, pval) %>% dplyr::filter(abs(rstudent) >= 3 | abs(cooks.d) >= 1 | abs(DFBETAS) >= 1) %>% rename(effect = cluster_unit) %>% dplyr::left_join(., meta_tib, by = "effect") %>% dplyr::select(effect.2, year, effect.3, rstudent, cooks.d, DFBETAS, leave1out, se, ci.lb, ci.ub, tval, pval) %>% tidyr::unite("effect.p1", effect.2:year, sep = "") %>% tidyr::unite("effect", effect.p1:effect.3, sep = "") %>% dplyr::mutate(across(c(2:9), ~sprintf("%.2f", round(., 10))))  %>% dplyr::mutate(pval = report.p(pval)) %>% tidyr::unite("CI", ci.lb:ci.ub, sep= ", ", remove = T) %>% dplyr::mutate(across(c(7), ~sub("(.{0})(.*)", "\\1[\\2]", .))) %>% add_column(effect0 = c(1), .before = T) %>% add_column(effect00 = c(1:nrow(.)), .before = T) %>% rename(effect_size = effect)

if(nrow(jjj) > 1){
for(counter in 2:max(jjj$effect00)){
  jjj$effect0[which(jjj$effect00 == counter)] <- NA
}} 
jjj <- jjj %>% rename(effect = effect0)
jjj$effect[which(jjj$effect == 1)] <- label
jjj$effect[which(is.na(jjj$effect))] <- ""
return(dplyr::select(jjj, -effect00))}
```





```{r son_and_hur.2020}
son_and_hur.2020_tib <- c(
  "son_and_hur.2020a", 
  "son_and_hur.2020b") %>% data.frame() %>% rename(., effect = .) %>% add_column(
    effect.2 = c("Son and Hur,", "Son and Hur, "),
    effect_description = c("Total Math Talk - Fall MA", "Total Maths Talk - Spring MA"),
    effect_id = c("Overall_Overall", "Overall_Overall"),
    year = c(2020, 2020),
    effect.3 = c("a", "b"),
    country = c("US", "US"),
    study_id = c("son_and_hur.2020", "son_and_hur.2020"),
    design = c("Correlational", "Correlational"),
    design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational"), 
    SES = c("Low", "Low"),
    main_language = c("English", "English"),
    deliverer_type = c("Parent", "Parent"),
    mothers = c(1, 1),
    white = c(0.500, 0.500), 
    female = c(0.47826087, 0.47826087),
    child_age_study_start = c(1717.284, 1717.284),
    child_age_NT_start = c(NA, NA),
    child_age_NT_mid = c(1793.378, 1793.378),
    child_age_NT_end = c(NA, NA),
    child_age_MA = c(1793.378, 2067.315),
    NT_measure_time = c(17.5, 17.5),
    time_between_NT_mid_MA = c(0, 273.937),
    intervention_dosage = c(NA, NA),
    NT_context = c("Home", "Home"),
    MA_context = c("School", "School"),
    NT_type = c("Overall", "Overall"),
    NT_type.1 = c("Overall", "Overall"),
    NT_type.10 = c("Overall", "Overall"),
    NT_type.boonen = c("Combined"),
    MA_test = c("WJ_AP", "WJ_AP"),
    MA_measure = c("Overall", "Overall"),
    MA_measure2 = c("Overall", "Overall"),
    analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation"),
    controlled_variables = c(0, 0),
    r = c(0.27, 0.12),
    n = c(29, 29))




```


```{r ramani_et_al.2015}
ramani_et_al.2015_tib <- c(
  "ramani_et_al.2015a", 
  "ramani_et_al.2015b", 
  "ramani_et_al.2015c", 
  "ramani_et_al.2015d",
  "ramani_et_al.2015e",
  "ramani_et_al.2015f",
  "ramani_et_al.2015g",
  "ramani_et_al.2015h",
  "ramani_et_al.2015i",
  "ramani_et_al.2015j",
  "ramani_et_al.2015k",
  "ramani_et_al.2015l") %>% data.frame() %>% rename(., effect = .) %>% add_column(
    effect.2 = c("Ramani et al. ", "Ramani et al., ", "Ramani et al.,", "Ramani et al., ", "Ramani et al., ", "Ramani et al., ", "Ramani et al., ", "Ramani et al., ", "Ramani et al., ", "Ramani et al., ", "Ramani et al., ", "Ramani et al., "),
    effect_description = c("Counting and Number Identification - Verbal Counting", "Cardinality and Ordering  - Verbal Counting", "Counting and Number Identification - Number Identification", "Cardinality and Ordering - Number Identification", "Counting and Number Identification - Counting principles", "Cardinality and Ordering - Counting principles", "Counting and Number Identification - Enumeration and Cardinality", "Cardinality and Ordering - Enumeration and Cardinality", "Counting and Number Identification - Number Line Estimation", "Cardinality and Ordering - Number Line Estimation", "Counting and Number Identification - Magnitude Comparison", "Cardinality and Ordering - Magnitude Comparison"),
    effect_id = c("Overall_Counting", "Overall_Counting", "Overall_Number_Identification", "Overall_Number_Identification", "Overall_Counting", "Overall_Counting", "Overall_Cardinality", "Overall_Cardinality",  "Overall_Number_Line_Estimation",  "Overall_Number_Line_Estimation", "Overall_Quantity_Comparison", "Overall_Quantity_Comparison"),
    year = c(2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015),
    effect.3 = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l"),
    country = c("US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US"),
    study_id = c("ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015"),
    design = c("Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational"),
    design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational"), 
    SES = c("Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low"),
    main_language = c("English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English"),
    deliverer_type = c("Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver"),
    mothers = c(0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788),
    white = c(0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33), 
    female = c(0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6),
    child_age_study_start = c(1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75),
    child_age_NT_start = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    child_age_NT_mid = c(1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75),
    child_age_NT_end = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    child_age_MA = c(1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25),
    NT_measure_time = c(15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15),
    time_between_NT_mid_MA = c(10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5),
    intervention_dosage = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    NT_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
    MA_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
    NT_type = c("Counting_and_Number_Identificaton", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering"),
    NT_type.1 = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall"),
    NT_type.10 = c("Number_Identification", "Overall", "Number_Identification", "Overall", "Number_Identification", "Overall", "Number_Identification", "Overall", "Number_Identification", "Overall", "Number_Identification", "Overall"),
    NT_type.boonen = c("Combined", "Combined", "Combined", "Combined", "Combined", "Combined", "Combined", "Combined", "Combined", "Combined", "Combined", "Combined"),
    MA_test = c("Verbal_Counting", "Verbal_Counting", "Number_Identification", "Number_Identification", "Counting_Principles", "Counting_Principles", "Enumeration_and_Cardinality", "Enumeration_and_Cardinality", "Number_Line_Estimation", "Number_Line_Estimation", "Magnitude_Comparison", "Magnitude_Comparison"),
    MA_measure = c("Counting", "Counting", "Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Number_Line_Estimation", "Number_Line_Estimation", "Quantity_Comparison", "Quantity_Comparison"),
    MA_measure2 = c("Counting", "Counting", "Number_Sense", "Number_Sense", "Counting", "Counting", "Cardinality", "Cardinality", "Number_Sense", "Number_Sense", "Quantity_Comparison", "Quantity_Comparison"),
    analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order _orrelation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation"),
    controlled_variables = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
    r = c(-0.12, 0.11, -0.19, 0.10, 0.07, 0.17, -0.31, -0.03, 0.05, 0.37, 0.11, 0.39),
    n = c(33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33))
#ramani_et_al.2015_kable <- ramani_et_al.2015_tib %>% 
  #dplyr::mutate(dplyr::across(where(is.numeric), ~round(., 2))) %>% 
  #kable(format = "html", caption = "Ramani et al. (2015) effect sizes and associated inferential statistics", col.names = c("Effect id", "Effect Description", "Analysis", "Controlled variables","r", "n", "z", "Var of z", "SE of z", "Weight", "Lower CI for z", "Upper CI for z", "Var of r", "SE of r", "Lower CI for r", "Upper CI for r")) %>% kable_styling(full_width = T, position = "center") %>% row_spec(row = 0, extra_css = "border-bottom: 2px solid black;") #

```

```{r mutaf_yildiz et al.2018}
mutaf_yildiz_et_al.2018_tib <- c(
  "mutaf_yildiz_et_al.2018a", 
  "mutaf_yildiz_et_al.2018b"
  ) %>% data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Mutaf-Yildiz et al., ", "Mutaf-Yildiz et al., "),
      effect_description = c("NT during book reading - Calculation skill", "NT during Lego playing - Calculation skill"),
      effect_id = c("Overall_Calculation", "Overall_Calculation"),
      year = c(2018, 2018),
      effect.3 = c("a", "b"),
      country = c("BE", "BE"),
      study_id = c("mutaf_yildiz_et_al.2018", "mutaf_yildiz_et_al.2018"),
      design = c("Correlational", "Correlational"),
      design.2 = c("Cross_sectional_Correlational", "Cross_sectional_Correlational"), 
      SES = c("Middle", "Middle"),
      main_language = c("Dutch", "Dutch"),
      deliverer_type = c("Parent", "Parent"),
      mothers = c(0.682, 0.682),
      white = c(NA, NA), 
      female = c(0.454545455, 0.454545455),
      child_age_study_start = c(2060.01, 2060.01),
      child_age_NT_start = c(NA, NA),
      child_age_NT_mid = c(2060.01, 2060.01),
      child_age_NT_end = c(NA, NA),
      child_age_MA = c(2060.01, 2060.01),
      NT_measure_time = c(5, 5),
      time_between_NT_mid_MA = c(0, 0),
      intervention_dosage = c(NA, NA),
      NT_context = c("Home", "Home"),
      MA_context = c("Home", "Home"),
      NT_type = c("Overall", "Overall"),
      NT_type.1 = c("Overall", "Overall"),
      NT_type.10 = c("Overall", "Overall"),
      NT_type.boonen = c("Combined", "Combined"),
      MA_test = c("TediMath", "TediMath"),
      MA_measure = c("Calculation", "Calculation"),
      MA_measure2 = c("Calculation", "Calculation"),
      analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation"),
      controlled_variables = c(0, 0),
      r = c(-0.05, -0.35),
      n = c(44, 44)) 

```

```{r elliott_et_al.2017}
elliott_et_al.2017_tib <- c(
  "elliott_et_al.2017a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Elliott et al., "),
      effect_description = c("NT - TEMA-3"),
      effect_id = c("Overall_Overall"),
      year = c(2017),
      effect.3 = c("a"),
      country = c("US"),
      study_id = c("elliott_et_al.2017"),
      design = c("Correlational"),
      design.2 = c("Cross_sectional_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(1),
      white = c(0.89), 
      female = c(0.434782609),
      child_age_study_start = c(2116.928),
      child_age_NT_start = c(NA),
      child_age_NT_mid = c(2116.928),
      child_age_NT_end = c(NA),
      child_age_MA = c(2116.928),
      NT_measure_time = c(10),
      time_between_NT_mid_MA= c(0),
      intervention_dosage = c(NA),
      NT_context = c("Lab"),
      MA_context = c("Lab"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      NT_type.boonen = c("Combined"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.16),
      n = c(44))

```




```{r levine_et_al.2010}
levine_et_al.2010_tib <- c(
  "levine_et_al.2010a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Levine et al., "),
      effect_description = c("NT - Point-to-X"),
      effect_id = c("Overall_Cardinality"), 
      year = c(2010),
      effect.3 = c("a"),
      country = c("US"),
      study_id = c("levine_et_al.2010"),
      design = c("Correlational"),
      design.2 = c("Longitudinal_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Caregiver"),
      mothers = c(NA),
      white = c(0.704545455), 
      female = c(0.454545455),
      child_age_study_start = c(426.125),
      child_age_NT_start = c(426.125),
      child_age_NT_mid = c(669.625),
      child_age_NT_end = c(913.125),
      child_age_MA = c(1400.125),
      NT_measure_time = c(450),
      time_between_NT_mid_MA = c(730.5),
      intervention_dosage = c(NA),
      NT_context = c("Home"),
      MA_context = c("Unknown"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      NT_type.boonen = c("Combined"),
      MA_test = c("Point_to_X"),
      MA_measure = c("Cardinality"),
      MA_measure2 = c("Cardinality"),
      analysis = c("Zero Order Correlation"),
      controlled_variables = c(0),
      r = c(0.47),
      n = c(44))


```

```{r mix_et_al.2012}

####################################################################################################
#Converts pre post design to Standardised difference (for repeated measures)
d.rm <- function(m1, m2, s1, s2, r){
  ((m1-m2)*(sqrt(2*(1-r))))/sqrt(((s1^2)+(s2^2))-(2*r*s1*s2))
}

mix_et_al.2012_tib <- c(
  "mix_et_al.2012a", "mix_et_al.2012b", "mix_et_al.2012c",  "mix_et_al.2012d", "mix_et_al.2012e", "mix_et_al.2012f", "mix_et_al.2012g", "mix_et_al.2012h", "mix_et_al.2012i", "mix_et_al.2012j",
  "mix_et_al.2012k", "mix_et_al.2012l", "mix_et_al.2012m", "mix_et_al.2012n", "mix_et_al.2012o", "mix_et_al.2012p") %>% 
  data.frame() %>% rename(., effect = .) %>% add_column(
    effect.2 = c("Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., ", "Mix et al., "),
    n = c(12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12),
    tm1 =   c(8.67, 7.67, 8.67, 7.67, 5.08, 0.25, 5.08, 0.25, 6.33, 9.25, 6.33, 9.25, 3.91, 0.33, 3.91, 0.33),  
    ts1 =   c(6.13, 6.13, 6.13, 6.13, 0.90, 0.45, 0.90, 0.45, 3.67, 5.02, 3.67, 5.02, 2.36, 0.14, 2.36, 0.14), 
    tm2 =   c(7.92, 8.25, 9.92, 10.33, 5.00, 0.25, 4.92, 0.50, 6.67, 8.08, 6.92, 8.00, 3.58, 0.17, 3.75, 0.50),
    ts2 =   c(4.78, 5.33, 4.47, 4.33, 0.87, 0.45, 1.07, 0.23, 3.71, 3.74, 5.02, 4.92, 1.97, 0.11, 2.15, 0.80),
    cm1 =   c(5.25, 7.42, 5.25, 7.42, 4.17, 0.08, 4.17, 0.08, 5.25, 7.42, 5.25, 7.42, 4.17, 0.08, 4.17, 0.08),
    cs1 =   c(3.64, 3.95, 3.64, 3.95, 1.59, 0.28, 1.59, 0.28, 3.64, 3.95, 3.64, 3.95, 1.59, 0.28, 1.59, 0.28),
    cm2 =   c(6.17, 6.58, 8.08, 7.50, 3.83, 0.25, 3.75, 0.33, 6.17, 6.58, 8.08, 7.50, 3.83, 0.25, 3.75, 0.33),
    cs2 =   c(4.05, 3.33, 4.33, 4.78, 1.70, 0.45, 2.46, 0.48, 4.05, 3.33, 4.33, 4.78, 1.70, 0.45, 2.46, 0.48),
    r.pp =  c(0.50, 0.50, 0.67, 0.67, 0.95, 0.11, 0.57, -0.13, 0.61, 0.61, 0.70, 0.70, 0.81, -0.32, 0.94, 0.46)) %>% mutate(
      d.rm = ((tm2-tm1)*(sqrt(2*(1-r.pp))))/sqrt(((ts1^2)+(ts2^2))-(2*r.pp*ts1*ts2)), 
      d.ppc = ((tm2-tm1)-(cm2-cm1))/sqrt((((n-1)*(ts1^2)) + ((n-1)*(cs1^2)))/(n + n -2))) %>% add_column(
      effect_description = c("Counting - Counting aloud at session 3", "Counting - Counting disks at session 3", "Counting NT - Counting aloud at session 6", "Counting NT - Counting disks at session 6", "Counting NT - Cardinality 123 at session 3", "Counting NT - Cardinality 6 at session 3", "Counting NT - Cardinality 123 at session 6", "Counting NT - Cardinality 6 at session 6", "Cardinality NT - Counting aloud at session 3", "Cardinality  NT - Counting disks at session 3", "Cardinality  NT - Counting aloud at session 6", "Cardinality  NT - Counting disks at session 6", "Cardinality  NT - Cardinality 123 at session 3", "Cardinality  NT - Cardinality 6 at session 3", "Cardinality  NT - Cardinality 123 at session 6", "Cardinality NT - Cardinality 6 at session 6"),
      effect_id = c("Counting_Counting", "Counting_Counting", "Counting_Counting", "Counting_Counting", "Counting_Cardinality", "Counting_Cardinality", "Counting_Cardinality", "Counting_Cardinality", "Cardinality_Counting", "Cardinality_Counting", "Cardinality_Counting", "Cardinality_Counting", "Cardinality_Cardinality", "Cardinality_Cardinality", "Cardinality_Cardinality", "Cardinality_Cardinality"),
      year = c(2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012),
      effect.3 = c("a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p"),
      country = c( "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US"),
      study_id = c("mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012"),
      design = c("Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental"),
      design.2 = c("Experimental_PPC","Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC","Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC"), 
      SES = c("Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle"),
      main_language = c("English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English"),
      deliverer_type = c("Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter"),
      mothers = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      white = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
      female = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_study_start = c(1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9),
      child_age_NT_start = c(1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9),
      child_age_NT_mid = c(1325.4, 1325.4, 1335.9, 1335.9, 1325.4, 1325.4, 1335.9, 1335.9, 1325.4, 1325.4, 1335.9, 1335.9, 1325.4, 1325.4, 1335.9, 1335.9),
      child_age_NT_end = c( NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_MA = c(1335.9, 1356.9, 1335.9, 1356.9, 1335.9, 1356.9, 1356.9, 1335.9, 1335.9, 1356.9, 1335.9, 1356.9, 1335.9, 1356.9, 1356.9, 1335.9),
      NT_measure_time = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      time_between_NT_mid_MA = c(10.5, 10.5, 21, 21, 10.5, 10.5, 21, 21, 10.5, 10.5, 21, 21, 10.5, 10.5, 21, 21),
      intervention_dosage = c(21, 21, 42, 42, 21, 21, 42, 42, 21, 21, 42, 42, 21, 21, 42, 42),
      NT_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
      MA_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
      NT_type = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      NT_type.1 = c("Counting","Counting","Counting","Counting","Counting","Counting","Counting","Counting","Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality"),
      NT_type.10 = c("Counting","Counting","Counting","Counting","Counting","Counting","Counting","Counting","Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality"),
      NT_type.boonen = c("Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single", "Single"),
      MA_test = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      MA_measure = c("Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality"),
      MA_measure2 = c("Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality"),
      analysis = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      controlled_variables = c(1, 1, 1, 1, 1, 1,1, 1, 1, 1, 1, 1, 1, 1, 1, 1)) %>% mutate(r = d.ppc/(sqrt((d.rm^2)+4))) %>%  dplyr::select(effect,effect.2, effect_description, effect_id, year, effect.3,country, study_id, design, design.2, SES, main_language, deliverer_type, mothers, white, female, child_age_study_start, child_age_NT_start, child_age_NT_mid, child_age_NT_end, child_age_MA, NT_measure_time, time_between_NT_mid_MA, intervention_dosage, NT_context, MA_context, NT_type, NT_type.1, NT_type.10, NT_type.boonen, MA_test, MA_measure, MA_measure2, analysis, controlled_variables, r, n)


```



```{r susperreguy_and_davis_kean.2016}
susperreguy_and_davis_kean.2016_tib <- c(
  "susperreguy_and_davis_kean.2016a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Susperreguy and Davis-Kean, "),
      effect_description = c("Proportion of Cumulative Math Talk - TEMA-3"),
      effect_id = c("Overall_Overall"),
      year = c(2016),
      effect.3 = c("a"),
      country = c("US"),
      study_id = c("susperreguy_and_davis_kean.2016"),
      design = c("Correlational"),
      design.2 = c("Longitudinal_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(1),
      white = c(0.686), 
      female = c(0.314285714),
      child_age_study_start = c(1643.625),
      child_age_NT_start = c(1643.625),
      child_age_NT_mid = c(1647.125),
      child_age_NT_end = c(1650.625),
      child_age_MA = c(2008.875),
      NT_measure_time = c(240),
      time_between_NT_mid_MA = c(365.25),
      intervention_dosage = c(NA),
      NT_context = c("Home"),
      MA_context = c("Unknown"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      NT_type.boonen = c("Combined"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.17),
      n = c(33))

```

```{r casey_et_al.2018}
casey_et_al.2018_tib <- c(
  "casey_et_al.2018a", 
  "casey_et_al.2018b",
  "casey_et_al.2018c", 
  "casey_et_al.2018d", 
  "casey_et_al.2018e", 
  "casey_et_al.2018f", 
  "casey_et_al.2018g", 
  "casey_et_al.2018h") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Casey et al., ", "Casey et al., ", "Casey et al., ", "Casey et al., ", "Casey et al., ", "Casey et al., ", "Casey et al., ", "Casey et al., "),
      effect_description = c("Identify numerals NT - WJ Applied Problems at 4.5 yrs", "Identify numerals NT - WJ Applied Problems at 1st grade", "One-to-one counting NT - WJ Applied Problems at 4.5 yrs", "One-to-one counting NT - WJ Applied Problems at 1st grade", "Label sets NT - WJ Applied Problems at 4.5 yrs", "Label sets NT - WJ Applied Problems at 1st grade", "Sum of numerical supports NT - WJ Applied Problems at 4.5 yrs", "Sum of numerical supports NT - WJ Applied Problems at 1st grade"),
      effect_id = c("Number_Identification_Overall", "Number_Identification_Overall", "Counting_Overall", "Counting_Overall", "Cardinality_Overall", "Cardinality_Overall", "Overall_Overall", "Overall_Overall" ), 
      year = c(2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018),
      effect.3 = c("a", "b", "c", "d", "e", "f", "g", "h"),
      country = c("US", "US", "US", "US", "US", "US", "US", "US"),
      study_id = c("casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018"),
      design = c("Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational"),
      design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational"), 
      SES = c("Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle"),
      main_language = c("English", "English", "English", "English", "English", "English", "English", "English"),
      deliverer_type = c("Parent", "Parent", "Parent", "Parent", "Parent", "Parent", "Parent", "Parent"),
      mothers = c(1, 1, 1, 1, 1, 1, 1, 1),
      white = c(0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84), 
      female = c(0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45),
      child_age_study_start = c(NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_NT_start = c(NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_NT_mid = c(1095.75, 1095.75, 1095.75, 1095.75, 1095.75, 1095.75, 1095.75, 1095.75),
      child_age_NT_end = c(NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_MA = c(1643.625, 2374.125, 1643.625, 2374.125, 1643.625, 2374.125, 1643.625, 2374.125),
      NT_measure_time = c(10, 10, 10, 10, 10, 10, 10, 10),
      time_between_NT_mid_MA = c(547.875, 1278.375, 547.875, 1278.375, 547.875, 1278.375, 547.875, 1278.375),
      intervention_dosage = c(NA, NA, NA, NA, NA, NA, NA, NA),
      NT_context = c("Lab", "Lab", "Lab", "Lab", "Lab", "Lab", "Lab", "Lab"),
      MA_context = c("Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown"),
      NT_type = c("Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Overall", "Overall"),
      NT_type.1 = c("Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Overall", "Overall"),
      NT_type.10 = c("Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Overall", "Overall"),
      NT_type.boonen = c("Single", "Single", "Single", "Single", "Single", "Single", "Combined", "Combined"),
      MA_test = c("WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP"),
      MA_measure = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall"),
      MA_measure2 = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall"),
      analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation","Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation"),
      controlled_variables = c(0, 0, 0, 0, 0, 0, 0, 0),
      r = c(-0.02, -0.04, -0.01, 0.05, 0.30, 0.33, 0.06, 0.07),
      n = c(99, 99, 99, 99, 99, 99, 99, 99))

```



```{r thippana_et_al.2020}
thippana_et_al.2020_tib <- c(
  "thippana_et_al.2020a", 
  "thippana_et_al.2020b") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Thippana et al., ", "Thippana et al., "), 
      effect_description = c("Home NT proportion - TEMA-3 ", "Lab NT proportion - TEMA-3"),
      effect_id = c("Overall_Overall", "Overall_Overall"),
      year = c(2020, 2020),
      effect.3 = c("a", "b"),
      country = c(NA, NA),
      study_id = c("thippana_et_al.2020", "thippana_et_al.2020"),
      design = c("Correlational", "Correlational"),
      design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational"), 
      SES = c("Middle",  "Middle"),
      main_language = c("English", "English"),
      deliverer_type = c("Parent", "Parent"),
      mothers = c(0.94, 0.94),
      white = c(0.85, 0.85), 
      female = c(0.484536082, 0.484536082),
      child_age_study_start = c(1430.562, 1430.562),
      child_age_NT_start = c(NA, NA),
      child_age_NT_mid = c(1446.172, 1446.172),
      child_age_NT_end = c(NA, NA),
      child_age_MA = c(1492.442, 1492.442),
      NT_measure_time = c(30, 20),
      time_between_NT_mid_MA = c(46.27, 46.27),
      intervention_dosage = c(NA, NA),
      NT_context = c("Home", "Lab"),
      MA_context = c("Lab", "Lab"),
      NT_type = c("Overall", "Overall"),
      NT_type.1 = c("Overall", "Overall"),
      NT_type.10 = c("Overall", "Overall"),
      NT_type.boonen = c("Combined", "Combined"),
      MA_test = c("TEMA_3", "TEMA_3"),
      MA_measure = c("Overall", "Overall"),
      MA_measure2 = c("Overall", "Overall"),
      analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation"),
      controlled_variables = c(0, 0),
      r = c(0.20, 0.11),
      n = c(81, 81))

```

```{r gibson_et_al.2020}
gibson_et_al.2020_tib <- c(
  "gibson_et_al.2020a", 
  "gibson_et_al.2020b") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Gibson et al., ", "Gibson et al., "),
      effect_description = c("Small Number Book vs Control", "Large Number vs Control"),
      effect_id = c("Overall_Number_Knowledge", "Overall_Number_Knowledge"),
      year = c(2020, 2020),
      effect.3 = c("a", "b"),
      country = c("US", "US"),
      study_id = c("gibson_et_al.2020", "gibson_et_al.2020"),
      design = c("Experimental", "Experimental"),
      design.2 = c("Long_term_Experimental", "Long_term_Experimental"), 
      SES = c("Middle", "Middle"),
      main_language = c("English", "English"),
      deliverer_type = c("Parent", "Parent"),
      mothers = c(NA, NA),
      white = c(0.52, 0.52), 
      female = c(0.52, 0.52),
      child_age_study_start = c(1132.275, 1132.275),
      child_age_NT_start = c(1132.275, 1132.275),
      child_age_NT_mid = c(1148.77, 1148.77),
      child_age_NT_end = c(1165.265, 1165.265),
      child_age_MA = c(1165.265, 1165.265),
      NT_measure_time = c(NA, NA),
      time_between_NT_mid_MA = c(16.495, 16.495),
      intervention_dosage = c(32.99, 32.99),
      NT_context = c("Home", "Home"),
      MA_context = c("Lab", "Lab"),
      NT_type = c("Counting_and_Labelling", "Counting_and_Labelling"),
      NT_type.1 = c("Overall", "Overall"),
      NT_type.10 = c("Overall", "Overall"),
      NT_type.boonen = c("Combined", "Combined"),
      MA_test = c("Give_N", "Give_N"),
      MA_measure = c("Cardinality", "Cardinality"),
      MA_measure2 = c("Cardinality", "Cardinality"),
      analysis = c("Pairwise_t", "Pairwise_t"),
      controlled_variables = c(0, 0),
      r = c(0.3224328, 0.069597355),
      n = c(97, 97))

```

```{r silver_et_al.2021}
silver_et_al.2021_tib <- c(
  "silver_et_al.2021a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Silver et al., "),
      effect_description = c("NT - MA"),
      effect_id = c("Overall_Overall"),
      year = c(2021),
      effect.3 = c("a"),
      country = c("US"),
      study_id = c("silver_et_al.2021"),
      design = c("Correlational"),
      design.2 = c("Cross_sectional_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(0.95),
      white = c(0.8), 
      female = c(0.479674797),
      child_age_study_start = c(1430.562),
      child_age_NT_start = c(1430.562),
      child_age_NT_mid = c(1430.562),
      child_age_NT_end = c(1430.562),
      child_age_MA = c(1430.562),
      NT_measure_time = c(10),
      time_between_NT_mid_MA = c(0),
      intervention_dosage = c(NA),
      NT_context = c("Lab"),
      MA_context = c("Lab"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      NT_type.boonen = c("Combined"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.04),
      n = c(123))

```


```{r ogul_and_arnas.2021}
ogul_and_arnas.2021_tib <- c(
  "ogul_and_arnas.2021a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect.2 = c("Ogul and Arnas, "),
      effect_description = c("NT - TEMA-3"),
      effect_id = c("Overall_Overall"),
      year = c(2021),
      effect.3 = c("a"),
      country = c("TURKEY"),
      study_id = c("ogul_and_arnas.2021"),
      design = c("Correlational"),
      design.2 = c("Unknown"), 
      SES = c("Unknown"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(1),
      white = c(NA), 
      female = c(0.675),
      child_age_study_start = c(1715.153),
      child_age_NT_start = c(1715.153),
      child_age_NT_mid = c(1715.153),
      child_age_NT_end = c(NA),
      child_age_MA = c(NA),
      NT_measure_time = c(160.5),
      time_between_NT_mid_MA = c(NA),
      intervention_dosage = c(NA),
      NT_context = c("Home"),
      MA_context = c("School"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      NT_type.boonen = c("Combined"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.39),
      n = c(40))


```


```{r constructing_meta_tib}
meta_tib.p1 <- rbind(
  levine_et_al.2010_tib,
  mix_et_al.2012_tib,
  ramani_et_al.2015_tib,
  susperreguy_and_davis_kean.2016_tib,
  elliott_et_al.2017_tib, 
  casey_et_al.2018_tib,
  mutaf_yildiz_et_al.2018_tib, 
  son_and_hur.2020_tib,
  thippana_et_al.2020_tib, 
  gibson_et_al.2020_tib, 
  silver_et_al.2021_tib,
  ogul_and_arnas.2021_tib) 



meta_tib <- escalc(measure = "ZCOR", ri = r, ni = n, data = meta_tib.p1) %>% data.frame() %>% 
    mutate(
    effect = as.factor(effect),
    effect_description = as.character(effect_description),
    effect.2 = as.character(effect.2),
    effect.3 = as.character(effect.3),
    effect_id = as.factor(effect_id),
    year = as.numeric(year),
    country = as.factor(country),
    study_id = as.factor(study_id),
    design = as.factor(design),
    design.2 = as.factor(design.2),
    SES = as.factor(SES),
    main_language = as.factor(main_language),
    deliverer_type = as.factor(deliverer_type),
    mothers = as.numeric(mothers),
    white = as.numeric(white),
    female = as.numeric(female),
    child_age_study_start = as.numeric(child_age_study_start),
    child_age_NT_start = as.numeric(child_age_NT_start),
    child_age_NT_mid = as.numeric(child_age_NT_mid),
    child_age_NT_end = as.numeric(child_age_NT_end),
    child_age_MA = as.numeric(child_age_MA),
    NT_measure_time = as.numeric(NT_measure_time),
    time_between_NT_mid_MA = as.numeric(time_between_NT_mid_MA),
    intervention_dosage = as.numeric(intervention_dosage),
    NT_context = as.factor(NT_context),
    MA_context = as.factor(MA_context),
    NT_type = as.factor(NT_type),
    NT_type.1 = as.factor(NT_type.1),
    NT_type.10 = as.factor(NT_type.10),
    NT_type.boonen = as.factor(NT_type.boonen),
    MA_test = as.factor(MA_test),
    MA_measure = as.factor(MA_measure),
    MA_measure2 = as.factor(MA_measure2),
    analysis = as.factor(analysis),
    controlled_variables = as.numeric(controlled_variables),
    r = as.numeric(r),
    n = as.numeric(n)) %>% 
  dplyr::mutate(
    main_language = forcats::fct_relevel(main_language, "Dutch", "English"),
    NT_type.1 = forcats::fct_relevel(NT_type.1, "Cardinality", "Counting", "Number_Identification", "Overall"),
    NT_type.10 = forcats::fct_relevel(NT_type.10,"Cardinality", "Counting", "Number_Identification", "Overall"),
    NT_type.boonen = forcats::fct_relevel(NT_type.boonen, "Single", "Combined"),
    MA_context = forcats::fct_relevel(MA_context, "Home", "Lab", "School", "Unknown"),
    MA_measure = forcats::fct_relevel(MA_measure, "Calculation", "Cardinality", "Counting", "Number_Identification", "Number_Line_Estimation", "Quantity_Comparison", "Overall"),
    MA_measure2 = forcats::fct_relevel(MA_measure2, "Calculation", "Cardinality", "Counting", "Number_Sense", "Quantity_Comparison", "Overall"),
    NT_context = forcats::fct_relevel(NT_context, "Home", "Lab", "School"),
    deliverer_type = forcats::fct_relevel(deliverer_type, "Parent", "Experimenter", "Caregiver"))


#REPORT TABLE
#The number of effects in each study
num_eff_tib <- meta_tib %>% dplyr::select(study_id, year) %>% group_by(study_id) %>% summarise(effects = n()) %>% add_column(as.tibble(str_sub(.$study_id, - 4, - 1))) %>% rename(year = value) %>%  mutate(year = as.numeric(year)) %>% arrange(year) %>% dplyr::select(study_id, effects)
num_eff_tib %>% apa_table()

#Stem and leaf diagram
stem(meta_tib$yi) %>% summary()


#Export data 
#write.xlsx(meta_tib, "meta_tib.xlsx", overwrite = T)

#Summary table


meta_data <- meta_tib %>% dplyr::select(effect.2, year, effect.3, design, main_language,  NT_type.1,  MA_measure, NT_context, MA_context, child_age_NT_mid, time_between_NT_mid_MA, r, yi, n) %>% tidyr::unite("Effect.p1", effect.2:year, sep= "", remove = T) %>% tidyr::unite("Effect", Effect.p1:effect.3, sep= "", remove = T) %>% dplyr::mutate(across(8:10, ~sprintf("%.3f", round(., digits = 5)))) 


#write.xlsx(meta_data, "./data/meta_tib.xlsx", overwrite = T)
```


```{r random_effect_meta_analysis}
#Random-effect meta-analysis
re_meta_model <- rma(yi = yi, vi = vi, data = meta_tib, method  = "REML")
re_meta_model

#Forest Plot
forest(re_meta_model, addpred = T, header = T)

#Gosh Plot 
#plot(gosh(re_meta_model, subset = 20000), out = 10)

#RESULTS
# Fisher's z = 0.0596
```


```{r ml_meta_analysis}
#2-level model (This is basically an RE model)
ml_meta_model.2lre <- rma.mv(yi = yi, V = vi, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | effect)
ml_meta_model.2lre

#2-level meta-analysis (this is the one that I fitted before)
ml_meta_model.2l <- rma.mv(yi = yi, V = vi, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | study_id)
ml_meta_model.2l

#3-level meta-analysis
ml_meta_model.3l <- rma.mv(yi = yi, V = vi, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | study_id/effect)
ml_meta_model.3l

#Correlated 3-level meta-analysis (CHE)
#Estimate dependency 
correlations <- c(0.5, 0.95, 0.11, 0.26, 0.61, 0.81, 0.32, 0.67) %>% as.tibble() %>% rename(r = value) %>% mutate(abs.r = abs(r))
dr <- correlations$r %>% mean() %>% sqrt()


#Adjust the covariance structure 
v_CHE <- impute_covariance_matrix(meta_tib$vi, cluster = meta_tib$study_id, r = dr)

#CHE model
ml_meta_model.3lCHE <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE 


#DEPENDENCY SENSITIVITY ANALYSIS
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE.dep.data <- dependency(data = meta_tib, random = ~ 1 | study_id/effect, cluster = meta_tib$study_id, r = seq(0, 0.99, 0.01), b = 0)
ml_meta_model.3lCHE.dep.data 

ml_meta_model.3lCHE.dep.estimate.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data, mapping = aes(x = r_level)) + geom_line(mapping = aes(y = estimate)) +  scale_x_continuous(breaks = seq(0, 1, by = 0.25), expand = expansion(mult = c(0, 0.1))) + labs(x = "Correlation", y = "Estimate") + theme_apa()
ml_meta_model.3lCHE.dep.estimate.plot

ml_meta_model.3lCHE.dep.estimate_with_CI.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data, mapping = aes(x = r_level)) + geom_ribbon(data =ml_meta_model.3lCHE.dep.data, mapping = aes(ymin = ci.lb, ymax = ci.ub), fill = "#AFABAB") + geom_line(mapping = aes(y = estimate)) + scale_y_continuous(breaks = seq(-0.05, 0.28, by = 0.05)) +  scale_x_continuous(breaks = seq(0, 1, by = 0.25), expand = expansion(mult = c(0, 0.1))) + labs(x = "Correlation", y = "Estimate with 95% CI") + theme_apa()
ml_meta_model.3lCHE.dep.estimate_with_CI.plot

ml_meta_model.3lCHE.dep.se.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data) + geom_line(mapping = aes(x = r_level, y = se)) + scale_x_continuous(breaks=seq(0, 1, 0.2), expand = expansion(mult = c(0, 0.1))) + labs(x = "Correlation", y = "SE") + theme_apa()
ml_meta_model.3lCHE.dep.se.plot 

ml_meta_model.3lCHE.dep.tval.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data) + geom_line(mapping = aes(x = r_level, y = tval)) + scale_x_continuous(breaks=seq(0, 1, 0.2), expand = expansion(mult = c(0, 0.1))) + labs(x = "Correlation", y = "t-statistic") + theme_apa()
ml_meta_model.3lCHE.dep.tval.plot 

ml_meta_model.3lCHE.dep.pval.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data) + geom_line(mapping = aes(x = r_level, y = pval)) + scale_x_continuous(breaks=seq(0, 1, 0.2), expand = expansion(mult = c(0, 0.1))) + labs(x = "Correlation", y = "p-value") + theme_apa()
ml_meta_model.3lCHE.dep.pval.plot 

ml_meta_model.3lCHE.dep.lev2var.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data) + geom_line(mapping = aes(x = r_level, y = lev2var)) + scale_x_continuous(breaks=seq(0, 1, 0.2), expand = expansion(mult = c(0, 0.1))) + labs(x = "Correlation", y = "Level 2 variance") + theme_apa()
ml_meta_model.3lCHE.dep.lev2var.plot 

ml_meta_model.3lCHE.dep.lev3var.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data) + geom_line(mapping = aes(x = r_level, y = lev3var)) + scale_x_continuous(breaks=seq(0, 1, 0.2), expand = expansion(mult = c(0, 0.1))) + labs(x = "Correlation", y = "Level 2 variance") + theme_apa()
ml_meta_model.3lCHE.dep.lev3var.plot 

dependency_fig.1 <- ggarrange(ml_meta_model.3lCHE.dep.estimate.plot , ml_meta_model.3lCHE.dep.se.plot, ml_meta_model.3lCHE.dep.tval.plot, ml_meta_model.3lCHE.dep.pval.plot,labels = c("A", "B", "C", "D"), ncol = 2, nrow = 2, left = c(1, 1))
dependency_fig.1




dependency_fig.2.p1 <- plot_grid(ml_meta_model.3lCHE.dep.estimate.plot, ml_meta_model.3lCHE.dep.se.plot, ml_meta_model.3lCHE.dep.tval.plot, ml_meta_model.3lCHE.dep.pval.plot, labels = c('B', 'C', 'D', 'E'), label_size = 12, hjust = -0.5, align = "hv", scale = 1.01, ncol = 2, nrow = 2)
dependency_fig.2.p1 

dependency_fig.2.p2 <- plot_grid(ml_meta_model.3lCHE.dep.estimate_with_CI.plot, labels = c("A"), scale = 0.9)
dependency_fig.2.p2

dependency_fig.2 <- plot_grid(dependency_fig.2.p2, dependency_fig.2.p1, ncol = 1, nrow = 2)
dependency_fig.2


#----------------------------------------------------------------------------------------------------
#Forest plots
forest(ml_meta_model.3lCHE, addpred = T, header = T, slab = meta_tib$effect)

#----------------------------------------------------------------------------------------------------
#VARIANCE DISTRIBUTION
#Examine the variance distribution (how much variance in each level)
vardist <- vardist.3l(model = ml_meta_model.3lCHE, digits =  7)
#var.comp(ml_meta_model.3lCHE) %>% plot()

ICC_lev2 <- (vardist$variances[2] + vardist$variances[3])/ (vardist$variances[1] + vardist$variances[2] + vardist$variances[3])
ICC_lev3 <- (vardist$variances[3])/ (vardist$variances[1] + vardist$variances[2] + vardist$variances[3])

ICC_lev2
ICC_lev3


#ROBUST
#----------------------------------------------------------------------------------------------------
#METAFOR
ml_meta_model.3lCHE.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE , cluster = meta_tib$study_id, adjust = T, clubSandwich = T)

#ClubSandwich 
ml_meta_model.3lCHE.rbst.cs <- coef_test(ml_meta_model.3lCHE, vcov="CR2", cluster=meta_tib$study_id) 

#Comparing all the models
fitstats(re_meta_model, ml_meta_model.2lre, ml_meta_model.2l, ml_meta_model.3l, ml_meta_model.3lCHE)
#ml_meta_model.2lre > re_meta_model > ml_meta_model.3l > ml_meta_model.2l


V_CHE_metafor <- vcalc(vi = vi, cluster = meta_tib$study_id, rho = dr, data = meta_tib, obs = meta_tib$effect)
v_CHE



#Report table 
rmatib2(mod1 = ml_meta_model.3lCHE, mod2 = ml_meta_model.3lCHE.rbst.metafor, elabs = c("Intercept"), dp = 2)



#INFLUENCE CHECKS
#----------------------------------------------------------------------------------------------------
#Effect level
#Beta 0
ml_meta_model.3lCHE.influence <- rma.mv.influence(random = ~1 | study_id/effect, struct = "CS", data = meta_tib, method = "REML", cluster = "effect", CHE = TRUE, r = dr, robust.cluster = "study_id", robust = F) %>% filter(abs(rstudent) > 3) %>% dplyr::select(-model.F, -model.F.p, -model.bic, -model.aicc, -sig)
ml_meta_model.3lCHE.influence %>% dplyr::filter(abs(rstudent) > 3) 
#Based on Cook's d, there are no influential cases



```

```{r metaSEM}
#Fitting a 3-level meta-analysis (Cheung, 2019) using metaSEM 
#Does not run, don't know why 
#meta3(y = yi, v = vi, cluster = study_id, data = meta_tib) %>%  summary()

#Compare with 3 level meta-analysis with metafor 
#TO COMPARE THEM, SET METHOD TO ML IN METAFOR, BECAUSE METASEM USES ML
#meta3(y = yi, v = vi, cluster = study_id, data = meta_tib) 
ml_meta_model.3lCHE

```






```{r moderator_analysis_NT_type.1}
#Checking the levels for NT_type.1
levels(meta_tib$NT_type.1)

#Setting contrast weights (deviation coding)
cardinalityNT_vs_mean           <- c(0.5, 0, 0, -0.5)          
countingNT_vs_mean              <- c(0, 0.5, 0, -0.5)      
number_identificationNT_vs_mean <- c(0, 0, 0.5, -0.5) 

contrasts(meta_tib$NT_type.1) <- cbind(
  cardinalityNT_vs_mean,
  countingNT_vs_mean,
  number_identificationNT_vs_mean)

#contrasts(meta_tib$NT_type.1) <- contr.sum(10) - This is for sum coding - The p-values/results are all the same as deviation coding


#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_NT_type.1 <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                            mods = ~ NT_type.1,
                                      random = ~ 1 | study_id/effect)


#ASSUMPTION
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_NT_type.1)
#RESULTS 

#NORMALITY OF RESIDUALS 
#Residuals are not normally distributed 

#HETEROSCEDASTICITY 
#Variance is fair 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: Robust it

#ROBUST
#----------------------------------------------------------------------------------------------------
#ROBUST SE
#METAFOR::ROBUST
ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_NT_type.1 , cluster=meta_tib$study_id, adjust = F, clubSandwich = F)
ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor


#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_NT_type.1.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_NT_type.1, vcov="CR2", cluster=meta_tib$study_id)
ml_meta_model.3lCHE_mod_NT_type.1.rbst.cs



#BONFERRONI CORRECTION
#----------------------------------------------------------------------------------------------------
bonferroni <- function(model){
  tib1 <- filter(add_column(rename(rownames_to_column(as.data.frame(model$beta), var = "comparison"), estimate = V1), rename(as.tibble(model$pval), pval = value)), comparison != "intrcpt")
  tib2 <- dplyr::select(mutate(tib1, bonferroni.pval = pval*nrow(tib1), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, "**", "*"), "ns"), sig.2 = ifelse(bonferroni.pval <= 0.05, ifelse(bonferroni.pval <= 0.01, "**", "*"), "ns")), comparison, estimate, pval, sig, bonferroni.pval, sig.2)
  return(tib2)
}




#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL
#Beta 1
ml_meta_model.3l_mod_NT_type.1_influence.lev2.b1 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ NT_type.1, random = ~1 | study_id/effect, cluster = "effect", b = 1, robust = T, robust.cluster = "study_id",adjust = T, CHE = TRUE, r = dr, clubSandwich = T)
ml_meta_model.3l_mod_NT_type.1_influence.lev2.b1 %>% filter(abs(rstudent) >= 3 | abs(cooks.d) >= 1 | abs(DFBETAS) >= 1)

#Beta 2
ml_meta_model.3l_mod_NT_type.1_influence.lev2.b2 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ NT_type.1, random = ~1 | study_id/effect, cluster = "effect", b = 2, robust = T, robust.cluster = "study_id",adjust = T, CHE = TRUE, r = dr, clubSandwich = T)
ml_meta_model.3l_mod_NT_type.1_influence.lev2.b2 %>% filter(abs(rstudent) >= 3 | abs(cooks.d) >= 1 | abs(DFBETAS) >= 1)


#Beta 3
ml_meta_model.3l_mod_NT_type.1_influence.lev2.b3 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ NT_type.1, random = ~1 | study_id/effect, cluster = "effect", b = 3, robust = T, robust.cluster = "study_id",adjust = T, CHE = TRUE, r = dr, clubSandwich = T)
ml_meta_model.3l_mod_NT_type.1_influence.lev2.b3 %>% filter(abs(rstudent) >= 3 | abs(cooks.d) >= 1 | abs(DFBETAS) >= 1)




#REPORT TABLE
#----------------------------------------------------------------------------------------------------
#Regression table 
NT_type.tab <- rmatib2(mod1 = ml_meta_model.3lCHE_mod_NT_type.1, mod2 = ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor, elabs = c("Intercept", "Cardinality", "Counting", "Number Identification"), dp = 2)
NT_type.tab


#Influence table 
ml_meta_model.3l_mod_NT_type.1_influence.lev2.b1


influence.NT_type.b1 <- influence.apa(ml_meta_model.3l_mod_NT_type.1_influence.lev2.b1, label = "b1") %>% dplyr::select(-tval)
influence.NT_type.b2 <- influence.apa(ml_meta_model.3l_mod_NT_type.1_influence.lev2.b2, label = "b2") %>% dplyr::select(-tval)
influence.NT_type.b3 <- influence.apa(ml_meta_model.3l_mod_NT_type.1_influence.lev2.b3, label = "b3") %>% dplyr::select(-tval)

influence.NT_type <- rbind(influence.NT_type.b1, influence.NT_type.b2, influence.NT_type.b3)




#Other functions
influence.apa.cs <- function(tib, label, df){
jjj <- tib %>% dplyr::select(cluster_unit,rstudent, cooks.d, DFBETAS, leave1out, se, t, df, p) %>% dplyr::filter(abs(rstudent) >= 3 | abs(cooks.d) >= 1 | abs(DFBETAS) >= 1) %>% rename(effect = cluster_unit) %>% dplyr::left_join(., meta_tib, by = "effect") %>% dplyr::select(effect.2, year, effect.3, rstudent, cooks.d, DFBETAS, leave1out, se, t, df, p) %>% tidyr::unite("effect.p1", effect.2:year, sep = "") %>% tidyr::unite("effect", effect.p1:effect.3, sep = "") %>% dplyr::mutate(ci.lb = (leave1out - (qt(p = 0.025, df = df)*se)), ci.ub = (leave1out + (qt(p = 0.025, df = df)*se))) %>% dplyr::select(effect, rstudent, cooks.d, DFBETAS, leave1out, se, ci.lb, ci.ub, t, p) %>% dplyr::mutate(across(c(2:9), ~sprintf("%.2f", round(., 10))))  %>% dplyr::mutate(p = report.p(p)) %>% tidyr::unite("CI", ci.lb:ci.ub, sep= ", ", remove = T) %>% dplyr::mutate(across(c(7), ~sub("(.{0})(.*)", "\\1[\\2]", .))) %>% add_column(effect0 = c(1), .before = T) %>% add_column(effect00 = c(1:nrow(.)), .before = T) %>% rename(effect_size = effect)

if(nrow(jjj) > 1){
for(counter in 2:max(jjj$effect00)){
  jjj$effect0[which(jjj$effect00 == counter)] <- NA
}} 
jjj <- jjj %>% rename(effect = effect0)
jjj$effect[which(jjj$effect == 1)] <- label
jjj$effect[which(is.na(jjj$effect))] <- ""
return(dplyr::select(jjj, -effect00))}

```



```{r MA_type}
#Checking the levels for MA_measure
levels(meta_tib$MA_measure)

#Setting contrast weights (deviation coding)
calculationMA_vs_mean <-             c(0.5, 0, 0, 0, 0, 0, -0.5)
cardinalityMA_vs_mean <-             c(0, 0.5, 0, 0, 0, 0, -0.5)
countingMA_vs_mean <-                c(0, 0, 0.5, 0, 0, 0, -0.5)
number_identificationMA_vs_mean <-   c(0, 0, 0, 0.5, 0, 0, -0.5) 
number_line_estimation_MA_vs_mean <- c(0, 0, 0, 0, 0.5, 0, -0.5)
quantity_comparisonMA_vs_mean <-     c(0, 0, 0, 0, 0, 0.5, -0.5)

contrasts(meta_tib$MA_measure) <- cbind(
  calculationMA_vs_mean, 
  cardinalityMA_vs_mean,
  countingMA_vs_mean,
  number_identificationMA_vs_mean,
  number_line_estimation_MA_vs_mean,
  quantity_comparisonMA_vs_mean)



#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
#3-level model
ml_meta_model.3lCHE_mod_MA_measure <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                      mods = ~ MA_measure, 
                                      random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_MA_measure


#ASSUMPTIONS 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_MA_measure)



#ROBUST
#----------------------------------------------------------------------------------------------------
#Sensitivity test with robust SE
ml_meta_model.3lCHE_mod_MA_measure

#ROBUST SE
#METAFOR::ROBUST
#l_meta_model.3lCHE_mod_MA_measure.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_MA_measure , cluster=meta_tib$study_id, adjust = T, clubSandwich = TRUE)
#ml_meta_model.3lCHE_mod_MA_measure.rbst.metafor 

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_MA_measure.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_MA_measure, vcov="CR2", cluster=meta_tib$study_id)
ml_meta_model.3lCHE_mod_MA_measure.rbst.cs


#REPORT TABLE
#----------------------------------------------------------------------------------------------------
#Regression 
MA_type_tab <- rmatib2.cs(mod1 = ml_meta_model.3lCHE_mod_MA_measure, mod2 = ml_meta_model.3lCHE_mod_MA_measure.rbst.cs, elabs = c("Intercept","Calculation", "Cardinality", "Counting", "Number Identification", "Number Line Estimation", "Quantity Comparison"), dp = 2)
MA_type_tab 




#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL 
#Beta 1
ml_meta_model.3l_mod_MA_measure.influence.b1 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 1, adjust = T)
ml_meta_model.3l_mod_MA_measure.influence.b1

ml_meta_model.3l_mod_MA_measure.influence.b2 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 2, adjust = T)
ml_meta_model.3l_mod_MA_measure.influence.b2

ml_meta_model.3l_mod_MA_measure.influence.b3 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 3, adjust = T)
ml_meta_model.3l_mod_MA_measure.influence.b3

ml_meta_model.3l_mod_MA_measure.influence.b4 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 4, adjust = T)
ml_meta_model.3l_mod_MA_measure.influence.b4

ml_meta_model.3l_mod_MA_measure.influence.b5 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 5, adjust = T)
ml_meta_model.3l_mod_MA_measure.influence.b5

ml_meta_model.3l_mod_MA_measure.influence.b6 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 6, adjust = T)
ml_meta_model.3l_mod_MA_measure.influence.b6



#INFLUENCE REPORT TABLE 
#----------------------------------------------------------------------------------------------------
influence.MA_type.b1 <- influence.apa.cs(ml_meta_model.3l_mod_MA_measure.influence.b1, label = c("Calculation")) %>% dplyr::select(-t)
influence.MA_type.b2 <- influence.apa.cs(ml_meta_model.3l_mod_MA_measure.influence.b2, label = c("Cardinality")) %>% dplyr::select(-t)
influence.MA_type.b3 <- influence.apa.cs(ml_meta_model.3l_mod_MA_measure.influence.b3, label = c("Counting")) %>% dplyr::select(-t)
influence.MA_type.b4 <- influence.apa.cs(ml_meta_model.3l_mod_MA_measure.influence.b4, label = c("Number Identification")) %>% dplyr::select(-t)
influence.MA_type.b5 <- influence.apa.cs(ml_meta_model.3l_mod_MA_measure.influence.b5, label = c("Number Line Estimation")) %>% dplyr::select(-t)
influence.MA_type.b6 <- influence.apa.cs(ml_meta_model.3l_mod_MA_measure.influence.b6, label = c("Quantity Comparison")) %>% dplyr::select(-t)
influence.MA_type <- rbind(influence.MA_type.b1, influence.MA_type.b2, influence.MA_type.b3, influence.MA_type.b4, influence.MA_type.b5, influence.MA_type.b6)
influence.MA_type

```




```{r MA_context}
#Checking the levels for MA context
levels(meta_tib$MA_context)

#Checking the data 
meta_tib %>% group_by(MA_context) %>% summarise(n = n())

#Setting contrast weights 
home_vs_mean <-   c(0.5, 0, 0, -0.5)
lab_vs_mean <-    c(0, 0.5, 0, -0.5)
school_vs_mean <- c(0, 0, 0.5, -0.5)

contrasts(meta_tib$MA_context) <- cbind(
  home_vs_mean,
  lab_vs_mean,
  school_vs_mean)


#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
#3-level model
ml_meta_model.3lCHE_mod_MA_context <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                       mods = ~ MA_context, 
                                       random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_MA_context


#ASSUMPTION 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_MA_context)
#RESULTS 

#NORMALITY OF RESIDUALS 
#Residuals are not normally distributed 

#HETEROSCEDASTICITY 
#Variance is heteroscedastic 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: Robust it 


#ROBUST
#----------------------------------------------------------------------------------------------------
#ROBUST SE
#METAFOR
ml_meta_model.3lCHE_mod_MA_context.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_MA_context, cluster=meta_tib$study_id, adjust = T, clubSandwich = T)
ml_meta_model.3lCHE_mod_MA_context.rbst.metafor

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_MA_context.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_MA_context, vcov = "CR2", cluster = meta_tib$study_id)



#REPORT TABLE
MA_context_tab <- rmatib2(mod1 = ml_meta_model.3lCHE_mod_MA_context, mod2 = ml_meta_model.3lCHE_mod_MA_context.rbst.metafor, elabs = c("Intercept","Home", "Lab", "School"), dp = 2)


#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL 
#Beta 1
#ml_meta_model.3l_mod_MA_context.influence.b1 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ MA_context, random = ~1 | study_id/effect, cluster = "effect", b = 1, robust = T, robust.cluster = "study_id",adjust = T, CHE = TRUE, r = dr, clubSandwich = T)
#ml_meta_model.3l_mod_MA_context.influence.b1


#Beta 2
#ml_meta_model.3l_mod_MA_context.influence.b2 <-  rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ MA_context, random = ~1 | study_id/effect, cluster = "effect", b = 2, robust = T, robust.cluster = "study_id",adjust = T, CHE = TRUE, r = dr, clubSandwich = T)
#ml_meta_model.3l_mod_MA_context.influence.b2  %>% dplyr::filter(abs(rstudent) > 3| abs(cooks.d) > 1 | abs(DFBETAS) > 1)


#Beta 3
#ml_meta_model.3l_mod_MA_context.influence.b3 <-  rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ MA_context, random = ~1 | study_id/effect, cluster = "effect", b = 3, robust = T, robust.cluster = "study_id",adjust = T, CHE = TRUE, r = dr, clubSandwich = T)
#ml_meta_model.3l_mod_MA_context.influence.b3  %>% dplyr::filter(abs(rstudent) > 3| abs(cooks.d) > 1 | abs(DFBETAS) > 1)


#INFLUENCE REPORT 
#----------------------------------------------------------------------------------------------------

#influence.MA_context.b2 <- influence.apa(ml_meta_model.3l_mod_MA_context.influence.b2, label = "b2") %>% dplyr::select(-tval)
#influence.MA_context.b3 <- influence.apa(ml_meta_model.3l_mod_MA_context.influence.b3, label = "b3") %>% dplyr::select(-tval)

#influence.MA_context <- rbind(influence.MA_context.b1, influence.MA_context.b2, influence.MA_context.b3)

```




```{r moderator_analysis_child_age_NT_mid}

#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_child_age_NT_mid <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                                mods = ~ child_age_NT_mid, 
                                                random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_child_age_NT_mid

regplot(ml_meta_model.3lCHE_mod_child_age_NT_mid, xlab = "Child Age During Number Talk (Days)")


#ASSUMPTION 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_child_age_NT_mid)



#ROBUST
#----------------------------------------------------------------------------------------------------
#METAFOR
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.metafor <- robust(ml_meta_model.3lCHE_mod_child_age_NT_mid, cluster = meta_tib$study_id, adjust = T, clubSandwich = T)
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.metafor

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_child_age_NT_mid, vcov = "CR2", cluster=meta_tib$study_id)
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.cs



#REGRESSION REPORT 
#----------------------------------------------------------------------------------------------------
child_age_during_NT <- rmatib2(mod1 = ml_meta_model.3lCHE_mod_child_age_NT_mid, mod2 = ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.metafor, elabs = c("Intercept","Child Age During NT"), dp = 2)
child_age_during_NT

#INFLUENCE
#---------------------------------------------------------------------------------------------------
#EFFECT LEVEL 
#Beta 1
ml_meta_model.3l_mod_child_age_NT_mid.influence.b1 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ child_age_NT_mid, random = ~1 | study_id/effect, cluster = "effect", b = 1, robust = F, CHE = TRUE, r = dr, robust.cluster = "study_id")
ml_meta_model.3l_mod_child_age_NT_mid.influence.b1

#INFLUENCE REPORT 
#---------------------------------------------------------------------------------------------------
#influence.child_age_NT_mid.b1 <- influence.apa(ml_meta_model.3l_mod_child_age_NT_mid.influence.b1, label = "Child Age During NT") %>% dplyr::select(-tval)

meta_tib
qplot(child_age_NT_mid, yi, data = meta_tib)



#FURTHER ANALYSIS: EXPONENTIAL DECAY
#---------------------------------------------------------------------------------------------------
exponential_decay <- ggplot(data = meta_tib, mapping = aes(x = child_age_NT_mid, y = tanh(yi))) + geom_point() + stat_smooth(method = "lm",  formula = "y ~ log(x)", color = "black", span = 2) + scale_x_continuous(breaks = seq(700, 2500, by = 200), expand = expansion(mult = c(0.008, 0.02))) + labs(x = "Child Age During NT (Days)", y = "Correlation") + theme_apa()
exponential_decay
ggplot(data = meta_tib, mapping = aes(x = child_age_NT_mid, y = yi)) + geom_point() + stat_smooth(method = "lm") + theme_apa()

exponential_decay

```

```{r time_lag}
#MODERATOR ANALYSIS
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_time_lag <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                       mods = ~ time_between_NT_mid_MA, 
                                       random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_time_lag 

regplot(ml_meta_model.3lCHE_mod_time_lag)

#ASSUMPTION
#----------------------------------------------------------------------------------------------------
assumption(ml_meta_model.3lCHE_mod_time_lag)

#ROBUST
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_time_lag.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_time_lag, cluster = meta_tib$study_id, adjust = T, clubSandwich = T)
ml_meta_model.3lCHE_mod_time_lag.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_time_lag, vcov = "CR2")
ml_meta_model.3lCHE_mod_time_lag.rbst.metafor 
ml_meta_model.3lCHE_mod_time_lag.rbst.cs



#REPORT TABLE
#----------------------------------------------------------------------------------------------------
time_lag_tab <- rmatib2(mod1 = ml_meta_model.3lCHE_mod_time_lag, mod2 = ml_meta_model.3lCHE_mod_time_lag.rbst.metafor, elabs = c("Intercept","Time Lag"), dp = 2)


#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL 
#Beta 1
ml_meta_model.3l_mod_time_between_NT_mid_MA.b1 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ time_between_NT_mid_MA, random = ~1 | study_id/effect, cluster = "effect", b = 1, robust = F, CHE = TRUE, r = dr, robust.cluster = "study_id")
ml_meta_model.3l_mod_time_between_NT_mid_MA.b1 %>% dplyr::filter(abs(rstudent) >= 3 | abs(cooks.d) >= 1 | abs(DFBETAS) >= 1)
#There were no outliers or influential cases
```



```{r publication_bias}
#Funnel plot
#----------------------------------------------------------------------------------------------------
metafor::funnel(ml_meta_model.3lCHE)

#Egger's test
#----------------------------------------------------------------------------------------------------
#Create the data for Egger's regression 
meta_tib_egger <- meta_tib %>% mutate(se = sqrt(vi), snd = yi/se, inv.se = 1/se)

egger_metafor <- metafor::rma.mv(yi = snd, V = vi, mods = inv.se, data = meta_tib_egger, random = ~ 1 | study_id/effect) 
egger_metafor

regplot(egger_metafor)



#Vevea and Wood (2005)
#----------------------------------------------------------------------------------------------------
weightfunct(effect = meta_tib$yi, v = meta_tib$vi, steps=c(0.05, 0.20, 1), weights = c(1, 0.7, 0.5))


#Negative selection 
weightfunct(effect = meta_tib$yi, v = meta_tib$vi, steps=c(0.5, 0.975, 1.00), weights = c(0.3, 0.6, 1), fe = F, table = T)

cntr.fctr <- (ml_meta_model.3lCHE$b - re_meta_model$b) %>% c()

meta_tib_weightr.cntr <-  meta_tib %>% mutate(yi.cntr = yi + cntr.fctr)
meta_tib_weightr.cntr

re_meta_model_weightr.cntr <-  rma(yi = yi.cntr, vi = vi, data = meta_tib_weightr.cntr)
re_meta_model_weightr.cntr


#Modelling moderate negative selection bias 
mod_neg <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.95, 1.00), weights = c(0.5, 1), fe = F, table = T)
mod_neg
mod_neg.report <- rd(tanh(mod_neg$adj_est[2]), digits = 2)

#Modelling severe negative selection bias
sev_neg <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.95, 1.00), weights = c(0.2, 1), fe = F, table = T)
sev_neg
sev_neg.report <- rd(tanh(sev_neg$adj_est[2]), digits = 2)

mod_pos <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.05, 1), weights = c(1, 0.5), fe = F, table = T)
mod_pos
mod_pos.report <- rd(tanh(mod_pos$adj_est[2]), digits = 2)

#Modelling severe negative selection bias
sev_pos <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.05, 1), weights = c(1, 0.2), fe = F, table = T)
sev_pos.report <- rd(tanh(sev_pos$adj_est[2]), digits = 2)



#REPORT
mod_neg.report
sev_neg.report
mod_pos.report
sev_pos.report

n.es.below.zero <- (nrow(dplyr::filter(dplyr::mutate(meta_tib, correlations = tanh(yi)), correlations < 0))/nrow(meta_tib))*100


```




# Abstract



# Introduction 
As science and mathematics are becoming more valued and relied on in today’s society, the demand for people with scientific and mathematical backgrounds has been increasing in the workforce (National Research Council, 2009). An increasing amount of focus has been drawn to meet this demand by fostering the essential scientific and mathematical skills in, encouraging, and improving accessibility for young ones.

Since early childhood experiences have been shown to impact later academic achievements (e.g. Duncan et al., 2007; Torpa et al., 2007), developmental science may have something to offer. The sociocultural theory (Vygotsky, 1978), a classic developmental theory, posits that the sociocultural context is instrumental for learning. More specifically, it suggests that guidance and the use of mediators, particularly language, in social interactions enable cognitive development more efficiently than learning independently. Accordingly, researchers began to examine sociocultural factors during early childhood that may be related to mathematical learning and preschool mathematical ability/attainment (MA). The Home Numeracy Environment (HNE; LeFevre et al., 2009) was of particular interest, most likely because the home is one of the few environments in which children spend a lot of time, others being nurseries or preschools. As this line of research became more refined, specific factors in the HNE were examined. Since exposure to language was found to predict literacy (e.g. Hart & Risley, 1992) and previous researchers have suggested that exposure to number words may develop children’s understanding of more abstract mathematical concepts (e.g. Mix et al., 2002; Wynn, 1990), researchers began to examine whether exposure to number talk (NT), that is number words spoken by an adult to children, would stimulate mathematical learning and predict later MA. Levine et al. (2010) was one of the first studies to examine this. They found that the amount of number words spoken by parents to their children in natural interactions when the children were between 14-30 months old was moderately associated with cardinal knowledge when the children were 46 months old. In addition, different types of NT have been identified. Types of NT are distinguished by the purpose for which number words are used (see A2). However, they only examined the overall effect of NT and not specific types of NT and suggested that future studies should investigate whether different types of NT are more effective. Following this promising finding, there was a steady flow of studies examining both the overall effect and the effects of different types of NT. However, findings were less promising. Some studies found much smaller effects that are also statistically nonsignificant. For example, Susperreguy and Davis-Kean (2016) and Elliott et al. (2017) found nonsignificant correlations of .17 and .16 respectively. This suggests that the true effect could be smaller than that estimated by Levine et al. (2010). Moreover, some studies even found negative effects. For example, Mutaf-Yildiz et al. (2018) found a correlation of -.35. These inconsistencies led to difficulties in concluding the effect of NT.

This brings us to the current study. The current study attempts to synthesise evidence from the NT literature through a meta-analysis. This synthesis attempts to determine whether or not the effect of NT is true and to estimate its true effect size with a greater precision and statistical power than any one of the individual studies in the NT literature. It also attempts to examine how consistent the current findings are and identify factors that may contribute to any inconsistencies, which could not be easily identified from any one of the individual studies. Lastly, it attempts to assess whether there was publication bias in the literature and determine the impact potential publication bias has on the true estimate as well as the literature as a whole. 



# Methods
## Search
Studies were searched through PsycInfo, PsycArticles, Scopus, ScienceDirect, and Web of Science with the same command `AB(("number* talk*") OR ("numer* talk*))`. The reference lists of identified studies were checked for studies not identified in the databases. All corresponding authors of the identified studies were enquired for unpublished data and ongoing studies through email. Ongoing studies were additionally searched through OSF.. 

## Selecting Effect Sizes 
The majority of the studies were correlational (k = 10) and the rest were experimental (k = 2), thus, Pearson’s correlation was used as the effect size for the meta-analysis. All effect sizes that represent the effect of NT on children’s MA were considered relevant and were included. Most studies had multiple relevant effects. Multiplicity arose from two sources, which were differences in effect specification (e.g. outcome measures) and differences in the type of statistical analysis (e.g. correlation or multiple regression with a different number of covariates). The first source of multiplicity could be dealt with by combining all relevant effect sizes as an average so that each study contributes only one effect size, or by including all relevant effect sizes from each study. The latter approach was chosen to enable moderator analyses. The second source of multiplicity was mainly from correlational studies in which studies provided effect sizes with a different number of covariates. Since most studies provided effect sizes without covariates and covariates differed across effect sizes and studies, only those without covariates were included to maintain comparability. Studies that did not provide effect sizes without covariates were excluded. A total of 49 effect sizes from 12 studies were included (data is available in the attached .csv file). The effect sizes were transformed to Fisher’s z for statistical analyses.

## Meta-analysis 
Since some studies included multiple effect sizes, a multilevel modelling approach was used to model the dependency and examine heterogeneity more accurately. A three-level hierarchical structure, in which sampling variances (level 1) were nested within effect sizes (level 2), and effect sizes were nested within studies (level 3) (Cheung, 2014, 2019; Assink & Wibbelink, 2016) was used. This model assumes that effect sizes within studies were independent of each other. However, effect sizes within each study were based on the same participants, hence, the model was extended to a correlated hierarchical effects model (Pustejovsky & Tipton, 2018, 2021), in which sampling variances of effect sizes within each study (level 1) in the three-level hierarchical structure were assumed to correlate with each other. The degree to which they correlate was estimated from an average of a series of correlations between outcome measures provided by a corresponding author of one of the included studies (Mix et al., 2012; r = .73). Most of the effect sizes within studies were cross-sectional, hence, compound symmetry was assumed. Lastly, constant sampling correlation (Pustejovsky & Tipton, 2021), that is having the same degree of correlation across all studies, was assumed as correlations between outcome measures could only be obtained from one study and there was no reason not to assume participants were not correlated to the same degree across studies. The sampling covariance structure was adjusted by the impute_covariance_matrix() function from the clubSandwich package (Pustejovsky, 2022). The three-level model was then fitted by the rma.mv() function from the metafor package (Viechtbauer, 2010) with Restricted Maximum Likelihood estimation. Since the sample size was small and there was dependency among effect sizes within studies, cluster robust standard error, specifically, ‘CR2’, and its associated results with small sample adjustment were estimated by the ‘robust()’ function from the metafor package and were examined for sensitivity analysis. The correlation used to estimate the sampling covariance structure was assumed and can change the results, hence, results at different levels of correlation were examined as a sensitivity analysis for sampling variance dependency. Outliers and influential cases were examined at the effect size level and they were indicated by having an absolute studentized residual larger than three and an absolute value of Cook’s distance or DEBETAS larger than one respectively. Leave-one-out analysis was conducted for outliers and/or influential cases as a sensitivity analysis.




## Publication bias
### Funnel Plot
Publication bias was first examined visually through the funnel plot (Light and Pillerner, 1984). The funnel plot shows the precision of estimation (SE) against its associated effect size. If effect sizes are symmetrical around the average given SE, it suggests no publication bias. On the other hand, asymmetry given SE shows there is an imbalance of studies reporting either larger or smaller effect sizes than average, which suggests publication bias.

### Egger's regression test
Small study bias was then examined. Small study bias is a type of publication bias in which small studies report more extreme effect sizes relative to larger studies. This can be tested by Egger’s regression test (Egger et al., 1997), which is a linear regression in which the standard normal deviate (SND) of the effect size is regressed against its precision. The SND is the standardised score of the effect size in the normal distribution under the null hypothesis (SNDi = ESi/sei) and its precision is its inverse SE (1/sei). When there is no publication bias, studies with a lower precision are expected to have an SND asymptotically closer to 0. Egger’s regression test tests this hypothesis by testing whether the intercept is zero, in other words, it tests whether the SND is zero when the inverse SE is zero. A non-significant intercept shows that there are no or very few studies with low precision that report more extreme SNDs relative to larger studies, which suggests no small study bias. On the other hand, a significant intercept shows that there are studies with low precision that report more extreme SNDs relative to larger studies, which suggests small study bias.

### Vevea and Woods' Selection Model
The impact of potential selection bias on this meta-analysis was assessed by Vevea and Woods’ (2005) selection model. Vevea and Wood’s (2005) selection model is a type of corrective method that estimates the average ‘corrected’ for specific patterns of selection bias based on statistical significance (i.e. p-values) using a weight function. Two specific patterns of selection bias based on statistical significance were examined. The first was indicated by the funnel plot and the second was determined a priori according to the hypothesised intention of the authors of the included studies. Each pattern was examined at a moderate and severe level. The model of selection bias determined a priori were: Moderate Upper-tail Selection Bias, in which effect sizes with p-values in the range 0 < p < .05 have a probability of 1 of being published and those in the range .05 < p < 1 have a probability of .50 of being published; and Severe Upper-tail Selection Bias, in which effect sizes with p-values in the range 0 < p < .05 have a probability of 1 of being published and those in the range .05 < p < 1 have a probability of .20 of being published. 


## Moderator Analysis
The effect sizes were coded for potential moderator variables. Although the reliability of coding was not assessed, the risk of error due to coding inaccuracies was minimised by only coding and examining moderators that were clearly described or defined within studies and were consistent across studies. Each potential moderator was then tested through a simple Generalised Least Squares mixed-effect linear regression model with random intercept and fixed slopes. The models were examined for any violations of assumptions of the General Linear Model (GLM) through the model residuals. Likewise, cluster robust SEs and their associated results with small sample adjustment were estimated and concluded if assumptions of the GLM were violated or examined as a sensitivity analysis if the assumptions were not violated. Outliers and influential cases were examined at the effect size level and were indicated as described previously. Similarly, a leave-one-out analysis was conducted for the outliers and/or influential cases as a sensitivity analysis.

```{r forest, echo = F, include = T, fig.cap= "Forest Plot", out.width="100%"}
png(file = "images/forest_plot2.png", res = 100, width = 1250, height = 1500, type = c("quartz"))
metafor::forest(ml_meta_model.3lCHE, slab=paste(meta_tib$effect.2, meta_tib$year, meta_tib$effect.3, sep=""), atransf = tanh,header = T, xlim=c(-3.5,2), cex = 1.2)
dev.off()
knitr::include_graphics("images/forest_plot2.png")
```

```{r}

  
reporta <- function(x, digits, leading = T){
  meshuggah <- paste0('%.', digits, 'f')
  
  if(isTRUE(leading)){sprintf(meshuggah, round(x,100))}
  else if(isFALSE(leading)){sub("^0+", "", sprintf(meshuggah, round(x,100)))}
  }

reporta(c(tanh(ml_meta_model.3lCHE$beta)), 3, leading = F)

Q.p <- report.p(ml_meta_model.3lCHE$QEp)

meta.p <- report.p(ml_meta_model.3lCHE$pval)

ml_meta_model.3lCHE
I_2 <- ((vardist$variances[2] + vardist$variances[3])/(vardist$variances[1] + vardist$variances[2] + vardist$variances[3]))*100


ml_meta_model.3lCHE.rbst.metafor
```

# Results
## Meta-analyis 
A forest plot is presented in figure 1. NT had a small and positive effect (*r* = `r reporta(c(tanh(ml_meta_model.3lCHE$beta)), 2, leading = F)`, *SE* = `r reporta(c(tanh(ml_meta_model.3lCHE$se)), 2, leading = T)`, 95% CI [`r reporta(c(tanh(ml_meta_model.3lCHE$ci.lb)), 2, leading = T)`, `r reporta(c(tanh(ml_meta_model.3lCHE$ci.ub)), 2, leading = T)`], *t*(`r reporta(c(ml_meta_model.3lCHE$ddf), 0, leading = T)`) = `r reporta(c(ml_meta_model.3lCHE$zval), 2, leading = T)`, *p* = `r meta.p`). There was a substantial amount of heterogeneity among effect sizes (*Q*(`r reporta(c(ml_meta_model.3lCHE$ddf), 0, leading = T)`) = `r reporta(c(ml_meta_model.3lCHE$QE), 2, leading = F)`, *p* `r Q.p`). The variance and intraclass correlation (ICC) were examined. The sampling variance was estimated using a method described in Higgins and Thompson (2002, equation 9) and the ICCs were estimated using a method described in Hox (2010, p.21). Regarding variances, levels one, two and three had variances of `r reporta(vardist$variances[1], 2, leading = T)`,`r reporta(vardist$variances[2], 2, leading = T)`, and `r reporta(vardist$variances[3], 2, leading = T)` respectively. 

This shows that most of the total variance was attributable to the true heterogeneity (*I^2^* = `r reporta(I_2, 2, leading = T)`%) and rest was attributable to sampling error. Further, all of the true heterogeneity was attributable to the effect size level and none was attributable to the study level. Regarding ICCs, levels two and three had ICCs of `r reporta(ICC_lev2, 2, leading = T)` and `r reporta(ICC_lev3, 2, leading = T)` respectively, which indicates that effect sizes within studies were strongly related to each other and studies were not related to each other.



```{r}
ml_meta_model.3lCHE.rbst.metafor$zval
```


Sensitivity analysis of sampling covariance shows that, comparing to a correlation of zero, that is assuming that sampling variances were independent, adjusting the sampling covariance for dependency led to a larger estimate (Figure 2A & 2B) and more conservative statistical significance (Figure 2A & E). The estimates (range = `r reporta(min(dplyr::select(dplyr::mutate(ml_meta_model.3lCHE.dep.data, estimate.r = tanh(estimate)), estimate.r)), 2, leading = F)` - `r reporta(max(dplyr::select(dplyr::mutate(ml_meta_model.3lCHE.dep.data, estimate.r = tanh(estimate)), estimate.r)), 2, leading = F)`) were consistently small and positive and significant regardless of dependency (Figure 2A, 2B, & 2E). Cluster robust SE and its associated results with small sample adjustment were examined as a sensitivity analysis. Results were consistent (*SE* = `r reporta(c(tanh(ml_meta_model.3lCHE.rbst.metafor$se)), 2, leading = T)`, *t*(`r reporta(ml_meta_model.3lCHE.rbst.metafor$ddf, 2, leading = T)`) = `r reporta(ml_meta_model.3lCHE.rbst.metafor$zval, 2, leading = T)`, *p* = `r report.p(ml_meta_model.3lCHE.rbst.metafor$pval)`). No outliers or influential cases were identified. To conclude, NT had a small and positive effect on children’s MA.
 
## Publication Bias
The funnel plot (Figure 3) shows asymmetry only for smaller studies, specifically, smaller studies more often report smaller effect sizes than larger studies and there is a lack of larger effect sizes among smaller studies, which suggests negative small study bias. Egger’s regression test shows that the intercept was negative but not significant (*b_0* = `r reporta(egger_metafor$beta[1], 2, leading = T)`, *SE* = `r reporta(egger_metafor$se[1], 2, leading = T)`, *t*(47) = `r reporta(egger_metafor$zval[1], 2, leading = T)`, *p* = `r report.p(egger_metafor$pval[1])`), which suggests a trend in negative study bias but might not be severe.


```{r dependency, echo = F, include = T, fig.cap= "Sensitivity Analysis for Dependency", out.width="100%"}


png(file = "images/dependency_fig.2.png", res = 100, width = 1000, height = 1100)
dependency_fig.2
dev.off()

knitr::include_graphics("images/dependency_fig.2.png")

```

The impact of potential selection bias based on statistical significance on the estimate was then examined by Vevea and Woods’ (2005) selection model. The pattern of selection bias hypothesised a priori was first examined. Results show that the effect size was reduced to `r mod_pos.report` and `r sev_pos.report` after correcting for Moderate and Severe Upper-tail Selection bias respectively. Since both funnel plot and Egger’s test indicated minor negative publication bias, the impact of negative selection bias based on p-values was examined at two levels: Moderate Lower-tail Selection Bias, in which effect sizes with .95 < p < 1 have a probability of 1 of being published and those with 0 < p < .95 have a probability of .50; and Severe Lower-tail Selection Bias, in which effect sizes with .95 < p < 1 have a probability of 1 of being published and those with 0 < p .95 have a probability of .20. Results suggest that the effect size was increased to `r mod_neg.report` and `r sev_neg.report` after correcting for Moderate and Severe Lower-tail Selection Bias respectively. Overall, the effect remains small and positive even after adjusting for either positive or negative selection biases based on statistical significance at two levels.


```{r funnel, echo = F, include = T, fig.cap= "Funnel Plot", out.width="70%"}
png(file = "images/funnel_plot1.png", res = 100, width = 700, height = 500)
metafor::funnel(ml_meta_model.3lCHE)
dev.off()

knitr::include_graphics("images/funnel_plot1.png")


```

## Moderator Analysis 
### NT Type
Some studies examined the effects of specific types of NT, meanwhile, others either examined the effects of multiple types of NT in combination or did not categorise the type of NT. Effect sizes for specific types of NT were coded for the type of NT according to the descriptions of the type of NT provided in the study and not their labels as labels for the same types of NT varied across studies. Three types of NT were identified: Cardinality, Counting, and Number Identification. Effect sizes that represent the effect of multiple types of NT in combination or an unknown type of NT were coded as ‘General’. The type of NT was entered into the regression as a categorical variable with deviation coding. Results suggest no effect of NT type (*F*(3, 45) = `r reporta(ml_meta_model.3lCHE_mod_NT_type.1$QM, 2, leading = T)`, *p* = `r report.p(ml_meta_model.3lCHE_mod_NT_type.1$QMp)`). None of the contrasts was significant (Table 1). Residual plots indicated that the assumption of homoscedasticity may not be met. Hence, cluster robust SE and its associated results with small sample adjustment were examined and concluded. Although the F-statistic was not available in the robust() function, the results for the contrasts were different. Compared to the average, Number Identification had a lower effect, meanwhile, Cardinality and Counting were not significantly different (Table 1). It also appears that Number Identification had a negative trend. There were two influential cases. Leave-one-out analysis for these influential cases shows that results for Cardinality and Counting were consistent in statistical significance, meanwhile, Number Identity had the same direction of effect but was non-significant after excluding either one of the two influential cases (A1). In sum, the effect of NT may be moderated by a specific type of NT, particularly, Number Identification had a smaller effect (and a negative trend) than other types of NT.


```{r table1, echo = FALSE, include = TRUE}
NT_type.tab %>% apa_table(., caption = "Effects of types of NT",  
          col.names = c("Effect", "$b$", "SE","95\\% CI", "t", "df","$p$"),
          escape = FALSE,
          note = "Cluster Robust SEs and associated results with small sample adjustment are in brackets",
          landscape = TRUE)
```




### MA Type
Outcome measures representing different types of MA on which the effect of NT was evaluated differed across effect sizes. Some studies evaluated the effect of NT on specific types of MA while others evaluated that on a combination of different types of MA. Effect sizes representing the effect of NT on specific types of MA were coded for their specific types of MA according to the description of the outcome measure within the papers. Six types of MA were identified: Calculation, Cardinality, Counting, Number Identification, Number Line Estimation, and Quantity Comparison. Effect sizes representing the effect of NT on several types of MA in combination were coded as ‘general’. MA type was entered into a simple regression as a categorical variable with deviation coding. Results indicated no effects of MA type (*F*(6, 42) = `r reporta(ml_meta_model.3lCHE_mod_MA_measure$QM, 2, leading = T)`, *p* = `r report.p(ml_meta_model.3lCHE_mod_MA_measure$QMp)`). However, the contrasts showed that, compared to the average, Quantity Comparison had a significantly larger effect and Calculation had a significantly lower (and negative) effect (Table 2). The model was examined for any violations of assumptions of the GLM. Residual plots suggest that the assumption of normality of residuals might not be met. Hence, cluster robust SEs and their associated results with small sample adjustments were examined and concluded. Results were consistent, in addition, Number Line Estimation had a significantly larger effect than average (Table 2). There were two influential cases. Leave-one-out analysis for the two influential cases shows that results for Counting, Number Identification, and Quantity Comparison were all consistent, meanwhile, Number Line Estimation had minor inconsistencies in terms of statistical significance, specifically, it was non-significant when one of the two influential cases was excluded (A2). In sum, the effect of NT may be moderated by specific types of MA, particularly, NT may have larger (and positive) effects on Quantity Comparison and Number Line Estimation but a smaller (and negative) effect on Calculation.

```{r table3, echo = FALSE,  include = TRUE}
MA_type_tab  %>% apa_table(., caption = "Effects of MA measures",  
          col.names = c("Effect", "$b$", "se","95\\% CI", "t", "df","$p$"),
          escape = FALSE,
          note = "Cluster Robust SEs and associated results with small sample adjustment are in brackets",
          landscape = TRUE)

```





### MA context
MA was measured in different contexts across studies. The effect sizes were coded for the context in which MA was measured according to the information provided in the studies. Some studies specified the context while others did not. For effect sizes with specified MA contexts, three MA contexts were identified: Home, Lab, and School. Effect sizes with unknown MA context were coded as ‘unknown’. MA context was entered into the regression as a categorical variable with deviation coding. Results indicated no effects of MA context (*F*(3, 45) = `r reporta(ml_meta_model.3lCHE_mod_MA_context$QM, 2, leading = T)`, *p* = `r report.p(ml_meta_model.3lCHE_mod_MA_context$QMp)`). None of the contrasts was significant (Table 4). The model was examined for any violations of assumptions of the GLM. Residual plots indicated that normality of residuals and homoscedasticity might not be met. Hence, cluster robust SEs and their associated results with small sample adjustment were examined and concluded. Results were consistent (F stats). However, results for the contrasts were different, specifically, compared to the average, measuring NT at home had a smaller (and negative) effect (Table 4). There were no outliers or influential cases. In sum, the effect of NT may be moderated by a specific context in which MA was measured, specifically, measuring MA at home may have a negative effect.






```{r table4 , echo = FALSE, include = TRUE}
MA_context_tab %>% apa_table(., caption = "Effects of MA context",  
          col.names = c("Effect", "$b$", "SE","95\\% CI", "t", "df","$p$"),
          escape = FALSE,
          note = "Cluster Robust SEs and associated results with small sample adjustment are in brackets",
          landscape = TRUE)

```



### Child Age
The age of children around which NT was delivered varied across studies. Child age during NT was defined as the mean age of the sample at the mid-point when NT was measured. Results indicated no effect of child age (*F*(1, 47) = `r reporta(ml_meta_model.3lCHE_mod_child_age_NT_mid$QM, 2, leading = T)`, *p* = `r report.p(ml_meta_model.3lCHE_mod_child_age_NT_mid$QMp)`; Table 5). The model was examined for any violations of assumptions of the GLM. Residual plots suggest that GLM assumptions were met. Nonetheless, cluster robust SEs and their associated results with small sample adjustment were examined for sensitivity analysis. Results were consistent (Table 5). There were no outliers or influential cases. In sum, the effect of NT may not be moderated by the children’s age during which NT was delivered.

```{r table5 , echo = FALSE, include = TRUE}
child_age_during_NT %>% apa_table(., caption = "Child Age During NT",  
          col.names = c("Effect", "$b$", "SE","95\\% CI", "t", "df","$p$"),
          escape = FALSE,
          note = "Cluster Robust SEs and associated results with small sample adjustment are in brackets",
          landscape = TRUE)
```




### Time Lag
The time lag between NT delivery and outcome measure varied across effect sizes. The time lag was defined as the length of time between the mid-point during which NT was delivered and the time at which MA was measured in the unit of days. Results indicated no effect of time lag (*F*(1, 46) = `r reporta(ml_meta_model.3lCHE_mod_time_lag$QM, 2, leading = T)`, *p* = `r report.p(ml_meta_model.3lCHE_mod_time_lag$QMp)`; Table 6). The model was examined for any violations of assumptions of the GLM. Residual plots indicated that assumptions of GLM were met. Nonetheless, cluster robust SEs and their associated results with small sample adjustment were examined for sensitivity analysis. Results were consistent (Table 6). There were no outliers or influential cases. Hence, the effect of NT may not be moderated by time lag.


```{r table6 , echo = FALSE, include = TRUE}
time_lag_tab %>% apa_table(., caption = "Time Lag",  
          col.names = c("Effect", "$b$", "SE","95\\% CI", "t", "df","$p$"),
          escape = FALSE,
          note = "Cluster Robust SEs and associated results with small sample adjustment are in brackets",
          landscape = TRUE)
```







```{r influence_NT_type, echo = FALSE, include = TRUE}
influence.NT_type %>%  apa_table(.,caption = "Outliers and influential cases and Leave-one-out analysis for NT type",  
            col.names = c("Effect","Effect Size","$t_{residual}$", "Cook's d", "DFBETAS", "Estimate", "se", "95\\% CI", "p"),
            note = "$t_{residual}$ = Studentized residuals;",
            landscape = TRUE,
            font_size = "small") 

```






# Discussion 

## Summary
The effect of NT on children’s MA was systematically reviewed through a meta-analysis. On average, NT was found to have a small and positive effect. Although there seemed to be minor negative publication bias, especially for smaller studies, the impacts of potential positive or negative publication bias on the meta-analysis were likely to be small. The effect sizes were highly heterogeneous and a considerable portion of which was negative (`r n.es.below.zero`%), which suggests that the average may be less representative. Moderator analysis was conducted to examine if the heterogeneity was attributable to potential moderators. Results suggest that the effect of NT was moderated by a specific type of NT, two specific types of MA on which the effect of NT was evaluated, and a specific context in which MA was measured, but not by the age of children around which NT was delivered, and the time lag between delivery of NT and the time at which MA was measured. Specifically for the type of NT, compared to the average, Number Identification had a smaller (and slightly negative) effect. Regarding the type of MA, compared to the average, NT had a larger effect on Quantity Comparison and Number Line Estimation, meanwhile, NT had a smaller (and negative) effect on Calculation. Regarding the context in which MA was measured, compared to the average, measuring MA at home had a smaller (and negative) effect on MA. Notable findings, limitations, and future directions are discussed.

## NT type
Different types of NT appear to differ in effectiveness, with Cardinality and Counting having a small and positive effect and Number Identification having a negative trend. However, the findings for Number Identification should be cautioned as there were only two effect sizes from one study that examined Number Identification. Future studies should examine the replicability of the effect of Number Identification. In terms of promoting MA in children, having identified that Cardinality and Counting may be particularly effective, this does not implicate that children should be exposed only to those that are the most effective. It may be beneficial for children to be exposed to a diverse range of NT that have no effect or positive effect, perhaps with more emphasis on more effective ones, as this may facilitate children to learn to generalise their understanding and use of numbers across contexts. Likewise, some types of NT should be combined in a specific way for particular mathematical understanding to develop (Mix et al., 2012). This brings to the suggestion that future studies should also examine the specific structures and combinations of NT that yield the best effect. Only three types of NT could be examined, which was less than the number of types of NT that have been described in the literature. This was because some studies were excluded as they did not report effect sizes without covariates, not all of the included studies categorised the type of NT that was measured, and for those that did only a few of them were examined. The latter may be due to the fact that some types of NT do not occur or occur less than others in natural interactions, which has been observed throughout the literature. From a practical standpoint, it would be beneficial to also know the effects of other types of NT, even those that do not occur or occur less in natural interactions, as not only could NT be implemented through natural parent-child interactions, it could also be implemented artificially (or intentionally) through encouraging parents or caregivers or teachers to increase certain types of NT, or specially designed activities or books, and it could inform which types of NT should be weighted more or avoided. Hence, future studies should examine the effects of other types of NT, even those that do not occur or occur less often in natural parent-child interactions. This could be facilitated by manipulating the occurrence of different types of NT through specially designed activities or books, much like Gibson et al. (2020) did for the size of numbers.

## MA type
It appeared that NT had different effects on different aspects of MA, with NT having greater positive effects on Quantity Comparison and Number Line Estimation and smaller (and negative) effects on Calculation compared to other aspects of MA. This implicates that NT should not be solely relied on but should be used alongside other effective techniques to foster different aspects of MA in preschoolers. However, the effect on Calculation should be cautioned as there were only two effect sizes, both of which were from Mutaf-Yildiz et al. (2018), that evaluated NT on Calculation. It is possible that the negative trend was confounded by the country of the study (or ethnicity of the participants) as that was the only study conducted in Belgium and all other studies were US studies. Future studies could disambiguate this by replicating Mutaf-Yildiz et al. (2018) with non-Belgium samples (or outside Belgium) as well as to examine the effect of NT on other types of MA with Belgium samples (or in Belgium). Finally in this respect, the aspects of MA examined in the studies did not necessarily have clear distinctions between them and some might be related to others, for example, Cardinality has been conceptualised as a facet or prerequisite of Counting (Ryoo et al., 2015). Similarly, Ramani et al. (2015) grouped different aspects of MA as either foundational or advanced MA. It is important to consider the structure of MA, that is, what aspects does MA constitute and whether and how they are related to one another, as this could facilitate both research and practice with regards to conceptualising MA, communication/collaboration, and targeting specific types of MA more effectively. Nevertheless, they were not combined and were analysed separately as the NT literature, on the whole, does not seem to consider the structure of MA, and the aforementioned grouping by Ramani et al. (2015) seemed to be study-specific and may not be agreed upon by other studies. Although some formal structural research on children’s MA has been done (e.g. Ryoo et al., 2015; Yao et al., 2017), factors identified in these studies were not entirely consistent with those in the NT literature, for example, Cardinality, Number Identification, and Number Line Estimation were not identified as factors in these structural studies. This may be because these structural studies were scale-specific as both of the aforementioned structural studies focused only on the factor structure of TEMA-3, which was a scale developed as a general test for MA for children aged 3 to 8.11 years, and therefore may lack comprehensiveness and developmental specificity. Hence, future research should formally examine the structure of preschoolers’ MA and the HME literature should base their research on that.

## Child Age During NT
It was found that the age of the children during which they were exposed to NT did not moderate the average effect. However, the data suggests a minor negative trend. A negative association between children’s age and the average effect is probable as it is sensical that NT may be more relevant for younger children but becomes less effective as children mature to the extent that their mathematical knowledge becomes more sophisticated. However, it is not sensical that the average effect would continuously decrease below 0 and become increasingly negative as children age, hence, the average effect may decrease to zero and remains constant. Indeed, the data could suggest an exponential decay (Figure 1000) as it showed that the largest effect size was at the lowest mean age and the average effect at the mean age of 2000 was around 0. However, this could not be tested as it was constrained by the small sample size and age range. Nevertheless, to extend this further, it may not be a simple exponential decay that descends from the highest effect at the intercept as it is not sensical that the effect is at the peak for newborns. The average effect is likely to be essentially zero at birth as newborns may not benefit from NT without acquiring some prerequisites, such as language, and then increases with age as children acquire more prerequisites. In addition, the increase could be exponential as prerequisites may interact with each other rendering children even more receptive to NT. Thus, linking the initial exponential increase and later exponential decay together, the effect of NT may follow a function similar to a normal distribution, with the peak representing a ‘sensitive period’ during which children become especially susceptive to the effect of NT. Future research may examine whether and how the effect of NT varies across a wider age range, as this could explain some of the heterogeneity in the effect sizes and identify any ‘sensitive periods’ to potentially maximise the effect of NT, which could be around 500 days old, as suggested by the current data.

## Limitations
Some limitations of this study and the literature are discussed. Not all identified relevant studies were included as effect sizes without covariates were not provided in those papers and could not be obtained from corresponding authors. Some potential moderators of interest could not be examined due to a lack of variation and non-standardised reporting of information across studies. To illustrate the lack of variation, 83.33% (10/12) of the studies were conducted in the US, English was the main language for the majority of the participants in 81.82% (9/11) of the studies, mostly it was mothers who delivered NT, and children were mostly from the general population or were ‘typically developing’. This suggests that generalisability is restricted. It would also be of interest to examine NT in different populations. There is an ongoing study conducted by Cahoon and colleagues that attempts to replicate Susperreguy and Davis-Kean (2016) in Northern Ireland, Cuba, and Mexico. That would provide some insight into the generalisability of the current findings. To illustrate non-standardised reporting of information, SES was measured differently across studies, with some using income-to-needs ratio, annual family income, or parental education. It may be helpful for future studies to report these information using either the same metric or standardised scores to facilitate syntheses.

A series of simple regressions and one-way ANOVA, each for a moderator, was conducted in the moderator analysis. This inflates the familywise error rate (FWER; Polanin & Pigott, 2015). Due to the exploratory nature of this study, however, FWER was not controlled. Results from the moderator analysis should be interpreted with caution with respect to type I error and require confirmation by future studies.

The last limitation relates to publication bias. Although there was funnel plot asymmetry, specifically, there was a lack of effect sizes in the bottom right region, more careful examination shows that all the effect sizes in the bottom left were from Mix et al. (2012), which shows that this study tended to report smaller effect sizes than average. However, it does not necessarily mean that there was publication bias in smaller studies nor in Mix et al. (2012). Publication bias is only one of many reasons for asymmetry (Egger et al., 1997; Stern, Gavaghan, & Egger, 2000). The specific reasons for the lower-than-average results from Mix et al. (2012) could be methodology, as it was one of two experimental studies or simply chance. The lack of studies in the bottom right of the funnel plot may be due to the simple fact that the sample size in Mix et al. (2012) was especially small (n = 12) and there were no studies with such a small sample size that Mix et al. (2012) could compare against. Hence, future studies may replicate Mix et al. (2012) and perhaps use both experimental and correlational designs. This also highlights that the funnel plot should be interpreted with extra caution in multilevel or correlated hierarchical meta-analyses, it may be more helpful to evaluate the funnel plot at the study level rather than the effect size level. Finally, Vevea and Wood’s (2005) corrective method was used to estimate the effect sizes ‘corrected’ for selection bias, however, this method was based on the assumption of the traditional random effect model with regards to the data structure, where each study is assumed to contribute only one effect size, and hence, the data structure is assumed to have sampling variances (level 1) nested within studies (level 2). Since the ‘corrected’ effect size is a function of variances of the levels in the hierarchical structure and does not account for any dependency among sampling error and effect sizes, (mis)applying this method to the current data structure may render the ‘corrected’ effect sizes less or not accurate. Nevertheless, it was used as there is currently a lack of appropriate or well-established methods for assessing and correcting publication bias in the context of multilevel and correlated hierarchical models. In fact, most meta-analytic methods were developed based on the aforementioned assumptions of the traditional random effect model (Rogers & Pustejovsky, 2021) and not much focus on methodology has been attended to meta-analyses with complex data structures. In practice, however, meta-analyses with complex data structures are highly common in the field of psychology, education, and medicine (Tipton, Pustejovsky, & Ahmadi, 2019), as demonstrated by this study. This calls for a greater methodological focus on meta-analyses with complex data structures, particularly in terms of assessing and correcting for publication bias.



## Conclusion
To conclude, on average, NT was found to have a small and positive effect on preschoolers’ MA. However, a substantial amount of heterogeneity was found among effect size estimates and a considerable proportion of which were negative, which suggests that the average may not be representative. The heterogeneity was examined and it was found that the effect of NT was moderated by a specific type of NT, a specific type of MA, and the context in which MA was measured. Methods for assessing publication bias suggest minor negative publication bias, however, interpretation should be cautioned and any impacts of publication bias would be small. Several recommendations for future research have been suggested.




```{r exponential_decay, echo = FALSE, include = TRUE}


png(file = "images/exponential_decay.png", res = 100, width = 800, height = 500)
exponential_decay
dev.off()

knitr::include_graphics("images/exponential_decay.png")

```






```{r studies_table, echo = FALSE, include = TRUE}
num_eff_tib %>% apa_table(caption = "Studies",  
            col.names = c("Study", "Number of effect sizes"),
            landscape = TRUE) 
```













