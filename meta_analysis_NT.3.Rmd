working file; full of bugs, check the simplified version, that definitely does not give a bug
---
title: "meta_analysis_NT"
date: '2022-03-05'
output: papaja::apa6_pdf
always_allow_html: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include = F)
```

```{r packages}
library(metafor)
library(clubSandwich)
library(weightr)
library(tidyverse)
library(dplyr)
library(kableExtra)
library(openxlsx)
library(metaSEM)
```




```{r function_chunk}
######################################################################
#Time converter, used to convert among different time units (mins, days, months, year)
time_converter <- function(min, d, m, y){
      mins <- ifelse(
    missing(min),
    ifelse(
      missing(d),
      ifelse(
        missing(m),
        y*525960,
        m*44560.5),
      d*1440),
    min*1)
    days <- ifelse(
    missing(d),
    ifelse(
      missing(min),
      ifelse(
        missing(m),
        y*365.25,
        m*30.4375),
      min/1440),
    d*1)
  months <- ifelse(
    missing(m),
    ifelse(
      missing(min), 
      ifelse(
        missing(d), 
        y*12, 
        d/30.4375),
      min/43830),
    m*1)
  years <- ifelse(
    missing(y),
    ifelse(
      missing(min), 
      ifelse(
        missing(d), 
        m/12, 
        d/365.25),
      min/525960),
    y*1)
  return(tibble(mins,days, months, years))
}


######################################################################
#Convert from t to r
t_to_r <- function(t, df){sqrt((t^2)/((t^2)+(df)))}




######################################################################
#Used to examine the variances at each level in the 3-level meta-analysis model 
vardist.3l <- function(model, digits = 3){
  level1 <- ((length(model$vi)-1)*(sum(1/model$vi)))/
    ((sum(1/model$vi)^2)-(sum(1/((model$vi)^2))))
  level2 <- model$sigma2[2]
  level3 <- model$sigma2[1]
  p_level1 <- level1/(level1 + model$sigma2[2] + model$sigma2[1])
  p_level2 <- model$sigma2[2]/(level1 + model$sigma2[2] + model$sigma2[1])
  p_level3 <- model$sigma2[1]/(level1 + model$sigma2[2] + model$sigma2[1])
  tib1 <- rename(as.tibble(c(level1, level2, level3)), variances = value)
  tib2 <- rename(as.tibble(c(p_level1, p_level2, p_level3)), proportions_I2 = value)
  tib3 <- dplyr::select(add_column(round(cbind(tib1, tib2), digits = digits), Level = c(1, 2, 3)), Level, variances, proportions_I2)
  return(tib3)
}



######################################################################
#Sensitivity analysis: See how different degree of dependency affect the estimates 
dependency.sen <- function(data, random = NULL, mods = NULL, b = 0, r, robust = NULL, cluster = cluster){
  c <- cluster
  r.1 <- r
  rlevelz <- rename(rowid_to_column(as.tibble(r.1), var = "r_id"), r_level = value)
  estimate <- c()
  se <- c()
  tval <- c()
  pval <- c()
  if(is.null(robust)){
    for(counter in 1:max(rlevelz$r_id)){
      rlevelz.1 <- unlist(array(c(rlevelz[counter,][2])))
      v_r <- impute_covariance_matrix(data$vi, cluster = c, r = rlevelz.1)
      model.r <- rma.mv(yi = yi, V = v_r, data = data, struct = "CS", method = "REML", test = "t", random = random, mods =  mods)
      estimate <- c(estimate, model.r$b[b+1])
      se <- c(se, model.r$se[b+1]) 
      tval <- c(tval, model.r$zval[b+1])
      pval <- c(pval, model.r$pval[b+1])}}
  else if(robust == "clubSandwich"){
    for(counter in 1:max(rlevelz$r_id)){
      rlevelz.1 <- unlist(array(c(rlevelz[counter,][2])))
      v_r <- impute_covariance_matrix(data$vi, cluster = c, r = rlevelz.1)
      model.r.p1 <- rma.mv(yi = yi, V = v_r, data = data, struct = "CS", method = "REML", test = "t", random = random, mods =  mods)
      model.r <- as.tibble(coef_test(model.r.p1, vcov = "CR2", cluster = c))
      estimate <- c(estimate, unlist(array(c((model.r[(b+1),][2])))))
      se <- c(se, unlist(array(c((model.r[(b+1),][3])))))
      tval <- c(tval, unlist(array(c((model.r[(b+1),][4])))))
      pval <- c(pval, unlist(array(c((model.r[(b+1),][6])))))}}

return(cbind(rlevelz, as.data.frame(cbind(estimate, se, tval, pval))))
}


######################################################################
#This function is replaced by rma.mv.influence
rma.mv.influence.retired <- function(data, struct = "CS", method = "REML", random = NULL, mods = NULL, b = 0, cluster, robust = FALSE, robust.cluster, adjust = FALSE, CHE = FALSE, r){
  data.gojira <- data
  c1 <- cluster #input should be something like "effect"
  c <- unlist(as.list(array(data[c(c1)]))) #This turns c1 into data$effect
  data.gojira.2 <- mutate(rowid_to_column(mutate(data.gojira, cluster.gojira = as.factor(c)), var = "rowid.gojira"), rowid.gojira = as.character(rowid.gojira))
  data.gojira.2$cluster.gojira2 <- group_indices(group_by(data.gojira.2, cluster.gojira), cluster.gojira)
  if(isTRUE(CHE)){
    vi_CHE <- impute_covariance_matrix(data.gojira$vi, cluster = c, r = r)}
  if(isFALSE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)}
  else if(isTRUE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi_CHE, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)
  }
     
     leveldetermine1 <- dplyr::select(mutate(rowid_to_column(rename(as.tibble(rev(str_trim(unlist(strsplit(str_trim(unlist(strsplit(as.character(model0$random), "[|]"))[2], side = c("both", "left", "right")), "[/]")), side = c("both", "left", "right")))), cluster = value), var = "id"), level = id + 1), level, cluster)
     leveldetermine2 <- unlist(as.list(array(dplyr::select(filter(leveldetermine1 , cluster == c1), level))))
    
       
  cluster_unit <- c()
  leave1out <- c()
  se <- c()
  tval <- c()
  pval <-c()
  ci.lb <- c()
  ci.ub <- c()
  if (!is.null(mods)) {model.F <- c()}
  if (!is.null(mods)) {model.F.p <- c()}
  model.aic <- c()
  model.bic <- c()
  model.aicc <- c()
  for(counter in 1:max(data.gojira.2$cluster.gojira2)){
    data.gojira.3 <- filter(data.gojira.2, cluster.gojira2 != counter)
    c2 <- unlist(as.list(array(data.gojira.3[c(robust.cluster)])))
    if(isTRUE(CHE)){
    vi_adjusted <- impute_covariance_matrix(data.gojira.3$vi, r = r, cluster = c2)}
    
    if (isFALSE(robust)){
      if(isFALSE(CHE)){
        model <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)}
      else if(isTRUE(CHE)){
        model <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)}}
    else if(isTRUE(robust)){
      if(isFALSE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- metafor::robust(model.p1, cluster = pull(data.gojira.3, robust.cluster), adjust = adjust)}
      else if(isTRUE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- metafor::robust(model.p1, cluster = pull(data.gojira.3, robust.cluster), adjust = adjust)}
      }
    cluster_unit <- c(cluster_unit, as.vector(dplyr::select(filter(data.gojira.2, cluster.gojira2 == counter) , cluster.gojira)[1,]))
    leave1out <- c(leave1out, model$b[b+1])
    se <- c(se, model$se[b+1])
    tval <- c(tval, model$zval[b+1])
    pval <- c(pval, model$pval[b+1])
    ci.lb <- c(ci.lb, model$ci.lb[b+1])
    ci.ub <- c(ci.ub, model$ci.ub[b+1])
    if (!is.null(mods)) {model.F <- c(model.F, model$QM[1])}
    if (!is.null(mods)) {model.F.p <- c(model.F.p, model$QMp[1])}
    model.aic <- c(model.aic ,model$fit.stats[ifelse(model$method == "ML", 1, 2)][3,])
    model.bic <- c(model.bic, model$fit.stats[ifelse(model$method == "ML", 1, 2)][4,])
    model.aicc <- c(model.aicc, model$fit.stats[ifelse(model$method == "ML", 1, 2)][5,])
  }
  resid <- rename(dplyr::select(full_join(data.gojira.2, rename(dplyr::select(rownames_to_column(as.data.frame(rstudent(model0)), var = "rowid.gojira"), rowid.gojira, z), rstudent = z), by = "rowid.gojira"), cluster.gojira, rstudent), cluster_unit = cluster.gojira)
  cd.1 <- cooks.distance(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
  cd.2 <- rename(mutate(rownames_to_column(as.data.frame(cd.1), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit)), cooks.d = cd.1)
  if(isFALSE(robust)){
    dfbetas1 <- dfbetas(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
    dfbetas2 <- mutate(rownames_to_column(as.data.frame(t(as.data.frame(t(dfbetas1))[(b + 1),])), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit))
    names(dfbetas2)[2]<-paste("DFBETAS") }
    cluster_unit_col <- rename(as.tibble(c), cluster_unit = value)
    cluster_unit_col2 <- cluster_unit_col[!duplicated(cluster_unit_col$cluster_unit), ]

   #OUTPUT
  if(isFALSE(robust)){
    if(is.null(mods)){
        if(leveldetermine2 == 2){
          return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}
        else if(leveldetermine2 != 2){
          return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}}}
    
  if(isTRUE(robust)){
        if(is.null(mods)){
          if(leveldetermine2 == 2){
            return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}
            else if(leveldetermine2 != 2){
              return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}}}}




######################################################################
#Sensitivity analysis: Outliers and influential cases and leave1out analysis 
rma.mv.influence <- function(data, struct = "CS", method = "REML", random = NULL, mods = NULL, b = 0, cluster, robust = FALSE, robust.cluster, adjust = FALSE, CHE = FALSE, r){
  data.gojira <- data
  c1 <- cluster #input should be something like "effect"
  c <- unlist(as.list(array(data[c(c1)]))) #This turns c1 into data$effect
  data.gojira.2 <- mutate(rowid_to_column(mutate(data.gojira, cluster.gojira = as.factor(c)), var = "rowid.gojira"), rowid.gojira = as.character(rowid.gojira))
  data.gojira.2$cluster.gojira2 <- group_indices(group_by(data.gojira.2, cluster.gojira), cluster.gojira)
  if(isTRUE(CHE)){
    vi_CHE <- impute_covariance_matrix(data.gojira$vi, cluster = c, r = r)}
  if(isFALSE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)}
  else if(isTRUE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi_CHE, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)
  }
     
     leveldetermine1 <- dplyr::select(mutate(rowid_to_column(rename(as.tibble(rev(str_trim(unlist(strsplit(str_trim(unlist(strsplit(as.character(model0$random), "[|]"))[2], side = c("both", "left", "right")), "[/]")), side = c("both", "left", "right")))), cluster = value), var = "id"), level = id + 1), level, cluster)
     leveldetermine2 <- unlist(as.list(array(dplyr::select(filter(leveldetermine1 , cluster == c1), level))))
    
       
  cluster_unit <- c()
  leave1out <- c()
  se <- c()
  tval <- c()
  pval <-c()
  ci.lb <- c()
  ci.ub <- c()
  if (!is.null(mods)) {model.F <- c()}
  if (!is.null(mods)) {model.F.p <- c()}
  model.aic <- c()
  model.bic <- c()
  model.aicc <- c()
  for(counter in 1:max(data.gojira.2$cluster.gojira2)){
    data.gojira.3 <- filter(data.gojira.2, cluster.gojira2 != counter)
    c2 <- unlist(as.list(array(data.gojira.3[c(robust.cluster)])))
    if(isTRUE(CHE)){
    vi_adjusted <- impute_covariance_matrix(data.gojira.3$vi, r = r, cluster = c2)}
    
    if (isFALSE(robust)){
      if(isFALSE(CHE)){
        model <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)}
      else if(isTRUE(CHE)){
        model <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)}}
    else if(isTRUE(robust)){
      if(isFALSE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- metafor::robust(model.p1, cluster = pull(data.gojira.3, robust.cluster), adjust = adjust)}
      else if(isTRUE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- metafor::robust(model.p1, cluster = pull(data.gojira.3, robust.cluster), adjust = adjust)}
      }
    cluster_unit <- c(cluster_unit, as.vector(dplyr::select(filter(data.gojira.2, cluster.gojira2 == counter) , cluster.gojira)[1,]))
    leave1out <- c(leave1out, model$b[b+1])
    se <- c(se, model$se[b+1])
    tval <- c(tval, model$zval[b+1])
    pval <- c(pval, model$pval[b+1])
    ci.lb <- c(ci.lb, model$ci.lb[b+1])
    ci.ub <- c(ci.ub, model$ci.ub[b+1])
    if (!is.null(mods)) {model.F <- c(model.F, model$QM[1])}
    if (!is.null(mods)) {model.F.p <- c(model.F.p, model$QMp[1])}
    model.aic <- c(model.aic ,model$fit.stats[ifelse(model$method == "ML", 1, 2)][3,])
    model.bic <- c(model.bic, model$fit.stats[ifelse(model$method == "ML", 1, 2)][4,])
    model.aicc <- c(model.aicc, model$fit.stats[ifelse(model$method == "ML", 1, 2)][5,])
  }
  resid <- rename(dplyr::select(full_join(data.gojira.2, rename(dplyr::select(rownames_to_column(as.data.frame(rstudent(model0)), var = "rowid.gojira"), rowid.gojira, z), rstudent = z), by = "rowid.gojira"), cluster.gojira, rstudent), cluster_unit = cluster.gojira)
  cd.1 <- cooks.distance(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
  cd.2 <- rename(mutate(rownames_to_column(as.data.frame(cd.1), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit)), cooks.d = cd.1)
    dfbetas1 <- dfbetas(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
    dfbetas2 <- mutate(rownames_to_column(as.data.frame(t(as.data.frame(t(dfbetas1))[(b + 1),])), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit))
    names(dfbetas2)[2]<-paste("DFBETAS") 
    cluster_unit_col <- rename(as.tibble(c), cluster_unit = value)
    cluster_unit_col2 <- cluster_unit_col[!duplicated(cluster_unit_col$cluster_unit), ]

   #OUTPUT
  if(isFALSE(robust)){
    if(is.null(mods)){
        if(leveldetermine2 == 2){
          return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}
        else if(leveldetermine2 != 2){
          return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d), DFBETAS = as.numeric(DFBETAS)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}}}
    
  if(isTRUE(robust)){
        if(is.null(mods)){
          if(leveldetermine2 == 2){
            return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"),dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}
            else if(leveldetermine2 != 2){
              return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.aic, model.bic, model.aicc))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, tval, pval, ci.lb, ci.ub, model.F, model.F.p, model.aic, model.bic, model.aicc)), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, ifelse(pval <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), tval = as.numeric(tval), pval = as.numeric(pval), ci.lb = as.numeric(ci.lb),ci.ub = as.numeric(ci.ub), model.F = as.numeric(model.F), model.F.p = as.numeric(model.F.p), model.aic = as.numeric(model.aic), model.bic = as.numeric(model.bic),  model.aicc = as.numeric(model.aicc)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d, DFBETAS, leave1out, se, tval, pval, ci.lb, ci.ub, sig, model.F, model.F.p, model.aic, model.bic, model.aicc))}}}}





######################################################################
#Same as rma.mv.influence, but this is for robust SE with the ClubSandwich package
sandwich.influence <- function(data, struct = "CS", method = "REML", random = NULL, mods = NULL, b = 0, cluster, robust.cluster, adjust = FALSE, CHE = FALSE, r, test = "Satterthwaite"){
  data.gojira <- data
  c1 <- cluster #input should be something like "effect"
  c <- unlist(as.list(array(data[c(c1)]))) #This turns c1 into data$effect
  data.gojira.2 <- mutate(rowid_to_column(mutate(data.gojira, cluster.gojira = as.factor(c)), var = "rowid.gojira"), rowid.gojira = as.character(rowid.gojira))
  data.gojira.2$cluster.gojira2 <- group_indices(group_by(data.gojira.2, cluster.gojira), cluster.gojira)
  if(isTRUE(CHE)){
    vi_CHE <- impute_covariance_matrix(data.gojira$vi, cluster = c, r = r)}
  if(isFALSE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)}
  else if(isTRUE(CHE)){
    model0 <- rma.mv(yi = yi, V = vi_CHE, data = data.gojira, struct = struct, method = method, test = "t", 
                                      random = random, mods = mods)
  }
     
     leveldetermine1 <- dplyr::select(mutate(rowid_to_column(rename(as.tibble(rev(str_trim(unlist(strsplit(str_trim(unlist(strsplit(as.character(model0$random), "[|]"))[2], side = c("both", "left", "right")), "[/]")), side = c("both", "left", "right")))), cluster = value), var = "id"), level = id + 1), level, cluster)
     leveldetermine2 <- unlist(as.list(array(dplyr::select(filter(leveldetermine1 , cluster == c1), level))))
    
  cluster_unit <- c()
  leave1out <- c()
  se <- c()
  t <- c()
  df <- c()
  p <- c()
  for(counter in 1:max(data.gojira.2$cluster.gojira2)){
    data.gojira.3 <- filter(data.gojira.2, cluster.gojira2 != counter)
    c2 <- unlist(as.list(array(data.gojira.3[c(robust.cluster)])))
    if(isTRUE(CHE)){
    vi_adjusted <- impute_covariance_matrix(data.gojira.3$vi, r = r, cluster = c2)}
  
    if(isFALSE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- tibble(as.data.frame(coef_test(obj = model.p1, vcov = "CR2", test = test, cluster = c2)))
        }
    else if(isTRUE(CHE)){
        model.p1 <- rma.mv(yi = yi, V = vi_adjusted, data = data.gojira.3, struct = struct, method = method, test = "t", random = random, mods = mods)
        model <- tibble(as.data.frame(coef_test(obj = model.p1, vcov = "CR2", test = test, cluster = c2)))}
  
    cluster_unit <- c(cluster_unit, as.vector(dplyr::select(filter(data.gojira.2, cluster.gojira2 == counter) , cluster.gojira)[1,]))
    leave1out <- c(leave1out, unlist(array(c(model[(b+1),][2]))))
    se <- c(se, unlist(array(c(model[(b+1),][3]))))
    t <- c(t,  unlist(array(c(model[(b+1),][4]))))
    df <- c(df,  unlist(array(c(model[(b+1),][5]))))
    p <- c(p,  unlist(array(c(model[(b+1),][6]))))}


  resid <- rename(dplyr::select(full_join(data.gojira.2, rename(dplyr::select(rownames_to_column(as.data.frame(rstudent(model0)), var = "rowid.gojira"), rowid.gojira, z), rstudent = z), by = "rowid.gojira"), cluster.gojira, rstudent), cluster_unit = cluster.gojira)
  cd.1 <- cooks.distance(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
  cd.2 <- rename(mutate(rownames_to_column(as.data.frame(cd.1), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit)), cooks.d = cd.1)
    dfbetas1 <- dfbetas(model0, progbar=FALSE, reestimate=TRUE, parallel="no", ncpus=1, cluster = as.factor(c))
    dfbetas2 <- mutate(rownames_to_column(as.data.frame(t(as.data.frame(t(dfbetas1))[(b + 1),])), var = "cluster_unit"), cluster_unit = as.factor(cluster_unit))
    names(dfbetas2)[2]<-paste("DFBETAS") 
    cluster_unit_col <- rename(as.tibble(c), cluster_unit = value)
    cluster_unit_col2 <- cluster_unit_col[!duplicated(cluster_unit_col$cluster_unit), ]

   #OUTPUT
    if(is.null(mods)){
        if(leveldetermine2 == 2){
          return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, t, df, p))}
        else if(leveldetermine2 != 2){
          return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d,DFBETAS, leave1out, se, t, df, p))}}
    if (!is.null(mods)) {
      if(leveldetermine2 == 2){
        return(dplyr::select(mutate(full_join(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), resid, by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, rstudent, cooks.d, DFBETAS, leave1out, se, t, df, p))}
      else if(leveldetermine2 != 2){
        return(dplyr::select(mutate(full_join(cluster_unit_col2, full_join(full_join(mutate(mutate(as.data.frame(cbind(cluster_unit, leave1out, se, t, df, p)), sig = ifelse(p <= 0.05, ifelse(p <= 0.01, ifelse(p <= 0.001, "***", "**"), "*"), "ns")), cluster_unit = as.factor(cluster_unit),leave1out = as.numeric(leave1out), se = as.numeric(se), t = as.numeric(t), p = as.numeric(p), df = as.numeric(df)), cd.2, by = "cluster_unit"), dfbetas2, by = "cluster_unit"), by = "cluster_unit"), cooks.d = as.numeric(cooks.d)), cluster_unit, cooks.d,DFBETAS, leave1out, se, t, df, p))}}}


#TUTORIAL FOR rma.mv.influence 
#WHAT IS rma.mv.influence
#-- This function returns statistics for outlier/influence diagnosis (studentized residuals, Cook's distance, DFBETAS, and leave1out statistics)
#-- Leave1out statistics are all those columns from the right (starting from the 'leave1out' column)

#HOW TO USE THE FUNCTION 
#-- USAGE 
#------ rma.mv.influence(data, struct = "CS", method = "REML", random = NULL, mods = NULL, b = 0, cluster, robust = FALSE, robust.cluster, adjust = FALSE)
#-- ARGUMENTS 
#-------- data - Data for the meta-analysis (Required)
#-------- struct - The same argument seen in rma.mv (do struct = "CS", I don't what would happen if struct is something else) (Required)
#-------- method - Estimation method for the meta-analysis (Use "REML", because I haven't completely validated the function with "ML", but I think both work) (Required)
#-------- random - Specify random effect, just like you would with the metafor package (e.g. ~ 1 | school/class) (Optional; default is NULL)
#-------- mods = Specify moderators, use it just like you would with the metafor package (e.g. mods = ~ predictor1 + predictor2) (Optional; default is NULL)
#-------- b - The particular beta that you are evaluating (intercept would be b = 0, predictor 1 would be b = 1; it corresponds to the order of your predictors; default is b = 0)
#-------- cluster - The level that you are evaluating (if you want to evaluate cook's distances for each study, instead of each effect, then specify it as cluster = "study", the function then takes in the study variable from your data and evaluate influence statistics based on that cluster)
#-------- robust - If you want robust SE, then set robust = TRUE, otherwise FALSE (default is FALSE) (robust only works for moderation analysis, does not work for intercept only models) (Optional; default is FALSE)
#-------- robust.cluster - If you set robust = TRUE, then you need to specify the robust cluster, this then calculate the cluster robust SE (see metafor::robust) (Required if robust = TRUE; no default)
#-------- adjust - If you want to correct robust SE for small sample size, then set adjust = TRUE (see metafor::robust) (required if robust = TRUE; default is FALSE)

#WIHOUT READING ALL THOSE CRAP... THIS IS THE STRUCTURE I USED 
#rma.mv.influence(data, struct = "CS", method = "REML", random = NULL, mods = NULL, b = 0, cluster, robust = FALSE, robust.cluster, adjust = FALSE)

#FOR THE INTERCEPT ONLY MODEL 
#rma.mv.influence(meta_tib, struct = "CS", method = "REML", random = NULL, mods = NULL, b = 0, cluster = "effect", robust = TRUE, robust.cluster = "effect", adjust = T)

#FOR REGRESSIONS 
#rma.mv.influence(meta_tib, struct = "CS", method = "REML", random = NULL, mods = NT_type.1, b = 2, cluster = "effect", robust = TRUE, robust.cluster = "study_id", adjust = T)



######################################################################
#Assumption function, used to examine model assumption 
assumption <- function(model){
  model_fitted <- mutate(rowid_to_column(rename(as.tibble(fitted(model)), fitted = value), var = "effect"), effect = as.factor(effect))
  model_resid <- rename(dplyr::select(rownames_to_column(as.data.frame(rstandard(model)) , var = "effect"), effect, resid, z), rraw = resid, rstandard = z)
  model_fitted_resid <- dplyr::full_join(model_fitted, model_resid, by = "effect")
  x <- seq(-5, 5, by = 0.05)
  normfunct <- function(x){(1/(1*sqrt(2*pi)))*exp((-1/2)*(((x - 0)/1)^2))}
  y <- normfunct(x = x)
  xynorm <- as.tibble(cbind(x, y))
  density.plot <- ggplot2::ggplot(data = model_resid) + geom_density(mapping = aes(x= rstandard), alpha = 0.8, fill= "#589E9E", color = "#589E9E", size = 0) + scale_x_continuous(limits = c(-5, 5)) + geom_line(data = xynorm, mapping = aes(x = x, y = y)) + theme_minimal()
  resid_fitted_plot <- ggplot2::ggplot(data = NULL) + geom_point(data = model_fitted_resid, mapping = aes(x = fitted, y = rraw), color = "#589E9E", alpha = 0.6, size = 3) + labs(x = "Fitted Values", y = "rstandard") + theme_minimal()
  qqplot <- qqnorm(residuals(model))
  return(list(qqplot, density.plot,resid_fitted_plot))}
```



```{r klibanoff_et_al.2006}
klibanoff_et_al.2006_tib <- c(
  "klibanoff_et_al.2006a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("NT - AD-MA"),
      effect_id = c("Overall_Overall"),
      year = c(2006),
      country = c("US"),
      study_id = c("klibanoff_et_al.2006"),
      design = c("Correlational"),
      design.2 = c("Unknown"), 
      SES = c("Unknown"),
      main_language = c("English"),
      deliverer_type = c("Teacher"),
      mothers = c(NA),
      white = c(NA), 
      female = c(0.50),
      child_age_study_start = c(1704.5),
      child_age_NT_start = c(1704.5),
      child_age_NT_mid = c(1826.25),
      child_age_NT_end = c(1826.25),
      child_age_MA = c(1887.125),
      NT_measure_time = c(165),
      time_between_NT_mid_MA = c(NA),
      intervention_dosage = c(NA),
      NT_context = c("School"),
      MA_context = c("School"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      MA_test = c("AD_MA"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.7690146),
      n = c(146))

```

```{r son_and_hur.2020}
son_and_hur.2020_tib <- c(
  "son_and_hur.2020a", 
  "son_and_hur.2020b") %>% data.frame() %>% rename(., effect = .) %>% add_column(
    effect_description = c("Total Math Talk - Fall MA", "Total Maths Talk - Spring MA"),
    effect_id = c("Overall_Overall", "Overall_Overall"),
    year = c(2020, 2020),
    country = c("US", "US"),
    study_id = c("son_and_hur.2020", "son_and_hur.2020"),
    design = c("Correlational", "Correlational"),
    design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational"), 
    SES = c("Low", "Low"),
    main_language = c("English", "English"),
    deliverer_type = c("Parent", "Parent"),
    mothers = c(1, 1),
    white = c(0.500, 0.500), 
    female = c(0.47826087, 0.47826087),
    child_age_study_start = c(1717.284, 1717.284),
    child_age_NT_start = c(NA, NA),
    child_age_NT_mid = c(1793.378, 1793.378),
    child_age_NT_end = c(NA, NA),
    child_age_MA = c(1793.378, 2067.315),
    NT_measure_time = c(17.5, 17.5),
    time_between_NT_mid_MA = c(0, 273.937),
    intervention_dosage = c(NA, NA),
    NT_context = c("Home", "Home"),
    MA_context = c("School", "School"),
    NT_type = c("Overall", "Overall"),
    NT_type.1 = c("Overall", "Overall"),
    NT_type.10 = c("Overall", "Overall"),
    MA_test = c("WJ_AP", "WJ_AP"),
    MA_measure = c("Overall", "Overall"),
    MA_measure2 = c("Overall", "Overall"),
    analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation"),
    controlled_variables = c(0, 0),
    r = c(0.27, 0.12),
    n = c(29, 29))
```


```{r ramani_et_al.2015}
ramani_et_al.2015_tib <- c(
  "ramani_et_al.2015a", 
  "ramani_et_al.2015b", 
  "ramani_et_al.2015c", 
  "ramani_et_al.2015d",
  "ramani_et_al.2015e",
  "ramani_et_al.2015f",
  "ramani_et_al.2015g",
  "ramani_et_al.2015h",
  "ramani_et_al.2015i",
  "ramani_et_al.2015j",
  "ramani_et_al.2015k",
  "ramani_et_al.2015l") %>% data.frame() %>% rename(., effect = .) %>% add_column(
    effect_description = c("Counting and Number Identification - Verbal Counting", "Cardinality and Ordering  - Verbal Counting", "Counting and Number Identification - Number Identification", "Cardinality and Ordering - Number Identification", "Counting and Number Identification - Counting principles", "Cardinality and Ordering - Counting principles", "Counting and Number Identification - Enumeration and Cardinality", "Cardinality and Ordering - Enumeration and Cardinality", "Counting and Number Identification - Number Line Estimation", "Cardinality and Ordering - Number Line Estimation", "Counting and Number Identification - Magnitude Comparison", "Cardinality and Ordering - Magnitude Comparison"),
    effect_id = c("Overall_Counting", "Overall_Counting", "Overall_Number_Identification", "Overall_Number_Identification", "Overall_Counting", "Overall_Counting", "Overall_Cardinality", "Overall_Cardinality",  "Overall_Number_Line_Estimation",  "Overall_Number_Line_Estimation", "Overall_Quantity_Comparison", "Overall_Quantity_Comparison"),
    year = c(2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015),
    country = c("US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US"),
    study_id = c("ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015", "ramani_et_al.2015"),
    design = c("Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational"),
    design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational"), 
    SES = c("Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low", "Low"),
    main_language = c("English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English"),
    deliverer_type = c("Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver", "Caregiver"),
    mothers = c(0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788, 0.787878788),
    white = c(0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33), 
    female = c(0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6),
    child_age_study_start = c(1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75),
    child_age_NT_start = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    child_age_NT_mid = c(1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75, 1582.75),
    child_age_NT_end = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    child_age_MA = c(1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25, 1593.25),
    NT_measure_time = c(15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15),
    time_between_NT_mid_MA = c(10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5, 10.5),
    intervention_dosage = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    NT_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
    MA_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
    NT_type = c("Counting_and_Number_Identificaton", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering", "Counting_and_Number_Identification", "Cardinality_and_Ordering"),
    NT_type.1 = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall"),
    NT_type.10 = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
    MA_test = c("Verbal_Counting", "Verbal_Counting", "Number_Identification", "Number_Identification", "Counting_Principles", "Counting_Principles", "Enumeration_and_Cardinality", "Enumeration_and_Cardinality", "Number_Line_Estimation", "Number_Line_Estimation", "Magnitude_Comparison", "Magnitude_Comparison"),
    MA_measure = c("Counting", "Counting", "Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Number_Line_Estimation", "Number_Line_Estimation", "Quantity_Comparison", "Quantity_Comparison"),
    MA_measure2 = c("Counting", "Counting", "Number_Sense", "Number_Sense", "Counting", "Counting", "Cardinality", "Cardinality", "Number_Sense", "Number_Sense", "Quantity_Comparison", "Quantity_Comparison"),
    analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order _orrelation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation"),
    controlled_variables = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
    r = c(-0.12, 0.11, -0.19, 0.10, 0.07, 0.17, -0.31, -0.03, 0.05, 0.37, 0.11, 0.39),
    n = c(33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33))
#ramani_et_al.2015_kable <- ramani_et_al.2015_tib %>% 
  #dplyr::mutate(dplyr::across(where(is.numeric), ~round(., 2))) %>% 
  #kable(format = "html", caption = "Ramani et al. (2015) effect sizes and associated inferential statistics", col.names = c("Effect id", "Effect Description", "Analysis", "Controlled variables","r", "n", "z", "Var of z", "SE of z", "Weight", "Lower CI for z", "Upper CI for z", "Var of r", "SE of r", "Lower CI for r", "Upper CI for r")) %>% kable_styling(full_width = T, position = "center") %>% row_spec(row = 0, extra_css = "border-bottom: 2px solid black;") #

```

```{r mutaf_yildiz et al.2018}
mutaf_yildiz_et_al.2018_tib <- c(
  "mutaf_yildiz_et_al.2018a", 
  "mutaf_yildiz_et_al.2018b"
  ) %>% data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("NT during book reading - Calculation skill", "NT during Lego playing - Calculation skill"),
      effect_id = c("Overall_Calculation", "Overall_Calculation"),
      year = c(2018, 2018),
      country = c("BE", "BE"),
      study_id = c("mutaf_yildiz_et_al.2018", "mutaf_yildiz_et_al.2018"),
      design = c("Correlational", "Correlational"),
      design.2 = c("Cross_sectional_Correlational", "Cross_sectional_Correlational"), 
      SES = c("Middle", "Middle"),
      main_language = c("Dutch", "Dutch"),
      deliverer_type = c("Parent", "Parent"),
      mothers = c(0.682, 0.682),
      white = c(NA, NA), 
      female = c(0.454545455, 0.454545455),
      child_age_study_start = c(2060.01, 2060.01),
      child_age_NT_start = c(NA, NA),
      child_age_NT_mid = c(2060.01, 2060.01),
      child_age_NT_end = c(NA, NA),
      child_age_MA = c(2060.01, 2060.01),
      NT_measure_time = c(5, 5),
      time_between_NT_mid_MA = c(0, 0),
      intervention_dosage = c(NA, NA),
      NT_context = c("Home", "Home"),
      MA_context = c("Home", "Home"),
      NT_type = c("Overall", "Overall"),
      NT_type.1 = c("Overall", "Overall"),
      NT_type.10 = c("Overall", "Overall"),
      MA_test = c("TediMath", "TediMath"),
      MA_measure = c("Calculation", "Calculation"),
      MA_measure2 = c("Calculation", "Calculation"),
      analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation"),
      controlled_variables = c(0, 0),
      r = c(-0.05, -0.35),
      n = c(44, 44)) 

```

```{r elliott_et_al.2017}
elliott_et_al.2017_tib <- c(
  "elliott_et_al.2017a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("NT - TEMA-3"),
      effect_id = c("Overall_Overall"),
      year = c(2017),
      country = c("US"),
      study_id = c("elliott_et_al.2017"),
      design = c("Correlational"),
      design.2 = c("Cross_sectional_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(1),
      white = c(0.89), 
      female = c(0.434782609),
      child_age_study_start = c(2116.928),
      child_age_NT_start = c(NA),
      child_age_NT_mid = c(2116.928),
      child_age_NT_end = c(NA),
      child_age_MA = c(2116.928),
      NT_measure_time = c(10),
      time_between_NT_mid_MA= c(0),
      intervention_dosage = c(NA),
      NT_context = c("Lab"),
      MA_context = c("Lab"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.16),
      n = c(44))

```

```{r boonen_et_al.2011}
#This study is excluded!
boonen_et_al.2011_tib <- c(
  "boonen_et_al.2011a", 
  "boonen_et_al.2011b", 
  "boonen_et_al.2011c", 
  "boonen_et_al.2011d", 
  "boonen_et_al.2011e", 
  "boonen_et_al.2011f", 
  "boonen_et_al.2011g", 
  "boonen_et_al.2011h",
  "boonen_et_al.2011i") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("Calculation NT predicting AD MA", "Conventional Nominatives NT predicting AD MA", "Conventional Nominatives NT predicting AD MA", "Conventional Nominatives predicting ENT-R", "Counting NT predicting ENT-R", "Ordering NT predicting ENT-R", "Number Symbols NT predicting ENT-R", "Cardinality NT predicting quantity comparison task", "Calculation NT predicting Cardinality"),
      effect_id = c("Calculation_Overall", "Conventional_Nominatives_Overall", "Conventional_Nominatives_Overall", "Conventional_Nominatives_Overall", "Counting_Overall", "Ordering_Overall", "Number_Identification_Overall", "Cardinality_Quantity_Comparison", "Calculation_Number_Identification"),
      year = c(2011, 2011, 2011, 2011, 2011, 2011, 2011, 2011,2011),
      country = c("NE", "NE", "NE", "NE", "NE", "NE", "NE", "NE", "NE"),
      study_id = c("boonen_et_al.2011", "boonen_et_al.2011", "boonen_et_al.2011", "boonen_et_al.2011", "boonen_et_al.2011", "boonen_et_al.2011", "boonen_et_al.2011", "boonen_et_al.2011", "boonen_et_al.2011"),
      design = c("Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational"),
      design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational"), 
      SES = c("Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle"),
      main_language = c("Dutch", "Dutch", "Dutch", "Dutch", "Dutch", "Dutch", "Dutch", "Dutch", "Dutch"),
      deliverer_type = c("Teacher", "Teacher", "Teacher", "Teacher", "Teacher", "Teacher", "Teacher", "Teacher", "Teacher"),
      mothers = c(NA, NA, NA, NA, NA, NA, NA, NA, NA),
      white = c(NA, NA, NA, NA, NA, NA, NA, NA, NA), 
      female = c(0.501992032, 0.501992032, 0.501992032, 0.501992032, 0.501992032, 0.501992032, 0.501992032, 0.501992032, 0.501992032),
      child_age_study_start = c(1899.3, 1899.3, 1899.3, 1899.3, 1899.3, 1899.3, 1899.3, 1899.3, 1899.3),
      child_age_NT_start = c(NA, NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_NT_mid = c(NA, NA, NA, NA, NA, NA, NA, NA,  NA),
      child_age_NT_end = c(NA, NA, NA, NA, NA, NA, NA, NA,  NA),
      child_age_MA = c(NA, NA, NA, NA, NA, NA, NA, NA,  NA),
      NT_measure_time = c(60, 60, 60, 60, 60, 60, 60, 60, 60),
      time_between_NT_mid_MA = c(NA, NA, NA, NA, NA, NA, NA, NA,  NA),
      intervention_dosage = c(NA, NA, NA, NA, NA, NA, NA, NA, NA),
      NT_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School"),
      MA_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School"),
      NT_type = c("Calculation", "Conventional_Nominatives", "Conventional_Nominatives","Conventional_Nominatives", "Counting", "Ordering", "Number_Identification", "Cardinality", "Calculation"),
      NT_type.1 = c("Calculation", "Conventional_Nominatives", "Conventional_Nominatives","Conventional_Nominatives", "Counting", "Ordering", "Number_Identification", "Cardinality", "Calculation"),
      NT_type.10 = c("Calculation", "Conventional_Nominatives", "Conventional_Nominatives","Conventional_Nominatives", "Counting", "Ordering", "Number_Identification", "Cardinality", "Calculation"),
      MA_test = c("AD_Number_Sense", "AD_Number_Sense", "AD_Number_Sense", "ENT_R", "ENT_R","ENT_R", "ENT_R", "Quantity_Comparison_Task", "Number_Naming_Task"),
      MA_measure = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Quantity_Comparison", "Number_Identification"),
      MA_measure2 = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Quantity_Comparison", "Number_Sense"),
      analysis = c("Multiple_Regression", "Multiple_Regression", "Multiple_Regression", "Multiple_Multilevel_Regression", "Multiple_Multilevel_Regression", "Multiple_Multilevel_Regression", "Multiple_Multilevel_Regression", "Multiple_Regression", "Multiple_Regression"),
      controlled_variables = c(5, 5, 2, 7, 7, 7, 7, 2, 3),
      r = c(-0.1394642, 0.2006911, 0.1733843, 0.2875227, -0.1124199, -0.1356559, -0.1237494, 0.1187748, -0.1475598),
      n = c(251, 251, 251, 251, 251, 251, 251, 251, 251))

```


```{r levine_et_al.2010}
levine_et_al.2010_tib <- c(
  "levine_et_al.2010a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("NT - Point-to-X"),
      effect_id = c("Overall_Cardinality"), 
      year = c(2010),
      country = c("US"),
      study_id = c("levine_et_al.2010"),
      design = c("Correlational"),
      design.2 = c("Longitudinal_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Caregiver"),
      mothers = c(NA),
      white = c(0.704545455), 
      female = c(0.454545455),
      child_age_study_start = c(426.125),
      child_age_NT_start = c(426.125),
      child_age_NT_mid = c(669.625),
      child_age_NT_end = c(913.125),
      child_age_MA = c(1400.125),
      NT_measure_time = c(450),
      time_between_NT_mid_MA = c(730.5),
      intervention_dosage = c(NA),
      NT_context = c("Home"),
      MA_context = c("Unknown"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      MA_test = c("Point_to_X"),
      MA_measure = c("Cardinality"),
      MA_measure2 = c("Cardinality"),
      analysis = c("Zero Order Correlation"),
      controlled_variables = c(0),
      r = c(0.47),
      n = c(44))

```

```{r mix_et_al.2012}

####################################################################################################
#Converts pre post design to Standardised difference (for repeated measures)
d.rm <- function(m1, m2, s1, s2, r){
  ((m1-m2)*(sqrt(2*(1-r))))/sqrt(((s1^2)+(s2^2))-(2*r*s1*s2))
}

mix_et_al.2012_tib <- c(
  "mix_et_al.2012a", "mix_et_al.2012b", "mix_et_al.2012c",  "mix_et_al.2012d", "mix_et_al.2012e", "mix_et_al.2012f", "mix_et_al.2012g", "mix_et_al.2012h", "mix_et_al.2012i", "mix_et_al.2012j",
  "mix_et_al.2012k", "mix_et_al.2012l", "mix_et_al.2012m", "mix_et_al.2012n", "mix_et_al.2012o", "mix_et_al.2012p") %>% 
  data.frame() %>% rename(., effect = .) %>% add_column(
    n = c(12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12),
    tm1 =   c(8.67, 7.67, 8.67, 7.67, 5.08, 0.25, 5.08, 0.25, 6.33, 9.25, 6.33, 9.25, 3.91, 0.33, 3.91, 0.33),  
    ts1 =   c(6.13, 6.13, 6.13, 6.13, 0.90, 0.45, 0.90, 0.45, 3.67, 5.02, 3.67, 5.02, 2.36, 0.14, 2.36, 0.14), 
    tm2 =   c(7.92, 8.25, 9.92, 10.33, 5.00, 0.25, 4.92, 0.50, 6.67, 8.08, 6.92, 8.00, 3.58, 0.17, 3.75, 0.50),
    ts2 =   c(4.78, 5.33, 4.47, 4.33, 0.87, 0.45, 1.07, 0.23, 3.71, 3.74, 5.02, 4.92, 1.97, 0.11, 2.15, 0.80),
    cm1 =   c(5.25, 7.42, 5.25, 7.42, 4.17, 0.08, 4.17, 0.08, 5.25, 7.42, 5.25, 7.42, 4.17, 0.08, 4.17, 0.08),
    cs1 =   c(3.64, 3.95, 3.64, 3.95, 1.59, 0.28, 1.59, 0.28, 3.64, 3.95, 3.64, 3.95, 1.59, 0.28, 1.59, 0.28),
    cm2 =   c(6.17, 6.58, 8.08, 7.50, 3.83, 0.25, 3.75, 0.33, 6.17, 6.58, 8.08, 7.50, 3.83, 0.25, 3.75, 0.33),
    cs2 =   c(4.05, 3.33, 4.33, 4.78, 1.70, 0.45, 2.46, 0.48, 4.05, 3.33, 4.33, 4.78, 1.70, 0.45, 2.46, 0.48),
    r.pp =  c(0.50, 0.50, 0.67, 0.67, 0.95, 0.11, 0.57, -0.13, 0.61, 0.61, 0.70, 0.70, 0.81, -0.32, 0.94, 0.46)) %>% mutate(
      d.rm = ((tm2-tm1)*(sqrt(2*(1-r.pp))))/sqrt(((ts1^2)+(ts2^2))-(2*r.pp*ts1*ts2)), 
      d.ppc = ((tm2-tm1)-(cm2-cm1))/sqrt((((n-1)*(ts1^2)) + ((n-1)*(cs1^2)))/(n + n -2))) %>% add_column(
      effect_description = c("Counting - Counting aloud at session 3", "Counting - Counting disks at session 3", "Counting NT - Counting aloud at session 6", "Counting NT - Counting disks at session 6", "Counting NT - Cardinality 123 at session 3", "Counting NT - Cardinality 6 at session 3", "Counting NT - Cardinality 123 at session 6", "Counting NT - Cardinality 6 at session 6", "Cardinality NT - Counting aloud at session 3", "Cardinality  NT - Counting disks at session 3", "Cardinality  NT - Counting aloud at session 6", "Cardinality  NT - Counting disks at session 6", "Cardinality  NT - Cardinality 123 at session 3", "Cardinality  NT - Cardinality 6 at session 3", "Cardinality  NT - Cardinality 123 at session 6", "Cardinality NT - Cardinality 6 at session 6"),
      effect_id = c("Counting_Counting", "Counting_Counting", "Counting_Counting", "Counting_Counting", "Counting_Cardinality", "Counting_Cardinality", "Counting_Cardinality", "Counting_Cardinality", "Cardinality_Counting", "Cardinality_Counting", "Cardinality_Counting", "Cardinality_Counting", "Cardinality_Cardinality", "Cardinality_Cardinality", "Cardinality_Cardinality", "Cardinality_Cardinality"),
      year = c(2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012),
      country = c( "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US", "US"),
      study_id = c("mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012", "mix_et_al.2012"),
      design = c("Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental"),
      design.2 = c("Experimental_PPC","Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC","Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC", "Experimental_PPC"), 
      SES = c("Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle"),
      main_language = c("English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English", "English"),
      deliverer_type = c("Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter", "Experimenter"),
      mothers = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      white = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), 
      female = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_study_start = c(1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9),
      child_age_NT_start = c(1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9, 1314.9),
      child_age_NT_mid = c(1325.4, 1325.4, 1335.9, 1335.9, 1325.4, 1325.4, 1335.9, 1335.9, 1325.4, 1325.4, 1335.9, 1335.9, 1325.4, 1325.4, 1335.9, 1335.9),
      child_age_NT_end = c( NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_MA = c(1335.9, 1356.9, 1335.9, 1356.9, 1335.9, 1356.9, 1356.9, 1335.9, 1335.9, 1356.9, 1335.9, 1356.9, 1335.9, 1356.9, 1356.9, 1335.9),
      NT_measure_time = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      time_between_NT_mid_MA = c(10.5, 10.5, 21, 21, 10.5, 10.5, 21, 21, 10.5, 10.5, 21, 21, 10.5, 10.5, 21, 21),
      intervention_dosage = c(21, 21, 42, 42, 21, 21, 42, 42, 21, 21, 42, 42, 21, 21, 42, 42),
      NT_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
      MA_context = c("School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School", "School"),
      NT_type = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      NT_type.1 = c("Counting","Counting","Counting","Counting","Counting","Counting","Counting","Counting","Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Cardinality"),
      NT_type.10 = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      MA_test = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      MA_measure = c("Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality"),
      MA_measure2 = c("Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality", "Counting", "Counting", "Counting", "Counting", "Cardinality", "Cardinality", "Cardinality", "Cardinality"),
      analysis = c(NA, NA, NA, NA, NA, NA ,NA, NA, NA, NA, NA, NA, NA, NA, NA, NA),
      controlled_variables = c(1, 1, 1, 1, 1, 1,1, 1, 1, 1, 1, 1, 1, 1, 1, 1)) %>% mutate(r = d.ppc/(sqrt((d.rm^2)+4))) %>%  dplyr::select(effect, effect_description, effect_id, year, country, study_id, design, design.2, SES, main_language, deliverer_type, mothers, white, female, child_age_study_start, child_age_NT_start, child_age_NT_mid, child_age_NT_end, child_age_MA, NT_measure_time, time_between_NT_mid_MA, intervention_dosage, NT_context, MA_context, NT_type, NT_type.1, NT_type.10, MA_test, MA_measure, MA_measure2, analysis, controlled_variables, r, n)


```


```{r susperreguy_and_davis_kean.2016}
susperreguy_and_davis_kean.2016_tib <- c(
  "susperreguy_and_davis_kean.2016a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("Proportion of Cumulative Math Talk - TEMA-3"),
      effect_id = c("Overall_Overall"),
      year = c(2016),
      country = c("US"),
      study_id = c("susperreguy_and_davis_kean.2016"),
      design = c("Correlational"),
      design.2 = c("Longitudinal_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(1),
      white = c(0.686), 
      female = c(0.314285714),
      child_age_study_start = c(1643.625),
      child_age_NT_start = c(1643.625),
      child_age_NT_mid = c(1647.125),
      child_age_NT_end = c(1650.625),
      child_age_MA = c(2008.875),
      NT_measure_time = c(240),
      time_between_NT_mid_MA = c(365.25),
      intervention_dosage = c(NA),
      NT_context = c("Home"),
      MA_context = c("Unknown"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.17),
      n = c(33))

```

```{r casey_et_al.2018}
casey_et_al.2018_tib <- c(
  "casey_et_al.2018a", 
  "casey_et_al.2018b",
  "casey_et_al.2018c", 
  "casey_et_al.2018d", 
  "casey_et_al.2018e", 
  "casey_et_al.2018f", 
  "casey_et_al.2018g", 
  "casey_et_al.2018h") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("Identify numerals NT - WJ Applied Problems at 4.5 yrs", "Identify numerals NT - WJ Applied Problems at 1st grade", "One-to-one counting NT - WJ Applied Problems at 4.5 yrs", "One-to-one counting NT - WJ Applied Problems at 1st grade", "Label sets NT - WJ Applied Problems at 4.5 yrs", "Label sets NT - WJ Applied Problems at 1st grade", "Sum of numerical supports NT - WJ Applied Problems at 4.5 yrs", "Sum of numerical supports NT - WJ Applied Problems at 1st grade"),
      effect_id = c("Number_Identification_Overall", "Number_Identification_Overall", "Counting_Overall", "Counting_Overall", "Cardinality_Overall", "Cardinality_Overall", "Overall_Overall", "Overall_Overall" ), 
      year = c(2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018),
      country = c("US", "US", "US", "US", "US", "US", "US", "US"),
      study_id = c("casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018", "casey_et_al.2018"),
      design = c("Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational", "Correlational"),
      design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational", "Longitudinal_Correlational"), 
      SES = c("Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle", "Middle"),
      main_language = c("English", "English", "English", "English", "English", "English", "English", "English"),
      deliverer_type = c("Parent", "Parent", "Parent", "Parent", "Parent", "Parent", "Parent", "Parent"),
      mothers = c(1, 1, 1, 1, 1, 1, 1, 1),
      white = c(0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84, 0.84), 
      female = c(0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45),
      child_age_study_start = c(NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_NT_start = c(NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_NT_mid = c(1095.75, 1095.75, 1095.75, 1095.75, 1095.75, 1095.75, 1095.75, 1095.75),
      child_age_NT_end = c(NA, NA, NA, NA, NA, NA, NA, NA),
      child_age_MA = c(1643.625, 2374.125, 1643.625, 2374.125, 1643.625, 2374.125, 1643.625, 2374.125),
      NT_measure_time = c(10, 10, 10, 10, 10, 10, 10, 10),
      time_between_NT_mid_MA = c(547.875, 1278.375, 547.875, 1278.375, 547.875, 1278.375, 547.875, 1278.375),
      intervention_dosage = c(NA, NA, NA, NA, NA, NA, NA, NA),
      NT_context = c("Lab", "Lab", "Lab", "Lab", "Lab", "Lab", "Lab", "Lab"),
      MA_context = c("Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown", "Unknown"),
      NT_type = c("Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Overall", "Overall"),
      NT_type.1 = c("Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Overall", "Overall"),
      NT_type.10 = c("Number_Identification", "Number_Identification", "Counting", "Counting", "Cardinality", "Cardinality", "Overall", "Overall"),
      MA_test = c("WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP", "WJ_AP"),
      MA_measure = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall"),
      MA_measure2 = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall"),
      analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation","Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation", "Zero_Order_Correlation"),
      controlled_variables = c(0, 0, 0, 0, 0, 0, 0, 0),
      r = c(-0.02, -0.04, -0.01, 0.05, 0.30, 0.33, 0.06, 0.07),
      n = c(99, 99, 99, 99, 99, 99, 99, 99))

```

```{r zippert_et_al.2019}
#This study has been excluded
zippert_et_al.2019_tib <- c(
  "zippert_et_al.2019a", 
  "zippert_et_al.2019b", 
  "zippert_et_al.2019c", 
  "zippert_et_al.2019d",
  "zippert_et_al.2019e",
  "zippert_et_al.2019f",
  "zippert_et_al.2019g",
  "zippert_et_al.2019h") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("Counting NT - Rote Counting", "Number Identification NT - Rote Counting", "Cardinality NT - Rote Counting", "Quantity Comparison NT - Rote Counting", "Counting NT - Number Line Estimation", "Number Identification NT - Number Line Estimation", "Cardinality NT - Number Line Estimation", "Quantity Comparison NT - Number Line Estimation"),
      effect_id = c("Counting_Counting", "Number_Identification_Counting", "Cardinality_Counting", "Quantity_Comparison_Counting", "Counting_Number_Line_Estimation", "Number_Identification_Number_Line_Estimation", "Cardinality_Number_Line_Estimation", "Quantity_Comparison_Number_Line_Estimation"), 
      year = c(2019, 2019, 2019, 2019, 2019, 2019, 2019, 2019),
      country = c("US", "US", "US", "US", "US", "US", "US", "US"),
      study_id = c("zippert_et_al.2019", "zippert_et_al.2019", "zippert_et_al.2019", "zippert_et_al.2019", "zippert_et_al.2019", "zippert_et_al.2019", "zippert_et_al.2019", "zippert_et_al.2019"),
      design = c("Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental", "Experimental"),
      design.2 = c("Short_term_Experimental", "Short_term_Experimental", "Short_term_Experimental", "Short_term_Experimental", "Short_term_Experimental", "Short_term_Experimental", "Short_term_Experimental", "Short_term_Experimental"), 
      SES = c(NA, NA, NA, NA, NA, NA, NA, NA),
      main_language = c("English", "English", "English", "English", "English", "English", "English", "English"),
      deliverer_type = c("Parent", "Parent", "Parent", "Parent", "Parent", "Parent", "Parent", "Parent"),
      mothers = c(0.61, 0.61, 0.61, 0.61, 0.61, 0.61, 0.61, 0.61),
      white = c(NA, NA, NA, NA, NA, NA, NA, NA), 
      female = c(0.41, 0.41, 0.41, 0.41, 0.41, 0.41, 0.41, 0.41),
      child_age_study_start = c(1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99),
      child_age_NT_start = c(1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99),
      child_age_NT_mid = c(1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99),
      child_age_NT_end = c(1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99),
      child_age_MA = c(1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99, 1835.99),
      NT_measure_time = c(NA, NA, NA, NA, NA, NA, NA, NA),
      time_between_NT_mid_MA = c(0, 0, 0, 0, 0, 0, 0, 0),
      intervention_dosage = c(0.006944444, 0.006944444, 0.006944444, 0.006944444, 0.006944444, 0.006944444, 0.006944444, 0.006944444),
      NT_context = c("Museum", "Museum", "Museum", "Museum", "Museum", "Museum", "Museum", "Museum"),
      MA_context = c("Museum", "Museum", "Museum", "Museum", "Museum", "Museum", "Museum", "Museum"),
      NT_size = c(NA, NA, NA, NA, NA, NA, NA, NA),
      NT_size.1 = c("Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall", "Overall"),
      NT_type = c("Counting", "Number_Identification", "Cardinality", "Quantity_Comparison", "Counting", "Number_Identification", "Cardinality", "Quantity_Comparison"),
      NT_type.1 = c("Counting", "Number_Identification", "Cardinality", "Quantity_Comparison", "Counting", "Number_Identification", "Cardinality", "Quantity_Comparison"),
      NT_type.10 = c("Counting", "Number_Identification", "Cardinality", "Quantity_Comparison", "Counting", "Number_Identification", "Cardinality", "Quantity_Comparison"),
      MA_test = c("Verbal_Counting", "Verbal_Counting", "Verbal_Counting", "Verbal_Counting", "Number_Line_Estimation", "Number_Line_Estimation", "Number_Line_Estimation", "Number_Line_Estimation"),
      MA_measure = c("Counting", "Counting", "Counting", "Counting", "Number_Line_Estimation", "Number_Line_Estimation", "Number_Line_Estimation", "Number_Line_Estimation"),
      MA_measure2 = c("Counting", "Counting", "Counting", "Counting", "Number_Sense", "Number_Sense", "Number_Sense", "Number_Sense"),
      analysis = c("Partial_Correlation", "Partial_Correlation", "Partial_Correlation", "Partial_Correlation", "Partial_Correlation", "Partial_Correlation", "Partial_Correlation", "Partial_Correlation"),
      controlled_variables = c(2, 2, 2, 2, 2, 2, 2, 2),
      r = c(-0.39, 0.01, -0.05, -0.06, 0.31, -0.01, -0.17, -0.17),
      n = c(25, 25, 25, 25, 25, 25, 25, 25))
```

```{r thippana_et_al.2020}
thippana_et_al.2020_tib <- c(
  "thippana_et_al.2020a", 
  "thippana_et_al.2020b") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("Home NT proportion - TEMA-3 ", "Lab NT proportion - TEMA-3"),
      effect_id = c("Overall_Overall", "Overall_Overall"),
      year = c(2020, 2020),
      country = c(NA, NA),
      study_id = c("thippana_et_al.2020", "thippana_et_al.2020"),
      design = c("Correlational", "Correlational"),
      design.2 = c("Longitudinal_Correlational", "Longitudinal_Correlational"), 
      SES = c("Middle",  "Middle"),
      main_language = c("English", "English"),
      deliverer_type = c("Parent", "Parent"),
      mothers = c(0.94, 0.94),
      white = c(0.85, 0.85), 
      female = c(0.484536082, 0.484536082),
      child_age_study_start = c(1430.562, 1430.562),
      child_age_NT_start = c(NA, NA),
      child_age_NT_mid = c(1446.172, 1446.172),
      child_age_NT_end = c(NA, NA),
      child_age_MA = c(1492.442, 1492.442),
      NT_measure_time = c(30, 20),
      time_between_NT_mid_MA = c(46.27, 46.27),
      intervention_dosage = c(NA, NA),
      NT_context = c("Home", "Lab"),
      MA_context = c("Lab", "Lab"),
      NT_type = c("Overall", "Overall"),
      NT_type.1 = c("Overall", "Overall"),
      NT_type.10 = c("Overall", "Overall"),
      MA_test = c("TEMA_3", "TEMA_3"),
      MA_measure = c("Overall", "Overall"),
      MA_measure2 = c("Overall", "Overall"),
      analysis = c("Zero_Order_Correlation", "Zero_Order_Correlation"),
      controlled_variables = c(0, 0),
      r = c(0.20, 0.11),
      n = c(81, 81))

```

```{r gibson_et_al.2020}
gibson_et_al.2020_tib <- c(
  "gibson_et_al.2020a", 
  "gibson_et_al.2020b") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("Small Number Book vs Control", "Large Number vs Control"),
      effect_id = c("Overall_Number_Knowledge", "Overall_Number_Knowledge"),
      year = c(2020, 2020),
      country = c("US", "US"),
      study_id = c("gibson_et_al.2020", "gibson_et_al.2020"),
      design = c("Experimental", "Experimental"),
      design.2 = c("Long_term_Experimental", "Long_term_Experimental"), 
      SES = c("Middle", "Middle"),
      main_language = c("English", "English"),
      deliverer_type = c("Parent", "Parent"),
      mothers = c(NA, NA),
      white = c(0.52, 0.52), 
      female = c(0.52, 0.52),
      child_age_study_start = c(1132.275, 1132.275),
      child_age_NT_start = c(1132.275, 1132.275),
      child_age_NT_mid = c(1148.77, 1148.77),
      child_age_NT_end = c(1165.265, 1165.265),
      child_age_MA = c(1165.265, 1165.265),
      NT_measure_time = c(NA, NA),
      time_between_NT_mid_MA = c(16.495, 16.495),
      intervention_dosage = c(32.99, 32.99),
      NT_context = c("Home", "Home"),
      MA_context = c("Lab", "Lab"),
      NT_type = c("Counting_and_Labelling", "Counting_and_Labelling"),
      NT_type.1 = c("Overall", "Overall"),
      NT_type.10 = c(NA, NA),
      MA_test = c("Give_N", "Give_N"),
      MA_measure = c("Cardinality", "Cardinality"),
      MA_measure2 = c("Cardinality", "Cardinality"),
      analysis = c("Pairwise_t", "Pairwise_t"),
      controlled_variables = c(0, 0),
      r = c(0.3224328, 0.069597355),
      n = c(97, 97))

```

```{r silver_et_al.2021}
silver_et_al.2021_tib <- c(
  "silver_et_al.2021a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("NT - MA"),
      effect_id = c("Overall_Overall"),
      year = c(2021),
      country = c("US"),
      study_id = c("silver_et_al.2021"),
      design = c("Correlational"),
      design.2 = c("Cross_sectional_Correlational"), 
      SES = c("Middle"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(0.95),
      white = c(0.8), 
      female = c(0.479674797),
      child_age_study_start = c(1430.562),
      child_age_NT_start = c(1430.562),
      child_age_NT_mid = c(1430.562),
      child_age_NT_end = c(1430.562),
      child_age_MA = c(1430.562),
      NT_measure_time = c(10),
      time_between_NT_mid_MA = c(0),
      intervention_dosage = c(NA),
      NT_context = c("Lab"),
      MA_context = c("Lab"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.04),
      n = c(123))

```


```{r ogul_and_arnas.2021}
ogul_and_arnas.2021_tib <- c(
  "ogul_and_arnas.2021a") %>% 
  data.frame() %>% rename(., effect = .) %>% 
    add_column(
      effect_description = c("NT - TEMA-3"),
      effect_id = c("Overall_Overall"),
      year = c(2021),
      country = c("TURKEY"),
      study_id = c("ogul_and_arnas.2021"),
      design = c("Correlational"),
      design.2 = c("Unknown"), 
      SES = c("Unknown"),
      main_language = c("English"),
      deliverer_type = c("Parent"),
      mothers = c(1),
      white = c(NA), 
      female = c(0.675),
      child_age_study_start = c(1715.153),
      child_age_NT_start = c(1715.153),
      child_age_NT_mid = c(NA),
      child_age_NT_end = c(NA),
      child_age_MA = c(NA),
      NT_measure_time = c(160.5),
      time_between_NT_mid_MA = c(NA),
      intervention_dosage = c(NA),
      NT_context = c("Home"),
      MA_context = c("School"),
      NT_type = c("Overall"),
      NT_type.1 = c("Overall"),
      NT_type.10 = c("Overall"),
      MA_test = c("TEMA_3"),
      MA_measure = c("Overall"),
      MA_measure2 = c("Overall"),
      analysis = c("Zero_Order_Correlation"),
      controlled_variables = c(0),
      r = c(0.39),
      n = c(40))


```


```{r constructing_meta_tib}
meta_tib.p1 <- rbind(
  levine_et_al.2010_tib,
  mix_et_al.2012_tib,
  ramani_et_al.2015_tib,
  susperreguy_and_davis_kean.2016_tib,
  elliott_et_al.2017_tib, 
  casey_et_al.2018_tib,
  mutaf_yildiz_et_al.2018_tib, 
  son_and_hur.2020_tib,
  thippana_et_al.2020_tib, 
  gibson_et_al.2020_tib, 
  silver_et_al.2021_tib) 


#These studies are excluded
zippert_et_al.2019_tib
boonen_et_al.2011_tib
ogul_and_arnas.2021_tib
  
meta_tib <- escalc(measure = "ZCOR", ri = r, ni = n, data = meta_tib.p1) %>% data.frame() %>% 
    mutate(
    effect = as.factor(effect),
    effect_description = as.character(effect_description),
    effect_id = as.factor(effect_id),
    year = as.numeric(year),
    country = as.factor(country),
    study_id = as.factor(study_id),
    design = as.factor(design),
    design.2 = as.factor(design.2),
    SES = as.factor(SES),
    main_language = as.factor(main_language),
    deliverer_type = as.factor(deliverer_type),
    mothers = as.numeric(mothers),
    white = as.numeric(white),
    female = as.numeric(female),
    child_age_study_start = as.numeric(child_age_study_start),
    child_age_NT_start = as.numeric(child_age_NT_start),
    child_age_NT_mid = as.numeric(child_age_NT_mid),
    child_age_NT_end = as.numeric(child_age_NT_end),
    child_age_MA = as.numeric(child_age_MA),
    NT_measure_time = as.numeric(NT_measure_time),
    time_between_NT_mid_MA = as.numeric(time_between_NT_mid_MA),
    intervention_dosage = as.numeric(intervention_dosage),
    NT_context = as.factor(NT_context),
    MA_context = as.factor(MA_context),
    NT_type = as.factor(NT_type),
    NT_type.1 = as.factor(NT_type.1),
    NT_type.10 = as.factor(NT_type.10),
    MA_test = as.factor(MA_test),
    MA_measure = as.factor(MA_measure),
    MA_measure2 = as.factor(MA_measure2),
    analysis = as.factor(analysis),
    controlled_variables = as.numeric(controlled_variables),
    r = as.numeric(r),
    n = as.numeric(n)) %>% 
  dplyr::mutate(
    main_language = forcats::fct_relevel(main_language, "Dutch", "English"),
    NT_type.1 = forcats::fct_relevel(NT_type.1, "Cardinality", "Counting", "Number_Identification", "Overall"),
    NT_type.10 = forcats::fct_relevel(NT_type.10,"Cardinality", "Counting", "Number_Identification", "Overall"),
    MA_context = forcats::fct_relevel(MA_context, "Home", "Lab", "School", "Unknown"),
    MA_measure = forcats::fct_relevel(MA_measure, "Calculation", "Cardinality", "Counting", "Number_Identification", "Number_Line_Estimation", "Quantity_Comparison", "Overall"),
    MA_measure2 = forcats::fct_relevel(MA_measure2, "Calculation", "Cardinality", "Counting", "Number_Sense", "Quantity_Comparison", "Overall"),
    NT_context = forcats::fct_relevel(NT_context, "Home", "Lab", "School"))


#REPORT TABLE
#The number of effects in each study
num_eff_tib <- meta_tib %>% dplyr::select(study_id, year) %>% group_by(study_id) %>% summarise(effects = n()) %>% add_column(as.tibble(str_sub(.$study_id, - 4, - 1))) %>% rename(year = value) %>%  mutate(year = as.numeric(year)) %>% arrange(year) %>% dplyr::select(study_id, effects)
num_eff_tib 

#Stem and leaf diagram
stem(meta_tib$yi)

#Export data 
#write.xlsx(meta_tib, "meta_tib.xlsx", overwrite = T)
meta_tib %>% view()
```


```{r random_effect_meta_analysis}
#Random-effect meta-analysis
re_meta_model <- rma(yi = yi, vi = vi, data = meta_tib, method  = "REML")
re_meta_model

#Forest Plot
forest(re_meta_model, addpred = T, header = T)

#Gosh Plot 
#plot(gosh(re_meta_model, subset = 20000), out = 10)

#RESULTS
# Fisher's z = 0.0596
```


```{r ml_meta_analysis}
#2-level model (This is basically an RE model)
ml_meta_model.2lre <- rma.mv(yi = yi, V = vi, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | effect)
ml_meta_model.2lre

#2-level meta-analysis (this is the one that I fitted before)
ml_meta_model.2l <- rma.mv(yi = yi, V = vi, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | study_id)
ml_meta_model.2l

#3-level meta-analysis
ml_meta_model.3l <- rma.mv(yi = yi, V = vi, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | study_id/effect)
ml_meta_model.3l

#Correlated 3-level meta-analysis (CHE)
#Estimate dependency 
correlations <- c(0.5, 0.95, 0.11, 0.26, 0.61, 0.81, 0.32, 0.67) %>% as.tibble() %>% rename(r = value) %>% mutate(abs.r = abs(r))
dr <- correlations$r %>% mean() %>% sqrt()
#Because effect sizes tend not to be measured across time, a compound symmetry variance matrix is assumed

#Adjust the covariance structure 
v_CHE <- impute_covariance_matrix(meta_tib$vi, cluster = meta_tib$study_id, r = dr)

#CHE model
ml_meta_model.3lCHE <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                        random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE 


#DEPENDENCY SENSITIVITY ANALYSIS
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE.dep.data <- dependency.sen(data = meta_tib, random = ~ 1 | study_id/effect, cluster = meta_tib$study_id, r = seq(0, 0.99, 0.01))
ml_meta_model.3lCHE.dep.data 

ml_meta_model.3lCHE.dep.plot <- ggplot(data = ml_meta_model.3lCHE.dep.data) + geom_line(mapping = aes(x = r_level, y = tval), color = "#50989D", alpha = 0.7, size = 1) + scale_y_continuous(breaks = seq(0.03, 0.10, by = 0.005)) + scale_x_continuous(breaks = seq(0, 1, by = 0.1)) + theme_minimal()
ml_meta_model.3lCHE.dep.plot 
#It requires a correlation of 0.335 for the effect to be significant, because it is not possible for the same sample to be correlated that weakly, I conclude that the effect is nonsignificant 




#INFLUENCE CHECKS
#----------------------------------------------------------------------------------------------------
#Effect level
#Beta 0
#ml_meta_model.3lCHE.influence.eff <- rma.mv.influence(random = ~1 | study_id/effect, struct = "CS", data = meta_tib, method = "REML", cluster = "effect", CHE = TRUE, r = dr, robust.cluster = "study_id", robust = F)
#ml_meta_model.3lCHE.influence.eff %>% filter(abs(DFBETAS) > 1)
#Based on Cook's d, there are no influential cases

#STUDY LEVEL
#Beta 0
#ml_meta_model.3lCHE.influence.stud <- rma.mv.influence(random = ~1 | study_id/effect, struct = "CS", data = meta_tib, method = "REML", cluster = "study_id", CHE = TRUE, r = dr, robust.cluster = "study_id")
#ml_meta_model.3lCHE.influence.stud
#Based on Cook's d, there are no influential studies

#Forest plots
forest(ml_meta_model.3lCHE, addpred = T, header = T, slab = meta_tib$effect)


#Examine the variance distribution (how much variance in each level)
vardist.3l(model = ml_meta_model.3lCHE, digits =  5)
#var.comp(ml_meta_model.3lCHE) %>% plot()



#ROBUST
#METAFOR
ml_meta_model.3lCHE.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE , cluster = meta_tib$study_id, adjust = T)

#ClubSandwich 
ml_meta_model.3lCHE.rbst.cs <- coef_test(ml_meta_model.3lCHE, vcov="CR2", cluster=meta_tib$study_id) 

#Comparing all the models
fitstats(re_meta_model, ml_meta_model.2lre, ml_meta_model.2l, ml_meta_model.3l, ml_meta_model.3lCHE)
#ml_meta_model.2lre > re_meta_model > ml_meta_model.3l > ml_meta_model.2l

```

```{r metaSEM}
#Fitting a 3-level meta-analysis (Cheung, 2019) using metaSEM 
#Does not run, don't know why 
#meta3(y = yi, v = v_CHE, cluster = study_id, data = meta_tib) %>% summary()

#Compare with 3 level meta-analysis with metafor 
#TO COMPARE THEM, SET METHOD TO ML IN METAFOR, BECAUSE METASEM USES ML
#meta3(y = yi, v = vi, cluster = study_id, data = meta_tib) 
ml_meta_model.3lCHE

```





```{r moderator_analysis_main_language}
#DON'T DO THIS ANALYSIS - NOT ENOUGH DATA 
#Checking the levels 
levels(meta_tib$main_language)

#Setting contrast weights
english_vs_dutch <- c(-1/2, 1/2)
contrasts(meta_tib$main_language) <- english_vs_dutch


#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_main_language <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                          mods = ~ main_language,
                                          random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_main_language

#Visualize 
regplot(ml_meta_model.3lCHE_mod_main_language, xlab = "Language")


#ASSUMPTION CHECKS
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_main_language)
#RESULTS 

#NORMALITY OF RESIDUALS 
#Residual normality good 

#HETEROSCEDASTICITY 
#Variance is homoscedastic 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: ROBUST IT 


#ROBUST
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_main_language.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_main_language, cluster = meta_tib$study_id)
ml_meta_model.3lCHE_mod_main_language.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_main_language, vcov="CR2", cluster=meta_tib$study_id)
ml_meta_model.3lCHE_mod_main_language.rbst.metafor 
ml_meta_model.3lCHE_mod_main_language.rbst.cs

#INFLUENCE CHECKS
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL
#Beta 1
#ml_meta_model.3lCHE_mod_main_language.b1.lev2 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ NT_type.1, random = ~1 | study_id/effect, cluster = "effect", b = 1, robust = T, robust.cluster = "study_id", adjust = T)
#There are no outliers/influential effects

#STUDY LEVEL
#Beta 1
#ml_meta_model.3lCHE_mod_main_language.b1.lev3 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ NT_type.1, random = ~1 | study_id/effect, cluster = "study_id", b = 1, robust = T, robust.cluster = "study_id", adjust = T)
#Based on Cook's d, there is 1 influential study (mutaf_yildiz_et_al.2018 and casey_et_al.2018)


```



```{r moderator_analysis_NT_type.1}
#Checking the levels for NT_type.1
levels(meta_tib$NT_type.1)

#Setting contrast weights (deviation coding)
cardinalityNT_vs_mean           <- c(0.5, 0, 0, -0.5)          
countingNT_vs_mean              <- c(0, 0.5, 0, -0.5)      
number_identificationNT_vs_mean <- c(0, 0, 0.5, -0.5) 

contrasts(meta_tib$NT_type.1) <- cbind(
  cardinalityNT_vs_mean,
  countingNT_vs_mean,
  number_identificationNT_vs_mean)

#contrasts(meta_tib$NT_type.1) <- contr.sum(10) - This is for sum coding - The p-values/results are all the same as deviation coding


#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_NT_type.1 <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                      mods = ~   NT_type.1, 
                                      random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_NT_type.1 


#ASSUMPTION
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_NT_type.1)
#RESULTS 

#NORMALITY OF RESIDUALS 
#Residuals are not normally distributed 

#HETEROSCEDASTICITY 
#Variance is fair 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: Robust it

#ROBUST
#----------------------------------------------------------------------------------------------------
#ROBUST SE
#METAFOR::ROBUST
ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_NT_type.1 , cluster=meta_tib$study_id, adjust = T)
ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_NT_type.1.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_NT_type.1, vcov="CR2", cluster=meta_tib$study_id)
ml_meta_model.3lCHE_mod_NT_type.1.rbst.cs


#BONFERRONI CORRECTION
#----------------------------------------------------------------------------------------------------
bonferroni <- function(model){
  tib1 <- filter(add_column(rename(rownames_to_column(as.data.frame(model$beta), var = "comparison"), estimate = V1), rename(as.tibble(model$pval), pval = value)), comparison != "intrcpt")
  tib2 <- dplyr::select(mutate(tib1, bonferroni.pval = pval*nrow(tib1), sig = ifelse(pval <= 0.05, ifelse(pval <= 0.01, "**", "*"), "ns"), sig.2 = ifelse(bonferroni.pval <= 0.05, ifelse(bonferroni.pval <= 0.01, "**", "*"), "ns")), comparison, estimate, pval, sig, bonferroni.pval, sig.2)
  return(tib2)
}

bonferroni(ml_meta_model.3lCHE_mod_main_language)


#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL
#Beta 3
#ml_meta_model.3l_mod_NT_type.1_influence.lev2.b3 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ NT_type.1, random = ~1 | study_id/effect, cluster = "effect", b = 3, robust = T, robust.cluster = "effect",adjust = T)
#ml_meta_model.3l_mod_NT_type.1_influence.lev2.b3 %>% filter(abs(DFBETAS) >= 1)
#Based on Cook's d and DFBETAS, There are no outliers and influential cases 


#STUDY LEVEL
#Beta 3
#ml_meta_model.3l_mod_NT_type.1_influence.lev3.b3 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ NT_type.1, random = ~1 | study_id/effect, cluster = "study_id", b = 3, robust = T, robust.cluster = "effect",adjust = T)
#ml_meta_model.3l_mod_NT_type.1_influence.lev3.b3

ml_meta_model.3lCHE_mod_NT_type.1


t1 <- cbind(ml_meta_model.3lCHE_mod_NT_type.1$b, ml_meta_model.3lCHE_mod_NT_type.1$se, ml_meta_model.3lCHE_mod_NT_type.1$zval, ml_meta_model.3lCHE_mod_NT_type.1$pval, ml_meta_model.3lCHE_mod_NT_type.1$ci.lb, ml_meta_model.3lCHE_mod_NT_type.1$ci.ub) %>% as.data.frame() %>% rownames_to_column(var = "Effect_Description.p1") %>% rename(estimate = V1, se = V2, t = V3, p = V4, ci.l = V5, ci.u = V6)  %>% add_row(Effect_Description.p1 = c("")) %>% add_column(Effect_Description = c("Intercept", "Cardinality", "Counting", "Number Identification", "Robust")) %>% dplyr::select(Effect_Description, estimate, se, t, p, ci.l, ci.u) %>% rbind(., cbind(ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor$b, ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor$se, ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor$zval, ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor$pval, ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor$ci.lb, ml_meta_model.3lCHE_mod_NT_type.1.rbst.metafor$ci.ub) %>% as.data.frame() %>% rownames_to_column(var = "Effect_Description.p1") %>% rename(estimate = V1, se = V2, t = V3, p = V4, ci.l = V5, ci.u = V6) %>% add_column(Effect_Description = c("Intercept", "Cardinality", "Counting", "Number Identification")) %>% dplyr::select(Effect_Description, estimate, se, t, p, ci.l, ci.u)) %>%  dplyr::mutate(dplyr::across(where(is.numeric), ~round(., 3)))%>% kable(format = "html", caption = "Table 1: The effect of NT type. Robust results at the bottom", col.names = c("Effect", "Estimate", "SE", "t", "p", "95% CI Lower", "95% CI Upper")) %>% kable_styling(full_width = T, position = "center") %>% row_spec(row = 0, extra_css = "border-bottom: 2px solid black;") %>% row_spec(row = 4, extra_css = "border-bottom: 2px solid black;") 
  

```



```{r MA_measure}
#Checking the levels for MA_measure
levels(meta_tib$MA_measure)

#Setting contrast weights (deviation coding)
calculationMA_vs_mean <-             c(0.5, 0, 0, 0, 0, 0, -0.5)
cardinalityMA_vs_mean <-             c(0, 0.5, 0, 0, 0, 0, -0.5)
countingMA_vs_mean <-                c(0, 0, 0.5, 0, 0, 0, -0.5)
number_identificationMA_vs_mean <-   c(0, 0, 0, 0.5, 0, 0, -0.5) 
number_line_estimation_MA_vs_mean <- c(0, 0, 0, 0, 0.5, 0, -0.5)
quantity_comparisonMA_vs_mean <-     c(0, 0, 0, 0, 0, 0.5, -0.5)

contrasts(meta_tib$MA_measure) <- cbind(
  calculationMA_vs_mean, 
  cardinalityMA_vs_mean,
  countingMA_vs_mean,
  number_identificationMA_vs_mean,
  number_line_estimation_MA_vs_mean,
  quantity_comparisonMA_vs_mean)



#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
#3-level model
ml_meta_model.3lCHE_mod_MA_measure <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                      mods = ~ MA_measure, 
                                      random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_MA_measure


#ASSUMPTIONS 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_MA_measure)
#RESULTS 
#NORMALITY OF RESIDUALS 
#Residuals are normally distributed
#HETEROSCEDASTICITY 
#Variance is homoscedastic 
#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods
#Conclusion: Normal SE


#ROBUST
#----------------------------------------------------------------------------------------------------
#Sensitivity test with robust SE
ml_meta_model.3lCHE_mod_MA_measure

#ROBUST SE
#METAFOR::ROBUST
ml_meta_model.3lCHE_mod_MA_measure.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_MA_measure , cluster=meta_tib$study_id, adjust = T)
ml_meta_model.3lCHE_mod_MA_measure.rbst.metafor 

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_MA_measure.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_MA_measure, vcov="CR2", cluster=meta_tib$study_id)


#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL (They are all the same; they are all based on Cook's d)
#Beta 1
#ml_meta_model.3l_mod_MA_measure.influence.b1.lev2 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 1, adjust = T)
#ml_meta_model.3l_mod_MA_measure.influence.b1.lev2

#Beta 5
#ml_meta_model.3l_mod_MA_measure.rbst.influence.b5.lev2 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 5, adjust = T)
#ml_meta_model.3l_mod_MA_measure.rbst.influence.b5.lev2
#Based on Cook's d, there are 7 influential cases
#Beta 6
#ml_meta_model.3l_mod_MA_measure.influence.b6.lev2 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 6, adjust = T)


#STUDY LEVEL 
#Beta 1
#ml_meta_model.3l_mod_MA_measure.influence.b1.lev3 <- sandwich.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "study_id", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~MA_measure, b = 1, adjust = T)
#ml_meta_model.3l_mod_MA_measure.influence.b1.lev3 
```




```{r MA_context}
#Checking the levels for MA context
levels(meta_tib$MA_context)

#Checking the data 
meta_tib %>% group_by(MA_context) %>% summarise(n = n())

#Setting contrast weights 
home_vs_mean <-   c(0.5, 0, 0, -0.5)
lab_vs_mean <-    c(0, 0.5, 0, -0.5)
school_vs_mean <- c(0, 0, 0.5, -0.5)

contrasts(meta_tib$MA_context) <- cbind(
  home_vs_mean,
  lab_vs_mean,
  school_vs_mean)


#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
#3-level model
ml_meta_model.3lCHE_mod_MA_context <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                       mods = ~ MA_context, 
                                       random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_MA_context


#ASSUMPTION 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_MA_context)
#RESULTS 

#NORMALITY OF RESIDUALS 
#Residuals are not normally distributed 

#HETEROSCEDASTICITY 
#Variance is heteroscedastic 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: Robust it 


#ROBUST
#----------------------------------------------------------------------------------------------------
#ROBUST SE
#METAFOR
ml_meta_model.3lCHE_mod_MA_context.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_MA_context, cluster=meta_tib$study_id, adjust = T)
ml_meta_model.3lCHE_mod_MA_context.rbst.metafor

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_MA_context.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_MA_context, vcov = "CR2", cluster = meta_tib$study_id)


#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL 
#Beta 1
#ml_meta_model.3l_mod_MA_context.influence.b1 <-  rma.mv.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~ MA_context, b = 1, adjust = T)
#ml_meta_model.3l_mod_MA_context.influence.b1

#Based on Cook's d, there are 2 influential cases (mutaf a and mutaf b)

#Beta 2
#ml_meta_model.3l_mod_MA_context.influence.b2 <-  rma.mv.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "effect", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~ MA_context, b = 2, adjust = T)
#ml_meta_model.3l_mod_MA_context.influence.b2


#STUDY LEVEL 
#Beta 1
#ml_meta_model.3l_mod_MA_context.influence.lev3.b1 <-  rma.mv.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "study_id", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~ MA_context, b = 1, adjust = T)
#ml_meta_model.3l_mod_MA_context.influence.lev3.b1

#Beta 2
#ml_meta_model.3l_mod_MA_context.influence.lev3.b2 <-  rma.mv.influence(data = meta_tib, random = ~1 | study_id/effect, struct = "CS", method = "REML", cluster = "study_id", robust.cluster = "study_id", CHE = TRUE, r = dr, mods = ~ MA_context, b = 2, adjust = T)
#ml_meta_model.3l_mod_MA_context.influence.lev3.b2


```

```{r moderator_analysis_mothers}
#Con mothers (Mothers as a continuous variable)
ml_meta_model.3lCHE_mod_mothers_con <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                    mods = ~ mothers, 
                                    random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_mothers_con
#RESULTS
#The proportion of mothers significantly enhanced the effect NT on MA


#Arcsine (Mothers as a an arc)
#----------------------------------------------------------------------------------------------------
meta_tib_mod_arc <- meta_tib %>% mutate(mothers.arc = asin(sqrt(mothers)))

ml_meta_model.3lCHE_mod_mothers_arc <- rma.mv(yi = yi, V = v_CHE, data = meta_tib_mod_arc, struct = "CS", method = "REML", test = "t",
                                            mods = ~ mothers.arc, 
                                            random = ~ 1 | study_id/effect)


#Cat mothers (Mothers as a categorical variable)
#----------------------------------------------------------------------------------------------------
#Create the mothers as a factor 
meta_tib_mod_mothers <- meta_tib %>% mutate(mothers_cat = ifelse(mothers > 0.8250958, "high", "low")) %>% mutate(mothers_cat = as.factor(mothers_cat)) %>% mutate(mothers_cat = fct_relevel(mothers_cat, "low", "high"))

#Setting contrast weights
#Checking the levels 
levels(meta_tib_mod_mothers$mothers_cat)
#Setting contrast weights 
mothers_cat.high_vs_low <- c(-0.5, 0.5)
contrasts(meta_tib_mod_mothers$mothers_cat) <- mothers_cat.high_vs_low


#Moderator analysis for mothers as a cat
#----------------------------------------------------------------------------------------------------
#3-level model 
ml_meta_model.3lCHE_mod_mothers_cat <- rma.mv(yi = yi, V = v_CHE, data = meta_tib_mod_mothers, struct = "CS", method = "REML", test = "t",
                                            mods = ~ mothers_cat, 
                                            random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_mothers_cat
#RESULTS
#Mothers was significant (p = 0.0468)

#Regression Plot
regplot(ml_meta_model.3lCHE_mod_mothers_cat , xlab = "Proportion of Mothers")


#ASSUMPTION 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_mothers_cat)
#RESULTS 

#NORMALITY OF RESIDUALS 
#Residuals are good 

#HETEROSCEDASTICITY 
#Variance is homoscedastic 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: Normal SE

#ROBUST
#METAFOR
robust(ml_meta_model.3lCHE_mod_mothers_cat, cluster = meta_tib$study_id)

#CLUBSANDWICH
coef_test(ml_meta_model.3lCHE_mod_mothers_cat, vcov = "CR2", cluster = meta_tib$study_id, test = "naive-tp")


#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL 
#Beta 1
#ml_meta_model.3l_mod_mothers_cat.influence.lev2.b1 <- rma.mv.influence( data = meta_tib_mod_mothers, struct = "CS", method = "REML",mods = ~ mothers_cat, random = ~ 1 | study_id/effect, cluster = "effect", b = 1, robust = F, robust.cluster = "effect", adjust = T)


#STUDY LEVEL 
#Beta 1
#ml_meta_model.3l_mod_mothers_cat.influence.lev3.b1 <- rma.mv.influence(data = meta_tib_mod_mothers, struct = "CS", method = "REML",mods = ~ mothers_cat, random = ~ 1 | study_id/effect, cluster = "study_id", b = 1, robust = F, robust.cluster = "effect", adjust = T)
#ml_meta_model.3l_mod_mothers_cat.influence.lev3.b1

```


```{r moderator_analysis_child_age_NT_mid}
#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_child_age_NT_mid <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                                mods = ~ child_age_NT_mid, 
                                                random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_child_age_NT_mid 

regplot(ml_meta_model.3lCHE_mod_child_age_NT_mid, xlab = "Child Age During Number Talk (Days)")


#ASSUMPTION 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_child_age_NT_mid)

#RESULTS 

#NORMALITY OF RESIDUALS 
#Residuals are fairly normal 

#HETEROSCEDASTICITY 
#Variance is homoscedastic 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: Normal SE

#ROBUST
#----------------------------------------------------------------------------------------------------
#METAFOR
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.metafor <- robust(ml_meta_model.3lCHE_mod_child_age_NT_mid, cluster = meta_tib$study_id, adjust = T)
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.metafor

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_child_age_NT_mid, vcov = "CR2", cluster=meta_tib$study_id)
ml_meta_model.3lCHE_mod_child_age_NT_mid.rbst.cs


#INFLUENCE
#----------------------------------------------------------------------------------------------------
#EFFECT LEVEL 
#Beta 1
#ml_meta_model.3l_mod_child_age_NT_mid.influence.b1.lev2 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ child_age_NT_mid, random = ~ 1 | study_id/effect, cluster = "effect",robust.cluster = "study_id", b = 1, robust = F, CHE = T, r = dr)
#ml_meta_model.3l_mod_child_age_NT_mid.influence.b1.lev2


#STUDY LEVEL 
#Beta 1
#ml_meta_model.3l_mod_child_age_NT_mid.influence.b1.lev3 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ child_age_NT_mid, random = ~ 1 | study_id/effect, cluster = "study_id",robust.cluster = "study_id", b = 1, robust = F, CHE = T, r = dr)
#ml_meta_model.3l_mod_child_age_NT_mid.influence.b1.lev3

```

```{r NT_context}
#Checking the levels
levels(meta_tib$NT_context)

meta_tib %>% group_by(NT_context) %>% summarise(n = n())

#Setting contrast weights 
NThome_vs_mean <-   c(0.5, 0, -0.5)
NTlab_vs_mean <-    c(0, 0.5, -0.5)

contrasts(meta_tib$NT_context) <- cbind(NThome_vs_mean, NTlab_vs_mean)


#MODERATOR ANALYSIS 
#----------------------------------------------------------------------------------------------------
#3-level regression
ml_meta_model.3lCHE_mod_NT_context <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                       mods = ~ NT_context, 
                                       random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_NT_context


#PAIRWISE COMPARISON
#----------------------------------------------------------------------------------------------------
#summary(glht(ml_meta_model.3lCHE_mod_NT_context, linfct=cbind(contrMat(rep(1,3), type="Tukey"))), test=adjusted("none"))


#ASSUMPTION 
#----------------------------------------------------------------------------------------------------
assumption(model = ml_meta_model.3lCHE_mod_NT_context)
#RESULTS 

#NORMALITY OF RESIDUALS 
#Residuals are questionable 

#HETEROSCEDASTICITY 
#Variance is homoscedastic 

#NORMALITY OF THE SAMPLING DISTRIBUTION 
#Sensitivity test with robust methods

#Conclusion: Robust 


#ROBUST
#----------------------------------------------------------------------------------------------------
#ROBUST SE
#METAFOR::ROBUST
ml_meta_model.3lCHE_mod_NT_context.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_NT_context, cluster= meta_tib$study_id, adjust = T)
ml_meta_model.3lCHE_mod_NT_context.rbst.metafor

#CLUBSANDWICH 
ml_meta_model.3lCHE_mod_NT_context.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_NT_context, cluster = meta_tib$study_id, vcov = "CR2")
ml_meta_model.3lCHE_mod_NT_context.rbst.cs
```


```{r time_lag}
#MODERATOR ANALYSIS
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_time_lag <- rma.mv(yi = yi, V = v_CHE, data = meta_tib, struct = "CS", method = "REML", test = "t",
                                       mods = ~ time_between_NT_mid_MA, 
                                       random = ~ 1 | study_id/effect)
ml_meta_model.3lCHE_mod_time_lag 

regplot(ml_meta_model.3lCHE_mod_time_lag)

#ASSUMPTION
#----------------------------------------------------------------------------------------------------
assumption(ml_meta_model.3lCHE_mod_time_lag)

#ROBUST
#----------------------------------------------------------------------------------------------------
ml_meta_model.3lCHE_mod_time_lag.rbst.metafor <- metafor::robust(ml_meta_model.3lCHE_mod_time_lag, cluster = meta_tib$study_id, adjust = T)
ml_meta_model.3lCHE_mod_time_lag.rbst.cs <- coef_test(ml_meta_model.3lCHE_mod_time_lag, vcov = "CR2")
ml_meta_model.3lCHE_mod_time_lag.rbst.metafor 
ml_meta_model.3lCHE_mod_time_lag.rbst.cs

#INFLUENCE
#----------------------------------------------------------------------------------------------------
#ml_meta_model.3lCHE_mod_time_lag_influence.lev2 <- rma.mv.influence(data = meta_tib, struct = "CS", method = "REML", mods = ~ time_between_NT_mid_MA, random = ~ 1 | study_id/effect, cluster = "effect",robust.cluster = "study_id", b = 1, robust = F, CHE = T, r = dr)
#ml_meta_model.3lCHE_mod_time_lag_influence.lev2
```



```{r publication_bias}
#Funnel plot
#----------------------------------------------------------------------------------------------------
metafor::funnel(ml_meta_model.3lCHE)

#Egger's test
#----------------------------------------------------------------------------------------------------
#Create the data for Egger's regression 
meta_tib_egger <- meta_tib %>% mutate(se = sqrt(vi), snd = yi/se, inv.se = 1/se)
#LM
egger <- lm(snd ~ inv.se, data = meta_tib_egger) 
summary(egger)

#Regression plot
ggplot(meta_tib_egger, aes(x = inv.se, y = snd)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "black") + 
  scale_x_continuous(limits = c(2.7, 10)) +
  theme_minimal()
#RESULTS
#Egger's test indicated that there is no publication bias 


#Vevea and Wood (2005)
#----------------------------------------------------------------------------------------------------
weightfunct(effect = meta_tib$yi, v = meta_tib$vi, steps=c(0.05, 0.20, 1), weights = c(1, 0.7, 0.5))


#Negative selection 
weightfunct(effect = meta_tib$yi, v = meta_tib$vi, steps=c(0.5, 0.975, 1.00), weights = c(0.3, 0.6, 1), fe = F, table = T)


cntr.fctr <- (ml_meta_model.3lCHE$b - re_meta_model$b) %>% c()


meta_tib_weightr.cntr <-  meta_tib %>% mutate(yi.cntr = yi + cntr.fctr)
meta_tib_weightr.cntr


re_meta_model_weightr.cntr <-  rma(yi = yi.cntr, vi = vi, data = meta_tib_weightr.cntr)
re_meta_model_weightr.cntr


#Modelling moderate negative selection bias 
mod_neg <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.95, 1.00), weights = c(0.5, 1), fe = F, table = T)
mod_neg
#Modelling severe negative selection bias
sev_neg <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.95, 1.00), weights = c(0.2, 1), fe = F, table = T)
sev_neg

mod_pos <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.05, 1), weights = c(1, 0.5), fe = F, table = T)
mod_pos
#Modelling severe negative selection bias
sev_pos <- weightfunct(effect = meta_tib_weightr.cntr$yi.cntr, v = meta_tib_weightr.cntr$vi, steps=c(0.05, 1), weights = c(1, 0.2), fe = F, table = T)
sev_pos


```



# Methods
## Search
<p class="gojira"> Studies are searched through several databases, specifically, PsycInfo, PsycArticles, Scopus, ScienceDirect, and Web of Science, using the same command `AB(("number* talk*") OR ("numer* talk*))`. The reference list of identified studies are checked for any studies not identified through the databases. All corresponding authors of the identified studies are enquired for unpublished data and ongoing studies through email. Ongoing studies are also searched through OSF. </p>

## Selecting Effect Sizes 
<p class="gojira"> The majority of the studies are correlational (k = 9) and the rest are experimental (k = 2), thus, Pearson's correlation is used as the effect size (ES) for the meta-analysis. All ESs that represent the effect of NT on MA are considered relevant and are included. Most studies have multiple relevant effects. There are 2 sources of multiplicity: differences in effect specification (e.g. outcome measures) and type of statistical analyses (e.g. Pearson's correlation or regression). The first source of multiplicity can be dealt by combining all relevant effect sizes as an average, so that each study contributes only one ES, or by including all relevant ESs from each study. The latter approach is chosen to enable moderator analyses. The second source of multiplicity is mainly from correlational studies in which studies provide estimates without covariates (mostly zero-order correlations) and those with different covariates. Since most studies provided estimates without covariates, only ESs without covariates are included to maintain comparability. Studies that do not provide ESs without covariates are excluded. A total of 48 ESs from 11 studies are included (summarised in Table x). The ESs are transformed to Fisher's z for statistical analyses. </p>

## Meta-analysis 
<p class="gojira"> Since some studies included multiple ESs, a multilevel modelling approach is used to examine heterogeneity more accurately. A 3-level hierarchical structure (Cheung, 2014, 2019; Assink & Wibbelink, 2016), in which sampling variances (level 1) are nested within ESs (level 2), and ESs are nested within studies (level 3) is used. This 3-level model assumes that ESs within studies are independent of each other. However, ESs within each study are based on the same participants, hence, the model is extended to a correlated hierarchical effects approach (Pustejovsky & Tipton, 2018, 2021), in which sampling variances of ESs within studies are assumed to correlate with each other. The degree of correlation is estimated from an average of a series of correlations between outcome measures provided by a corresponding author of one of the included studies (r = .73). Most of the ESs within studies are cross-sectional, hence, compound symmetry is assumed. The sampling covariance structure is adjusted by the `clubSandwich package` (Pustejovsky, 2022) with the `impute_covariance_matrix` function. The 3-level model is then fitted by the `metafor` package (Viechtbauer, 2010) with the `rma.mv` function with Restricted Maximum Likelihood estimation. Cluster robust standard error (SE) is estimated by the `metafor::robust` function and its associated results with small sample adjustment are examined. </p>




## Publication bias
### Funnel Plot
<p class="gojira"> Publication bias is first examined visually through the funnel plot. The funnel plot shows the precision of estimation (SE) against its associated ES. If the ESs are symmetrical around the weighted-average given SE, it suggests no publication bias. However, asymmetry shows there is an imbalance of studies reporting either larger or smaller ESs, which suggests publication bias.   </p>
### Egger's test
<p class="gojira"> Small study bias is then examined. Small study bias is a type of bias in which small studies report more extreme ESs relative to its precision. This can be tested by Egger's test (Egger et al., 1997), which is a linear regression in which the standard normal deviate (SND) of the ESs is regressed against its precision. The SND is the standardised score of an ES in the normal distribution under the null hypothesis (SND = zi = ESi/sei) and its precision is its inverse SE (1/sei). When there is no publication bias, studies with a lower precision are expected to have an SND closer to 0, and that a precision of 0 will have an SND of 0. Egger's test tests this hypothesis by testing whether the intercept is 0, in other words, it tests whether the SND is 0 when the inverse SE is 0. A non-significant intercept shows that there are no or very little number of small studies with low precision that report relatively large SND, which suggests no small study bias. On the other hand, a significant intercept shows that there are studies with low precision that report relatively large SND, which suggests small study bias.  </p>
### Vevea and Woods' Selection Model
<p class="gojira"> The impact of selection bias on this meta-analysis is assessed by Vevea and Woods' (2005) selection model, which is a type of corrective method that estimates the weighted-average under certain pattern of selection bias based on p-values. Selection bias based on p-values has to be modelled by a weight function for the biased ES to be estimated. 2 models of selection bias are examined. The first is indicated by the funnel plot, the second is determined a priori according to the hypothesised intention of authors of the included studies. Each model is examined at a moderate and severe level. The model of selection bias determined a priori are Moderate Upper-tail Selection Bias, in which ESs with p-values in the range 0 < p < .05 have a probability of 1 of being published and those in the range .05 < p < 1 have a probability of 0.5 of being published; and Severe Upper-tail Selection Bias, in which ESs with p-values in the range 0 < p < .05 have a probability of 1 of being published and those in the range .05 < p < 1 have a probability of 0.2 of being published. </p>


## Moderator Analysis
<p class="gojira"> Potential moderators are tested through series of simple Generalised Least Squares mixed effect linear regression models, in which the intercept is random and slopes are fixed. The models are examined for any violations of assumptions of GLM through the model residuals. Cluster robust SEs are estimated and their associated results with small sample adjustment are compared. Outliers and influential cases are examined at the ES level. Outliers are indicated by having an absolute studentized residual larger than 1.96 and influential ESs are indicated by having either an absolute value of Cook's distances or DEBETASs larger than 1. Leave1out analysis is conducted for ESs that are considered as outliers or influential.</p>


# Results
## Meta-analyis 
<p class="gojira"> NT has a small effect on children's MA (zr = 0.114, SE = .052, 95% CI = [0.009, 0.219], t(47) = 2.18, p = .0341). There is a significant amount of heterogeneity among ESs (Q(47) = 171.328, p < .001). The variance and intraclass correlation (ICC) are examined. The sampling variance is estimated using a method described in Higgins and Thompson (2002, equation 9) and the ICCs are estimated using a method described in Hox (2010, p.21, equation 2.16). Level 1 has a variance of .025, level 2 has a variance of .025 and an ICC of .503, and level 3 has a variance of 0 and an ICC of 0. This shows that half of the variance is attributable to sampling error and the other half is attributable to the true heterogeneity (I^2 = 50.27%). All of the true heterogeneity is attributable to differences between effects within studies and none is attributable to differences between studies. The ICC also shows that ESs within studies are strongly correlated with each other and studies are not correlated with each other. Outliers and influential cases are examined. There are 3 outliers indicated by studentized residual but no influential ESs indicated by Cook's distance or DFBETAS. Leave1out analysis shows that results remain significant except for Levine et al. (2010). Robust SE is estimated and results derived from robust SE with small sample adjustment are estimated for sensitivity analysis. Results are consistent (SE = .040, t(10) = 2.85, p = 0.017). </p>

```{r forest, echo = FALSE, fig.align='center', include = TRUE}
metafor::forest(ml_meta_model.3lCHE, slab = meta_tib$effect, header = T, xlim=c(-2.5,2))
```


## Publication Bias
<p class="gojira">  The funnel plot (figure n) shows symmetry for larger studies but asymmetry for smaller studies, specifically, smaller studies more often report smaller ESs than larger studies. The lack of larger ESs for smaller studies suggests some negative publication bias in smaller studies. Egger's test shows the intercept is negative but not significant (b0 = -0.736, SE = 0.41017, t(46) = -1.794, p = .0794), which indicates no small study bias. However, it is not far from being significant and has a considerable effect size, which suggests minor negative publication bias. The impact of selection bias on the estimate is examined by Vevea and Woods' (2005) selection model. The model of selection bias hypothesised a priori is first examined. Results suggest the ES is reduced to .077 and .028 under Moderate and Severe Upper-tail Selection bias respectively. As suggested by the funnel plot and Egger's test, there may be some negative selection bias. Hence, a model of negative selection bias is examined at 2 levels: Moderate Lower-tail Selection Bias, in which ESs with .95 < p < 1 have a probability of 1 of being published and those with 0 < p .95 have a probability of 0.5; and Severe Lower-tail Selection Bias, in which ESs with .95 < p < 1 have a probability of 1 of being published and those with 0 < p .95 have a probability of 0.2. Results suggest the ES is increased to 0.1247 and 0.1387 under Moderate and Severe Lower-tail Selection Bias respectively. Overall, Vevea and Woods' selection model suggests the estimate is small and positive even under various selection biases based on p-values. </p>

```{r funnel, echo = FALSE, fig.align='center', include = TRUE}
metafor::funnel(ml_meta_model.3lCHE)
```


## Moderator Analysis 
### NT Type
<p class="gojira">  Some studies examined the effects of specific individual types of NT, meanwhile others either examined the effects of multiple types of NT in combination or did not categorise the type of NT. ESs that represent effects of distinct types of NT are coded for the type of NT according to the definition and examples of the type of NT provided in the study and not their labels as labels for the same definitions and examples, which represent the same types of NT, can vary across studies. 3 types of NT are identified: Cardinality, Counting, and Number Identification. ESs that represent the effect of multiple types of NT in combination or unknown type of NT are coded as 'General'. The type of NT is entered into a simple regression as a categorical with 4 levels with deviation coding. Results suggest no effect of the type of NT (F(3, 44) = 0.5562, p = 0.6468). None of the contrasts is statistically significant (Table 1). Residual plots indicated that the assumption of homoscedasticity may not be met. Hence, cluster robust SE is estimated and results derived from cluster robust SE with small sample adjustment are examined. Results indicated that the type of NT has a significant effect (F(3, 7) = 1.81 * 10^16, p < .001). Compared to the grand mean, Number Identification is significantly lower (-0.2539, SE = 0.0261, p < .001) and Cardinality (b = .089, SE = 0.2371, p = 0.3752) and Count (b = .133, SE = 0.1482, p = 0.3983) are not significantly different (Table 1). Outliers and influential cases are examined. There are 3 outliers indicated by studentized residuals and 2 other influential ESs indicated by Cook's distance. Leave1out analysis is conducted for these 4 ESs (A1). In sum, the effect of NT may be moderated by the type of NT, particularly, Number Identification NT has a smaller (and negative) effect than other types of NT.  </p>
```{r t1, include = T, echo = F, fig.align='center'}
t1
```



### MA Type
<p class="gojira"> Outcome measures representing different types of MA on which the effect of NT is evaluated differ across ESs. Some studies evaluated the effect of NT on distinct types of MA while others evaluated that on a combination of different types of MA. ESs representing the effect of NT on distinct types of MA are coded for their specific types of MA according to the description of the outcome measure. 6 types of MA are identified: Calculation, Cardinality, Counting, Number Identification, Number Line Estimation, and Quantity Comparison. ESs representing the effect of NT on several types of MA in combination are coded as 'general'. MA type is entered into a simple regression as a categorical variable with deviation coding. Results indicated no effect of the MA type (F(6, 41) = 1.6818, p = .150). Examining the contrasts (Table n), compared to average, Quantity Comparison has a significantly larger effect and calculation has a significantly lower effect. The model is examined for any violations of model assumptions. Residual plots suggest the assumption of normality of residuals may not be met. Hence, cluster robust SEs are estimated and the associated results with small sample adjustment are examined. Results are consistent, in addition, Number Line Estimation has a significantly larger effect than average. Outliers and influential ESs are examined. There are 4  outliers indicated by studentized residual and 4 influential cases based on Cook's distance. Leave1out analysis for these ESs are shown in table n. In sum, the effect of NT may be moderated by the type of MA, particularly, NT may have larger (and positive) effects on Quantity Comparison and Number Line Estimation but smaller (and negative) effect on Calculation. </p>


### NT context
<p class="gojira"> NT is delivered in different contexts across studies. The ESs are coded for the context in which NT is delivered (NT context). All studies provided information about the NT context. 3 NT contexts are identified: Home, Lab, and School. NT context is entered in a simple regression as a categorical variable with deviation coding. Results indicated no effects of NT context (F stats). Since deviation coding does not compare all 3 levels, and all 3 levels are genuine, levels are compared with each other in a multiple comparison. None of the comparisons is significant. Overall, the effect of NT on MA may not be moderated by the context in which NT is delivered. </p>



### MA context
<p class="gojira"> MA is measured in different context across studies. The ESs are coded for the context in which MA is measured (MA context) according to information in the paper. Some studies specified the context while others did not. For ESs in studies that specified the MA context, 3 contexts are identified: Home, Lab, and School. ESs with unknown MA context are coded as 'unknown'. MA context is entered into a simple regression as a categorical variable with deviation coding. Results indicated no effect of MA context (F stats). None of the contrasts is significant (Table n). The model is examined for any violations of GLM assumptions. Residual plots indicated that normality of residuals and homoscedasticity may not be met. Hence, cluster robust SEs are estimated and associated results with small sample adjustment are examined. Results indicated that measuring NT at home has a smaller (and negative) effect and measuring NT in a lab has a larger effect than average (Table n). Outliers and influential cases are examined. There are 2 outlying ESs indicated by studentized residual and 2 influential ESs indicated by Cook's distance and DFBETAS. Leave1out analysis is conducted for the only significant contrast and is presented in Table n. </p>


### Child Age
<p class="gojira"> The age of the children around which NT is delivered varies across studies. Child age during NT is defined as the mean age of the sample at the mid-point when NT is measured. Child age is entered in a simple regression. Results indicated no effect of child age. The model is examined for any violations of assumptions of GLM. Residual plots suggest GLM assumptions are met. Nonetheless, cluster robust SEs are estimated and associated results with small sample adjustment are examined for sensitivity analysis.  Results are consistent. Outliers and influential cases are examined. There is 1 outlier indicated by studentized residual and no influential ES indicated by either Cook's distance or DFBETAS. Leave1out analysis shows that leave1out estimates are consistently non-significantly except for 1 ES (Elliott et al. 2017a). Overall, the effect of NT on MA may not be moderated by child age during which NT is delivered.  </p>

### Time Lag
<p class="gojira"> The length of time between NT delivery and outcome measure differs across ESs. This time lag is defined as the length of time between the mid point of NT delivered is and the time at which MA is measured in days. Time lag is entered in a simple regression. Results indicated no effect of time lag. The model is examined for any violations of GLM assumptions. Residual plots indicated that assumptions of GLM are met. Nonetheless, cluster robust SE is estimated and the associated results with small sample adjustment are examined for sensitivity analysis. Results are consistent. Outliers and influential cases are examined. There are 3 outliers indicated by studentised residuals but no influential ESs indicated by either Cook's distance or DFBETAS. Leave1out analysis is conducted for those outliers (Table n) </p>












